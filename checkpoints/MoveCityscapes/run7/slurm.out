Starting run 7
Cityscapes data copied to scratch
----------------- Options ---------------
               batch_size: 64                            	[default: 1]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
           continue_train: False                         
                crop_size: 256                           	[default: 64]
                 dataroot: /scratch/datasets/Cityscapes/ 	[default: None]
             dataset_mode: move_coco                     	[default: room]
                direction: AtoB                          
              display_env: main                          
             display_freq: 10                            	[default: 100]
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
              fake_target: 0.1                           
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 64]
                       lr: 2e-05                         	[default: 0.0002]
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: 10000                         	[default: inf]
          min_obj_surface: 100                           
                    model: move                          	[default: copy]
                 n_epochs: 10                            	[default: 100]
           n_epochs_decay: 20                            	[default: 100]
               n_layers_D: 3                             
            n_layers_conv: 4                             
                     name: Move                          	[default: MoveModel]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: True                          
                  no_html: False                         
             noisy_labels: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               	[default: resize]
               print_freq: 20                            
              real_target: 0.9                           
                      run: -1                            
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
                     seed: 42                            	[default: 0]
           serial_batches: False                         
                   suffix:                               
                theta_dim: 6                             	[default: 2]
              tracemalloc: False                         
               two_stream: False                         
         update_html_freq: 10                            	[default: 100]
                  use_amp: False                         
              use_eq_loss: False                         
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [MoveCocoDataset] and dataloder are created
dataset [MoveCocoDataset] and dataloder are created
The number of validation images = 500
Starting training of move-model
The number of training images = 2975
The number of epochs to run = 30
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [MoveModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): MoveConvNET(
    (model): Sequential(
      (0): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.2, inplace=True)
      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (4): LeakyReLU(negative_slope=0.2, inplace=True)
      (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (7): LeakyReLU(negative_slope=0.2, inplace=True)
      (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (10): LeakyReLU(negative_slope=0.2, inplace=True)
      (11): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (13): LeakyReLU(negative_slope=0.2, inplace=True)
      (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (15): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (16): LeakyReLU(negative_slope=0.2, inplace=True)
      (17): Flatten(start_dim=1, end_dim=-1)
      (18): Linear(in_features=32768, out_features=100, bias=True)
    )
    (zero_c): Sequential(
      (0): Linear(in_features=100, out_features=2, bias=True)
      (1): Tanh()
    )
    (one_c): Sequential(
      (0): Linear(in_features=100, out_features=2, bias=True)
      (1): Tanh()
    )
    (trans): Sequential(
      (0): Linear(in_features=100, out_features=2, bias=True)
      (1): Tanh()
    )
  )
)
[Network Conv] Total number of parameters : 9.550 M
DataParallel(
  (module): NLayerDiscriminator(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.2)
      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (4): LeakyReLU(negative_slope=0.2)
      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (7): LeakyReLU(negative_slope=0.2)
      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (10): LeakyReLU(negative_slope=0.2)
      (11): Conv2d(512, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
      (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (13): LeakyReLU(negative_slope=0.2)
      (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
      (15): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 6.960 M
-----------------------------------------------
create web directory /scratch/checkpoints/Move/web...
validation accuracies:
                real: 0.48, 0.4937337239583333
                fake: 0.53, 0.4999186197916667

ran validation set (B:1) in                         30.3 s.
10 tensor([[1.2356, 0.0000, 0.6073],
        [0.0000, 0.7589, 0.5718]], device='cuda:0', grad_fn=<SelectBackward>)
20 tensor([[1.0791, 0.0000, 0.4162],
        [0.0000, 0.7716, 0.4259]], device='cuda:0', grad_fn=<SelectBackward>)
(epoch: 1, batches: 20, time: 0.019, data: 0.027) loss_D_real: 0.765 loss_D_fake: 0.746 loss_D: 0.755 loss_G: 0.840 loss_conv: 0.840 acc_real: 0.531 acc_fake: 0.554 
30 tensor([[1.0929, 0.0000, 0.7049],
        [0.0000, 0.7455, 0.4631]], device='cuda:0', grad_fn=<SelectBackward>)
40 tensor([[ 0.8632,  0.0000,  0.4931],
        [ 0.0000,  0.7037, -0.6699]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 1, batches: 40, time: 0.019, data: 0.023) loss_D_real: 0.697 loss_D_fake: 0.693 loss_D: 0.695 loss_G: 0.876 loss_conv: 0.876 acc_real: 0.603 acc_fake: 0.622 
learning rate 0.0000200 -> 0.0000200
End of epoch 1 / 30 	 Time Taken: 172 sec
50 tensor([[ 1.1650,  0.0000, -0.5442],
        [ 0.0000,  0.7941, -0.4976]], device='cuda:0',
       grad_fn=<SelectBackward>)
60 tensor([[ 0.8131,  0.0000, -0.3884],
        [ 0.0000,  0.6980, -0.7644]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 2, batches: 20, time: 0.012, data: 0.020) loss_D_real: 0.643 loss_D_fake: 0.646 loss_D: 0.644 loss_G: 0.883 loss_conv: 0.883 acc_real: 0.671 acc_fake: 0.685 
70 tensor([[ 0.7674,  0.0000, -0.3765],
        [ 0.0000,  0.7331, -0.7866]], device='cuda:0',
       grad_fn=<SelectBackward>)
80 tensor([[ 0.7339,  0.0000,  0.5379],
        [ 0.0000,  0.6748, -0.8258]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 2, batches: 40, time: 0.014, data: 0.022) loss_D_real: 0.637 loss_D_fake: 0.629 loss_D: 0.633 loss_G: 0.901 loss_conv: 0.901 acc_real: 0.679 acc_fake: 0.719 
90 tensor([[ 0.7078,  0.0000, -0.4440],
        [ 0.0000,  0.6719, -0.7355]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000200 -> 0.0000200
End of epoch 2 / 30 	 Time Taken: 151 sec
100 tensor([[ 0.6929,  0.0000, -0.5578],
        [ 0.0000,  0.6731, -0.7536]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.70, 0.591796875
                fake: 0.70, 0.4149576822916667

ran validation set (B:101) in                         29.0 s.
110 tensor([[ 0.6951,  0.0000, -0.7819],
        [ 0.0000,  0.6761, -0.7432]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 3, batches: 20, time: 0.012, data: 0.025) loss_D_real: 0.647 loss_D_fake: 0.578 loss_D: 0.612 loss_G: 1.002 loss_conv: 1.002 acc_real: 0.681 acc_fake: 0.770 
120 tensor([[0.7154, 0.0000, 0.2627],
        [0.0000, 0.6708, 0.0859]], device='cuda:0', grad_fn=<SelectBackward>)
130 tensor([[ 0.6784,  0.0000, -0.0443],
        [ 0.0000,  0.6857, -0.7688]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 3, batches: 40, time: 0.012, data: 0.031) loss_D_real: 0.591 loss_D_fake: 0.557 loss_D: 0.574 loss_G: 1.057 loss_conv: 1.057 acc_real: 0.745 acc_fake: 0.798 
learning rate 0.0000200 -> 0.0000200
End of epoch 3 / 30 	 Time Taken: 169 sec
140 tensor([[ 0.6933,  0.0000,  0.1408],
        [ 0.0000,  0.6703, -0.5506]], device='cuda:0',
       grad_fn=<SelectBackward>)
150 tensor([[ 0.6732,  0.0000, -0.5102],
        [ 0.0000,  0.6765, -0.7040]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 4, batches: 20, time: 0.014, data: 0.029) loss_D_real: 0.588 loss_D_fake: 0.541 loss_D: 0.564 loss_G: 1.041 loss_conv: 1.041 acc_real: 0.752 acc_fake: 0.814 
160 tensor([[ 0.6740,  0.0000, -0.8204],
        [ 0.0000,  0.6692, -0.7992]], device='cuda:0',
       grad_fn=<SelectBackward>)
170 tensor([[ 0.6704,  0.0000,  0.3768],
        [ 0.0000,  0.6710, -0.6291]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 4, batches: 40, time: 0.013, data: 0.023) loss_D_real: 0.560 loss_D_fake: 0.524 loss_D: 0.542 loss_G: 1.132 loss_conv: 1.132 acc_real: 0.770 acc_fake: 0.829 
180 tensor([[ 0.6686,  0.0000, -0.4467],
        [ 0.0000,  0.6690, -0.8242]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000200 -> 0.0000200
End of epoch 4 / 30 	 Time Taken: 152 sec
190 tensor([[ 0.6713,  0.0000, -0.8055],
        [ 0.0000,  0.7074, -0.7649]], device='cuda:0',
       grad_fn=<SelectBackward>)
200 tensor([[ 0.6832,  0.0000,  0.4099],
        [ 0.0000,  0.6737, -0.5381]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.81, 0.65771484375
                fake: 0.74, 0.380126953125

ran validation set (B:201) in                         28.7 s.
(epoch: 5, batches: 20, time: 0.012, data: 9.404) loss_D_real: 0.479 loss_D_fake: 0.555 loss_D: 0.517 loss_G: 1.071 loss_conv: 1.071 acc_real: 0.886 acc_fake: 0.785 
210 tensor([[ 0.6678,  0.0000,  0.8273],
        [ 0.0000,  0.6701, -0.4403]], device='cuda:0',
       grad_fn=<SelectBackward>)
220 tensor([[ 0.6728,  0.0000,  0.3022],
        [ 0.0000,  0.6817, -0.8171]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 5, batches: 40, time: 0.014, data: 0.026) loss_D_real: 0.546 loss_D_fake: 0.523 loss_D: 0.534 loss_G: 1.263 loss_conv: 1.263 acc_real: 0.795 acc_fake: 0.826 
230 tensor([[ 0.6775,  0.0000,  0.4945],
        [ 0.0000,  0.6753, -0.5151]], device='cuda:0',
       grad_fn=<SelectBackward>)
saving the model at the end of epoch 5, iters 14720
learning rate 0.0000200 -> 0.0000200
End of epoch 5 / 30 	 Time Taken: 169 sec
240 tensor([[0.6722, 0.0000, 0.1258],
        [0.0000, 0.6678, 0.6301]], device='cuda:0', grad_fn=<SelectBackward>)
250 tensor([[ 0.6701,  0.0000,  0.1858],
        [ 0.0000,  0.6710, -0.8083]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 6, batches: 20, time: 0.021, data: 0.024) loss_D_real: 0.470 loss_D_fake: 0.544 loss_D: 0.507 loss_G: 1.243 loss_conv: 1.243 acc_real: 0.892 acc_fake: 0.797 
260 tensor([[ 0.6669,  0.0000,  0.7130],
        [ 0.0000,  0.6673, -0.7380]], device='cuda:0',
       grad_fn=<SelectBackward>)
270 tensor([[ 0.6763,  0.0000, -0.5976],
        [ 0.0000,  0.6735, -0.7072]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 6, batches: 40, time: 0.021, data: 0.022) loss_D_real: 0.516 loss_D_fake: 0.520 loss_D: 0.518 loss_G: 1.249 loss_conv: 1.249 acc_real: 0.835 acc_fake: 0.834 
learning rate 0.0000200 -> 0.0000200
End of epoch 6 / 30 	 Time Taken: 152 sec
280 tensor([[ 0.6746,  0.0000, -0.7618],
        [ 0.0000,  0.7007, -0.7169]], device='cuda:0',
       grad_fn=<SelectBackward>)
290 tensor([[ 0.6685,  0.0000, -0.4865],
        [ 0.0000,  0.6761, -0.5047]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 7, batches: 20, time: 0.014, data: 0.022) loss_D_real: 0.485 loss_D_fake: 0.485 loss_D: 0.485 loss_G: 1.431 loss_conv: 1.431 acc_real: 0.875 acc_fake: 0.865 
300 tensor([[ 0.6678,  0.0000,  0.5058],
        [ 0.0000,  0.6686, -0.8195]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.83, 0.6857096354166666
                fake: 0.82, 0.321044921875

ran validation set (B:301) in                         28.7 s.
310 tensor([[ 0.6674,  0.0000,  0.8255],
        [ 0.0000,  0.6673, -0.6098]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 7, batches: 40, time: 0.011, data: 0.206) loss_D_real: 0.524 loss_D_fake: 0.479 loss_D: 0.502 loss_G: 1.356 loss_conv: 1.356 acc_real: 0.829 acc_fake: 0.866 
320 tensor([[ 0.6718,  0.0000,  0.8023],
        [ 0.0000,  0.6782, -0.4997]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000200 -> 0.0000200
End of epoch 7 / 30 	 Time Taken: 167 sec
330 tensor([[ 0.6792,  0.0000, -0.8078],
        [ 0.0000,  0.6903, -0.1928]], device='cuda:0',
       grad_fn=<SelectBackward>)
340 tensor([[ 0.6718,  0.0000,  0.1313],
        [ 0.0000,  0.6732, -0.6567]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 8, batches: 20, time: 0.012, data: 0.027) loss_D_real: 0.462 loss_D_fake: 0.464 loss_D: 0.463 loss_G: 1.466 loss_conv: 1.466 acc_real: 0.919 acc_fake: 0.902 
350 tensor([[ 0.6684,  0.0000, -0.0824],
        [ 0.0000,  0.6669, -0.7802]], device='cuda:0',
       grad_fn=<SelectBackward>)
360 tensor([[ 0.6679,  0.0000,  0.3814],
        [ 0.0000,  0.6671, -0.7681]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 8, batches: 40, time: 0.014, data: 0.023) loss_D_real: 0.508 loss_D_fake: 0.469 loss_D: 0.488 loss_G: 1.431 loss_conv: 1.431 acc_real: 0.835 acc_fake: 0.882 
learning rate 0.0000200 -> 0.0000200
End of epoch 8 / 30 	 Time Taken: 152 sec
370 tensor([[ 0.6675,  0.0000, -0.5389],
        [ 0.0000,  0.6691, -0.0841]], device='cuda:0',
       grad_fn=<SelectBackward>)
380 tensor([[ 0.6669,  0.0000, -0.1807],
        [ 0.0000,  0.6671, -0.8048]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 9, batches: 20, time: 0.013, data: 0.023) loss_D_real: 0.462 loss_D_fake: 0.493 loss_D: 0.477 loss_G: 1.496 loss_conv: 1.496 acc_real: 0.882 acc_fake: 0.861 
390 tensor([[ 0.6674,  0.0000, -0.7011],
        [ 0.0000,  0.6674, -0.7940]], device='cuda:0',
       grad_fn=<SelectBackward>)
400 tensor([[ 0.6708,  0.0000, -0.7544],
        [ 0.0000,  0.6677,  0.1669]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.85, 0.7145182291666666
                fake: 0.83, 0.2967936197916667

ran validation set (B:401) in                         28.7 s.
(epoch: 9, batches: 40, time: 0.011, data: 0.020) loss_D_real: 0.505 loss_D_fake: 0.456 loss_D: 0.480 loss_G: 1.443 loss_conv: 1.443 acc_real: 0.836 acc_fake: 0.897 
410 tensor([[ 0.6672,  0.0000, -0.8139],
        [ 0.0000,  0.6676, -0.8108]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000200 -> 0.0000200
End of epoch 9 / 30 	 Time Taken: 168 sec
420 tensor([[ 0.6719,  0.0000, -0.6375],
        [ 0.0000,  0.6680, -0.2285]], device='cuda:0',
       grad_fn=<SelectBackward>)
430 tensor([[ 0.6712,  0.0000,  0.1323],
        [ 0.0000,  0.6680, -0.5774]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 10, batches: 20, time: 0.014, data: 9.078) loss_D_real: 0.496 loss_D_fake: 0.454 loss_D: 0.475 loss_G: 1.504 loss_conv: 1.504 acc_real: 0.874 acc_fake: 0.892 
440 tensor([[ 0.6677,  0.0000, -0.8200],
        [ 0.0000,  0.6669, -0.8180]], device='cuda:0',
       grad_fn=<SelectBackward>)
450 tensor([[ 0.6741,  0.0000,  0.7236],
        [ 0.0000,  0.6680, -0.2598]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 10, batches: 40, time: 0.013, data: 9.303) loss_D_real: 0.440 loss_D_fake: 0.463 loss_D: 0.451 loss_G: 1.482 loss_conv: 1.482 acc_real: 0.919 acc_fake: 0.895 
460 tensor([[ 0.6671,  0.0000,  0.6591],
        [ 0.0000,  0.6669, -0.4068]], device='cuda:0',
       grad_fn=<SelectBackward>)
saving the model at the end of epoch 10, iters 29440
learning rate 0.0000200 -> 0.0000160
End of epoch 10 / 30 	 Time Taken: 152 sec
470 tensor([[ 0.6670,  0.0000, -0.2125],
        [ 0.0000,  0.6677, -0.8216]], device='cuda:0',
       grad_fn=<SelectBackward>)
480 tensor([[ 0.6670,  0.0000,  0.4719],
        [ 0.0000,  0.6672, -0.7973]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 11, batches: 20, time: 0.023, data: 0.026) loss_D_real: 0.514 loss_D_fake: 0.455 loss_D: 0.484 loss_G: 1.486 loss_conv: 1.486 acc_real: 0.813 acc_fake: 0.895 
490 tensor([[ 0.6670,  0.0000,  0.7621],
        [ 0.0000,  0.6679, -0.8299]], device='cuda:0',
       grad_fn=<SelectBackward>)
500 tensor([[0.6692, 0.0000, 0.8222],
        [0.0000, 0.6676, 0.0290]], device='cuda:0', grad_fn=<SelectBackward>)
(epoch: 11, batches: 40, time: 0.028, data: 0.027) loss_D_real: 0.418 loss_D_fake: 0.437 loss_D: 0.427 loss_G: 1.561 loss_conv: 1.561 acc_real: 0.943 acc_fake: 0.915 
validation accuracies:
                real: 0.89, 0.7498372395833334
                fake: 0.84, 0.287353515625

ran validation set (B:501) in                         28.6 s.
learning rate 0.0000160 -> 0.0000160
End of epoch 11 / 30 	 Time Taken: 170 sec
510 tensor([[ 0.6671,  0.0000,  0.8327],
        [ 0.0000,  0.6705, -0.7883]], device='cuda:0',
       grad_fn=<SelectBackward>)
520 tensor([[ 0.6696,  0.0000,  0.2554],
        [ 0.0000,  0.6671, -0.8015]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 12, batches: 20, time: 0.013, data: 0.025) loss_D_real: 0.437 loss_D_fake: 0.448 loss_D: 0.442 loss_G: 1.683 loss_conv: 1.683 acc_real: 0.927 acc_fake: 0.889 
530 tensor([[ 0.6668,  0.0000, -0.7276],
        [ 0.0000,  0.6669, -0.8163]], device='cuda:0',
       grad_fn=<SelectBackward>)
540 tensor([[ 0.6670,  0.0000,  0.6031],
        [ 0.0000,  0.6682, -0.8036]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 12, batches: 40, time: 0.012, data: 0.024) loss_D_real: 0.514 loss_D_fake: 0.443 loss_D: 0.478 loss_G: 1.628 loss_conv: 1.628 acc_real: 0.833 acc_fake: 0.913 
550 tensor([[ 0.6671,  0.0000,  0.4928],
        [ 0.0000,  0.6678, -0.7669]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000160 -> 0.0000160
End of epoch 12 / 30 	 Time Taken: 152 sec
560 tensor([[ 0.6672,  0.0000,  0.7776],
        [ 0.0000,  0.6674, -0.3964]], device='cuda:0',
       grad_fn=<SelectBackward>)
570 tensor([[ 0.6670,  0.0000, -0.2510],
        [ 0.0000,  0.6681, -0.7326]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 13, batches: 20, time: 0.014, data: 0.021) loss_D_real: 0.501 loss_D_fake: 0.398 loss_D: 0.450 loss_G: 1.602 loss_conv: 1.602 acc_real: 0.835 acc_fake: 0.960 
580 tensor([[ 0.6670,  0.0000, -0.5681],
        [ 0.0000,  0.6683, -0.8329]], device='cuda:0',
       grad_fn=<SelectBackward>)
590 tensor([[ 0.6668,  0.0000, -0.5569],
        [ 0.0000,  0.6668, -0.6059]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 13, batches: 40, time: 0.013, data: 0.023) loss_D_real: 0.454 loss_D_fake: 0.426 loss_D: 0.440 loss_G: 1.532 loss_conv: 1.532 acc_real: 0.885 acc_fake: 0.931 
learning rate 0.0000160 -> 0.0000160
End of epoch 13 / 30 	 Time Taken: 152 sec
600 tensor([[ 0.6670,  0.0000,  0.3924],
        [ 0.0000,  0.6672, -0.8285]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.89, 0.7584635416666666
                fake: 0.86, 0.2661539713541667

ran validation set (B:601) in                         28.5 s.
610 tensor([[ 0.6678,  0.0000, -0.6894],
        [ 0.0000,  0.6668, -0.7328]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 14, batches: 20, time: 0.008, data: 0.032) loss_D_real: 0.463 loss_D_fake: 0.437 loss_D: 0.450 loss_G: 1.565 loss_conv: 1.565 acc_real: 0.886 acc_fake: 0.911 
620 tensor([[ 0.6671,  0.0000, -0.5829],
        [ 0.0000,  0.6674, -0.7915]], device='cuda:0',
       grad_fn=<SelectBackward>)
630 tensor([[ 0.6684,  0.0000, -0.4512],
        [ 0.0000,  0.6678,  0.8020]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 14, batches: 40, time: 0.011, data: 0.031) loss_D_real: 0.452 loss_D_fake: 0.439 loss_D: 0.445 loss_G: 1.703 loss_conv: 1.703 acc_real: 0.898 acc_fake: 0.907 
640 tensor([[ 0.6669,  0.0000, -0.3265],
        [ 0.0000,  0.6671, -0.6948]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000160 -> 0.0000160
End of epoch 14 / 30 	 Time Taken: 159 sec
650 tensor([[ 0.6680,  0.0000, -0.4037],
        [ 0.0000,  0.6683, -0.8142]], device='cuda:0',
       grad_fn=<SelectBackward>)
660 tensor([[ 0.6675,  0.0000,  0.5259],
        [ 0.0000,  0.6744, -0.8233]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 15, batches: 20, time: 0.013, data: 9.405) loss_D_real: 0.421 loss_D_fake: 0.424 loss_D: 0.423 loss_G: 1.563 loss_conv: 1.563 acc_real: 0.933 acc_fake: 0.925 
670 tensor([[ 0.6675,  0.0000, -0.3344],
        [ 0.0000,  0.6729, -0.8332]], device='cuda:0',
       grad_fn=<SelectBackward>)
680 tensor([[ 0.6669,  0.0000,  0.6387],
        [ 0.0000,  0.6669, -0.8222]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 15, batches: 40, time: 0.012, data: 8.896) loss_D_real: 0.439 loss_D_fake: 0.412 loss_D: 0.426 loss_G: 1.678 loss_conv: 1.678 acc_real: 0.904 acc_fake: 0.932 
690 tensor([[ 0.6669,  0.0000,  0.8290],
        [ 0.0000,  0.6671, -0.8300]], device='cuda:0',
       grad_fn=<SelectBackward>)
saving the model at the end of epoch 15, iters 44160
learning rate 0.0000160 -> 0.0000160
End of epoch 15 / 30 	 Time Taken: 154 sec
700 tensor([[ 0.6672,  0.0000,  0.6367],
        [ 0.0000,  0.6669, -0.8323]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.91, 0.7734375
                fake: 0.87, 0.2561848958333333

ran validation set (B:701) in                         28.9 s.
710 tensor([[ 0.6682,  0.0000,  0.5875],
        [ 0.0000,  0.6698, -0.3205]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 16, batches: 20, time: 0.027, data: 0.022) loss_D_real: 0.436 loss_D_fake: 0.466 loss_D: 0.451 loss_G: 1.778 loss_conv: 1.778 acc_real: 0.911 acc_fake: 0.877 
720 tensor([[ 0.6708,  0.0000, -0.6776],
        [ 0.0000,  0.6781, -0.7109]], device='cuda:0',
       grad_fn=<SelectBackward>)
730 tensor([[ 0.6682,  0.0000, -0.8054],
        [ 0.0000,  0.6682, -0.8300]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 16, batches: 40, time: 0.026, data: 10.144) loss_D_real: 0.461 loss_D_fake: 0.424 loss_D: 0.443 loss_G: 1.625 loss_conv: 1.625 acc_real: 0.913 acc_fake: 0.922 
learning rate 0.0000160 -> 0.0000160
End of epoch 16 / 30 	 Time Taken: 158 sec
740 tensor([[ 0.6680,  0.0000, -0.8152],
        [ 0.0000,  0.6672, -0.4686]], device='cuda:0',
       grad_fn=<SelectBackward>)
750 tensor([[ 0.6667,  0.0000, -0.3449],
        [ 0.0000,  0.6677, -0.8206]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 17, batches: 20, time: 0.011, data: 0.030) loss_D_real: 0.428 loss_D_fake: 0.505 loss_D: 0.467 loss_G: 1.609 loss_conv: 1.609 acc_real: 0.923 acc_fake: 0.865 
760 tensor([[ 0.6673,  0.0000, -0.8315],
        [ 0.0000,  0.6690, -0.3583]], device='cuda:0',
       grad_fn=<SelectBackward>)
770 tensor([[ 0.6670,  0.0000,  0.7463],
        [ 0.0000,  0.6674, -0.5852]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 17, batches: 40, time: 0.014, data: 0.026) loss_D_real: 0.425 loss_D_fake: 0.496 loss_D: 0.460 loss_G: 1.729 loss_conv: 1.729 acc_real: 0.932 acc_fake: 0.852 
780 tensor([[0.6676, 0.0000, 0.6871],
        [0.0000, 0.6670, 0.0280]], device='cuda:0', grad_fn=<SelectBackward>)
learning rate 0.0000160 -> 0.0000160
End of epoch 17 / 30 	 Time Taken: 152 sec
790 tensor([[ 0.6672,  0.0000,  0.8102],
        [ 0.0000,  0.6670, -0.5696]], device='cuda:0',
       grad_fn=<SelectBackward>)
800 tensor([[ 0.6670,  0.0000,  0.8192],
        [ 0.0000,  0.6672, -0.8287]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.91, 0.7757161458333334
                fake: 0.90, 0.2369384765625

ran validation set (B:801) in                         28.6 s.
(epoch: 18, batches: 20, time: 0.013, data: 0.022) loss_D_real: 0.432 loss_D_fake: 0.417 loss_D: 0.425 loss_G: 1.662 loss_conv: 1.662 acc_real: 0.909 acc_fake: 0.928 
810 tensor([[ 0.6670,  0.0000,  0.0333],
        [ 0.0000,  0.6668, -0.3832]], device='cuda:0',
       grad_fn=<SelectBackward>)
820 tensor([[ 0.6668,  0.0000,  0.6448],
        [ 0.0000,  0.6669, -0.8290]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 18, batches: 40, time: 0.009, data: 0.030) loss_D_real: 0.476 loss_D_fake: 0.414 loss_D: 0.445 loss_G: 1.590 loss_conv: 1.590 acc_real: 0.887 acc_fake: 0.937 
learning rate 0.0000160 -> 0.0000160
End of epoch 18 / 30 	 Time Taken: 159 sec
830 tensor([[ 0.6676,  0.0000, -0.0521],
        [ 0.0000,  0.6693, -0.7986]], device='cuda:0',
       grad_fn=<SelectBackward>)
840 tensor([[ 0.6670,  0.0000, -0.2955],
        [ 0.0000,  0.6668, -0.6260]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 19, batches: 20, time: 0.014, data: 0.031) loss_D_real: 0.418 loss_D_fake: 0.407 loss_D: 0.412 loss_G: 1.705 loss_conv: 1.705 acc_real: 0.930 acc_fake: 0.945 
850 tensor([[ 0.6669,  0.0000,  0.7302],
        [ 0.0000,  0.6671, -0.6887]], device='cuda:0',
       grad_fn=<SelectBackward>)
860 tensor([[ 0.6675,  0.0000, -0.2151],
        [ 0.0000,  0.6686, -0.0586]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 19, batches: 40, time: 0.013, data: 0.361) loss_D_real: 0.468 loss_D_fake: 0.417 loss_D: 0.442 loss_G: 1.795 loss_conv: 1.795 acc_real: 0.871 acc_fake: 0.931 
870 tensor([[ 0.6682,  0.0000,  0.6530],
        [ 0.0000,  0.6680, -0.8160]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000160 -> 0.0000160
End of epoch 19 / 30 	 Time Taken: 151 sec
880 tensor([[ 0.6675,  0.0000,  0.5090],
        [ 0.0000,  0.6672, -0.8218]], device='cuda:0',
       grad_fn=<SelectBackward>)
890 tensor([[ 0.6693,  0.0000, -0.4432],
        [ 0.0000,  0.6672, -0.7608]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 20, batches: 20, time: 0.012, data: 8.907) loss_D_real: 0.419 loss_D_fake: 0.428 loss_D: 0.423 loss_G: 1.786 loss_conv: 1.786 acc_real: 0.940 acc_fake: 0.904 
900 tensor([[ 0.6669,  0.0000, -0.8248],
        [ 0.0000,  0.6671, -0.8315]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.93, 0.7854817708333334
                fake: 0.90, 0.23262532552083334

ran validation set (B:901) in                         28.6 s.
910 tensor([[ 0.6676,  0.0000, -0.4022],
        [ 0.0000,  0.6698, -0.8100]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 20, batches: 40, time: 0.010, data: 0.029) loss_D_real: 0.427 loss_D_fake: 0.417 loss_D: 0.422 loss_G: 2.076 loss_conv: 2.076 acc_real: 0.927 acc_fake: 0.928 
920 tensor([[ 0.6673,  0.0000, -0.5484],
        [ 0.0000,  0.6668, -0.7772]], device='cuda:0',
       grad_fn=<SelectBackward>)
saving the model at the end of epoch 20, iters 58880
learning rate 0.0000160 -> 0.0000128
End of epoch 20 / 30 	 Time Taken: 161 sec
930 tensor([[ 0.6668,  0.0000,  0.7925],
        [ 0.0000,  0.6673, -0.7079]], device='cuda:0',
       grad_fn=<SelectBackward>)
940 tensor([[ 0.6672,  0.0000,  0.6120],
        [ 0.0000,  0.6669, -0.6584]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 21, batches: 20, time: 0.033, data: 0.027) loss_D_real: 0.425 loss_D_fake: 0.441 loss_D: 0.433 loss_G: 1.800 loss_conv: 1.800 acc_real: 0.918 acc_fake: 0.897 
950 tensor([[ 0.6669,  0.0000,  0.2027],
        [ 0.0000,  0.6670, -0.6611]], device='cuda:0',
       grad_fn=<SelectBackward>)
960 tensor([[ 0.6669,  0.0000, -0.2257],
        [ 0.0000,  0.6674, -0.5172]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 21, batches: 40, time: 0.031, data: 0.028) loss_D_real: 0.390 loss_D_fake: 0.445 loss_D: 0.417 loss_G: 1.671 loss_conv: 1.671 acc_real: 0.965 acc_fake: 0.905 
learning rate 0.0000128 -> 0.0000128
End of epoch 21 / 30 	 Time Taken: 152 sec
970 tensor([[ 0.6671,  0.0000,  0.7145],
        [ 0.0000,  0.6668, -0.1933]], device='cuda:0',
       grad_fn=<SelectBackward>)
980 tensor([[ 0.6678,  0.0000, -0.5540],
        [ 0.0000,  0.6677, -0.7703]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 22, batches: 20, time: 0.014, data: 0.022) loss_D_real: 0.381 loss_D_fake: 0.403 loss_D: 0.392 loss_G: 1.647 loss_conv: 1.647 acc_real: 0.971 acc_fake: 0.959 
990 tensor([[ 0.6668,  0.0000,  0.8138],
        [ 0.0000,  0.6667, -0.3338]], device='cuda:0',
       grad_fn=<SelectBackward>)
1000 tensor([[0.6683, 0.0000, 0.8198],
        [0.0000, 0.6681, 0.1176]], device='cuda:0', grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.93, 0.7887369791666666
                fake: 0.91, 0.21110026041666666

ran validation set (B:1001) in                         28.6 s.
(epoch: 22, batches: 40, time: 0.013, data: 0.023) loss_D_real: 0.441 loss_D_fake: 0.431 loss_D: 0.436 loss_G: 1.716 loss_conv: 1.716 acc_real: 0.920 acc_fake: 0.915 
1010 tensor([[ 0.6685,  0.0000, -0.7012],
        [ 0.0000,  0.6692,  0.1041]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000128 -> 0.0000128
End of epoch 22 / 30 	 Time Taken: 160 sec
1020 tensor([[ 0.6669,  0.0000, -0.4438],
        [ 0.0000,  0.6674, -0.0368]], device='cuda:0',
       grad_fn=<SelectBackward>)
1030 tensor([[ 0.6677,  0.0000,  0.1798],
        [ 0.0000,  0.6684, -0.0403]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 23, batches: 20, time: 0.012, data: 0.027) loss_D_real: 0.399 loss_D_fake: 0.441 loss_D: 0.420 loss_G: 1.753 loss_conv: 1.753 acc_real: 0.954 acc_fake: 0.911 
1040 tensor([[0.6670, 0.0000, 0.5325],
        [0.0000, 0.6674, 0.3143]], device='cuda:0', grad_fn=<SelectBackward>)
1050 tensor([[ 0.6670,  0.0000, -0.2056],
        [ 0.0000,  0.6668, -0.4836]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 23, batches: 40, time: 0.014, data: 0.029) loss_D_real: 0.430 loss_D_fake: 0.400 loss_D: 0.415 loss_G: 1.753 loss_conv: 1.753 acc_real: 0.920 acc_fake: 0.946 
learning rate 0.0000128 -> 0.0000128
End of epoch 23 / 30 	 Time Taken: 151 sec
1060 tensor([[ 0.6669,  0.0000, -0.8281],
        [ 0.0000,  0.6676,  0.6084]], device='cuda:0',
       grad_fn=<SelectBackward>)
1070 tensor([[0.6672, 0.0000, 0.6515],
        [0.0000, 0.6667, 0.8106]], device='cuda:0', grad_fn=<SelectBackward>)
(epoch: 24, batches: 20, time: 0.013, data: 0.020) loss_D_real: 0.398 loss_D_fake: 0.432 loss_D: 0.415 loss_G: 1.799 loss_conv: 1.799 acc_real: 0.954 acc_fake: 0.914 
1080 tensor([[ 0.6677,  0.0000, -0.0191],
        [ 0.0000,  0.6667,  0.8287]], device='cuda:0',
       grad_fn=<SelectBackward>)
1090 tensor([[ 0.6671,  0.0000,  0.3245],
        [ 0.0000,  0.6674, -0.7421]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 24, batches: 40, time: 0.012, data: 0.021) loss_D_real: 0.413 loss_D_fake: 0.427 loss_D: 0.420 loss_G: 1.553 loss_conv: 1.553 acc_real: 0.947 acc_fake: 0.920 
1100 tensor([[ 0.6668,  0.0000,  0.8249],
        [ 0.0000,  0.6671, -0.8217]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.95, 0.8131510416666666
                fake: 0.89, 0.2481689453125

ran validation set (B:1101) in                         28.3 s.
learning rate 0.0000128 -> 0.0000128
End of epoch 24 / 30 	 Time Taken: 171 sec
1110 tensor([[ 0.6667,  0.0000, -0.6780],
        [ 0.0000,  0.6671, -0.8079]], device='cuda:0',
       grad_fn=<SelectBackward>)
1120 tensor([[ 0.6669,  0.0000, -0.5302],
        [ 0.0000,  0.6669, -0.8185]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 25, batches: 20, time: 0.014, data: 8.676) loss_D_real: 0.410 loss_D_fake: 0.412 loss_D: 0.411 loss_G: 1.797 loss_conv: 1.797 acc_real: 0.941 acc_fake: 0.931 
1130 tensor([[ 0.6668,  0.0000, -0.7971],
        [ 0.0000,  0.6669, -0.7567]], device='cuda:0',
       grad_fn=<SelectBackward>)
1140 tensor([[ 0.6669,  0.0000,  0.5344],
        [ 0.0000,  0.6668, -0.1815]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 25, batches: 40, time: 0.013, data: 8.384) loss_D_real: 0.439 loss_D_fake: 0.390 loss_D: 0.415 loss_G: 1.693 loss_conv: 1.693 acc_real: 0.906 acc_fake: 0.958 
1150 tensor([[ 0.6668,  0.0000, -0.6737],
        [ 0.0000,  0.6682, -0.8267]], device='cuda:0',
       grad_fn=<SelectBackward>)
saving the model at the end of epoch 25, iters 73600
learning rate 0.0000128 -> 0.0000128
End of epoch 25 / 30 	 Time Taken: 153 sec
1160 tensor([[ 0.6667,  0.0000,  0.6154],
        [ 0.0000,  0.6673, -0.8113]], device='cuda:0',
       grad_fn=<SelectBackward>)
1170 tensor([[ 0.6668,  0.0000,  0.7569],
        [ 0.0000,  0.6668, -0.8257]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 26, batches: 20, time: 0.034, data: 0.021) loss_D_real: 0.423 loss_D_fake: 0.408 loss_D: 0.416 loss_G: 1.753 loss_conv: 1.753 acc_real: 0.932 acc_fake: 0.938 
1180 tensor([[ 0.6674,  0.0000,  0.7992],
        [ 0.0000,  0.6672, -0.8284]], device='cuda:0',
       grad_fn=<SelectBackward>)
1190 tensor([[0.6669, 0.0000, 0.0399],
        [0.0000, 0.6669, 0.2583]], device='cuda:0', grad_fn=<SelectBackward>)
(epoch: 26, batches: 40, time: 0.038, data: 0.024) loss_D_real: 0.383 loss_D_fake: 0.412 loss_D: 0.397 loss_G: 1.863 loss_conv: 1.863 acc_real: 0.977 acc_fake: 0.931 
learning rate 0.0000128 -> 0.0000128
End of epoch 26 / 30 	 Time Taken: 151 sec
1200 tensor([[ 0.6675,  0.0000,  0.6926],
        [ 0.0000,  0.6695, -0.6128]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.95, 0.8186848958333334
                fake: 0.92, 0.21875

ran validation set (B:1201) in                         29.1 s.
1210 tensor([[0.6668, 0.0000, 0.8184],
        [0.0000, 0.6668, 0.8136]], device='cuda:0', grad_fn=<SelectBackward>)
(epoch: 27, batches: 20, time: 0.011, data: 0.121) loss_D_real: 0.451 loss_D_fake: 0.451 loss_D: 0.451 loss_G: 1.740 loss_conv: 1.740 acc_real: 0.891 acc_fake: 0.891 
1220 tensor([[0.6672, 0.0000, 0.2604],
        [0.0000, 0.6667, 0.3553]], device='cuda:0', grad_fn=<SelectBackward>)
1230 tensor([[ 0.6671,  0.0000, -0.7016],
        [ 0.0000,  0.6680, -0.8317]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 27, batches: 40, time: 0.009, data: 0.385) loss_D_real: 0.385 loss_D_fake: 0.466 loss_D: 0.426 loss_G: 1.535 loss_conv: 1.535 acc_real: 0.962 acc_fake: 0.863 
1240 tensor([[ 0.6670,  0.0000, -0.5354],
        [ 0.0000,  0.6672, -0.8110]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000128 -> 0.0000128
End of epoch 27 / 30 	 Time Taken: 168 sec
1250 tensor([[ 0.6667,  0.0000, -0.8123],
        [ 0.0000,  0.6687, -0.7765]], device='cuda:0',
       grad_fn=<SelectBackward>)
1260 tensor([[ 0.6680,  0.0000,  0.7249],
        [ 0.0000,  0.6669, -0.7898]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 28, batches: 20, time: 0.014, data: 0.025) loss_D_real: 0.406 loss_D_fake: 0.385 loss_D: 0.396 loss_G: 1.716 loss_conv: 1.716 acc_real: 0.950 acc_fake: 0.962 
1270 tensor([[ 0.6669,  0.0000, -0.5343],
        [ 0.0000,  0.6669, -0.7040]], device='cuda:0',
       grad_fn=<SelectBackward>)
1280 tensor([[0.6675, 0.0000, 0.8317],
        [0.0000, 0.6669, 0.1346]], device='cuda:0', grad_fn=<SelectBackward>)
(epoch: 28, batches: 40, time: 0.013, data: 0.026) loss_D_real: 0.404 loss_D_fake: 0.436 loss_D: 0.420 loss_G: 1.715 loss_conv: 1.715 acc_real: 0.948 acc_fake: 0.907 
learning rate 0.0000128 -> 0.0000128
End of epoch 28 / 30 	 Time Taken: 151 sec
1290 tensor([[ 0.6670,  0.0000, -0.8304],
        [ 0.0000,  0.6684,  0.1929]], device='cuda:0',
       grad_fn=<SelectBackward>)
1300 tensor([[ 0.6674,  0.0000, -0.3929],
        [ 0.0000,  0.6676, -0.7976]], device='cuda:0',
       grad_fn=<SelectBackward>)
validation accuracies:
                real: 0.94, 0.8040364583333334
                fake: 0.93, 0.19795735677083334

ran validation set (B:1301) in                         29.8 s.
(epoch: 29, batches: 20, time: 0.012, data: 0.020) loss_D_real: 0.396 loss_D_fake: 0.419 loss_D: 0.407 loss_G: 1.694 loss_conv: 1.694 acc_real: 0.949 acc_fake: 0.941 
1310 tensor([[ 0.6670,  0.0000,  0.1868],
        [ 0.0000,  0.6671, -0.7816]], device='cuda:0',
       grad_fn=<SelectBackward>)
1320 tensor([[ 0.6670,  0.0000, -0.0769],
        [ 0.0000,  0.6682, -0.8317]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 29, batches: 40, time: 0.014, data: 9.935) loss_D_real: 0.391 loss_D_fake: 0.397 loss_D: 0.394 loss_G: 1.810 loss_conv: 1.810 acc_real: 0.968 acc_fake: 0.943 
1330 tensor([[ 0.6668,  0.0000,  0.7182],
        [ 0.0000,  0.6668, -0.8267]], device='cuda:0',
       grad_fn=<SelectBackward>)
learning rate 0.0000128 -> 0.0000128
End of epoch 29 / 30 	 Time Taken: 168 sec
1340 tensor([[ 0.6676,  0.0000,  0.8321],
        [ 0.0000,  0.6687, -0.5901]], device='cuda:0',
       grad_fn=<SelectBackward>)
1350 tensor([[ 0.6670,  0.0000,  0.2212],
        [ 0.0000,  0.6669, -0.8244]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 30, batches: 20, time: 0.013, data: 8.302) loss_D_real: 0.426 loss_D_fake: 0.388 loss_D: 0.407 loss_G: 1.743 loss_conv: 1.743 acc_real: 0.919 acc_fake: 0.951 
1360 tensor([[ 0.6679,  0.0000,  0.2138],
        [ 0.0000,  0.6679, -0.7243]], device='cuda:0',
       grad_fn=<SelectBackward>)
1370 tensor([[ 0.6695,  0.0000,  0.8032],
        [ 0.0000,  0.6684, -0.5837]], device='cuda:0',
       grad_fn=<SelectBackward>)
(epoch: 30, batches: 40, time: 0.012, data: 8.259) loss_D_real: 0.424 loss_D_fake: 0.385 loss_D: 0.404 loss_G: 1.870 loss_conv: 1.870 acc_real: 0.922 acc_fake: 0.974 
1380 tensor([[ 0.6683,  0.0000,  0.7102],
        [ 0.0000,  0.6681, -0.4697]], device='cuda:0',
       grad_fn=<SelectBackward>)
saving the model at the end of epoch 30, iters 88320
learning rate 0.0000128 -> 0.0000102
End of epoch 30 / 30 	 Time Taken: 153 sec
Finished training, model is saved (30 epochs in 5433.226087808609s)
Batches trained - G: 920, D: 460 
