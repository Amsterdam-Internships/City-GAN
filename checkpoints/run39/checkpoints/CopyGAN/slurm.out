starting training run 39
----------------- Options ---------------
              D_headstart: 0                             	[default: 80000]
              D_threshold: 0.6                           
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.2                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 70                            
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: False                         
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
----------------- Options ---------------
              D_headstart: 0                             	[default: 80000]
              D_threshold: 0.6                           
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.2                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 70                            
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: False                         
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [DoubleDataset] was created
dataset [DoubleDataset] was created
The number of training images = 15000
The number of epochs to run = 30
initialize network with normal
initialize network with normal
model [CopyPasteGANModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.469 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): GaussianSmoothing()
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (sigmoid): Sigmoid()
    (avg): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=2, padding=0)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=256, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=256, out_features=1, bias=True)
      (5): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 3.600 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 0.00
                real: 1.00
                fake: 0.00

ran validation set (B:1) in                         46.9 s.
(epoch: 1, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.820 loss_D_fake: 0.511 loss_D: 2.302 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.467 loss_D_gr_fake: 0.504 acc_grfake: 0.000 
(epoch: 1, batches: 40, time: 0.008, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.833 loss_D_fake: 0.481 loss_D: 2.258 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.496 loss_D_gr_fake: 0.448 acc_grfake: 0.000 
(epoch: 1, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.776 loss_D_fake: 0.483 loss_D: 2.180 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.519 loss_D_gr_fake: 0.403 acc_grfake: 0.000 
(epoch: 1, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.817 loss_D_fake: 0.383 loss_D: 2.044 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.563 loss_D_gr_fake: 0.282 acc_grfake: 0.000 
(epoch: 1, batches: 100, time: 0.009, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.604 loss_D_fake: 0.534 loss_D: 2.055 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.586 loss_D_gr_fake: 0.332 acc_grfake: 0.000 
validation accuracies:
                gf: 0.95
                real: 0.76
                fake: 0.90

ran validation set (B:101) in                         45.5 s.
(epoch: 1, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.744 loss_G_anti_sc: 0.398 loss_G: 1.505 loss_D_real: 0.620 loss_D_fake: 0.624 loss_D: 2.129 acc_real: 0.762 acc_fake: 0.901 loss_G_conf: 0.363 loss_AUX: 0.582 loss_D_gr_fake: 0.304 acc_grfake: 0.948 
(epoch: 1, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 1.022 loss_G_anti_sc: 0.206 loss_G: 1.567 loss_D_real: 0.587 loss_D_fake: 0.692 loss_D: 2.192 acc_real: 0.762 acc_fake: 0.901 loss_G_conf: 0.339 loss_AUX: 0.601 loss_D_gr_fake: 0.313 acc_grfake: 0.948 
(epoch: 1, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.835 loss_G_anti_sc: 0.254 loss_G: 1.418 loss_D_real: 0.625 loss_D_fake: 0.578 loss_D: 2.128 acc_real: 0.762 acc_fake: 0.901 loss_G_conf: 0.330 loss_AUX: 0.619 loss_D_gr_fake: 0.306 acc_grfake: 0.948 
(epoch: 1, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.684 loss_G_anti_sc: 0.334 loss_G: 1.362 loss_D_real: 0.592 loss_D_fake: 0.727 loss_D: 2.189 acc_real: 0.762 acc_fake: 0.901 loss_G_conf: 0.343 loss_AUX: 0.640 loss_D_gr_fake: 0.231 acc_grfake: 0.948 
(epoch: 1, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.588 loss_G_anti_sc: 0.429 loss_G: 1.357 loss_D_real: 0.658 loss_D_fake: 0.694 loss_D: 2.185 acc_real: 0.762 acc_fake: 0.901 loss_G_conf: 0.340 loss_AUX: 0.661 loss_D_gr_fake: 0.172 acc_grfake: 0.948 
validation accuracies:
                gf: 0.89
                real: 0.95
                fake: 0.31

ran validation set (B:201) in                         45.5 s.
(epoch: 1, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.588 loss_G_anti_sc: 0.429 loss_G: 1.357 loss_D_real: 0.578 loss_D_fake: 0.489 loss_D: 1.901 acc_real: 0.951 acc_fake: 0.309 loss_G_conf: 0.340 loss_AUX: 0.668 loss_D_gr_fake: 0.166 acc_grfake: 0.889 
learning rate 0.0001000 -> 0.0001000
End of epoch 1 / 30 	 Time Taken: 249 sec
(epoch: 2, batches: 20, time: 0.007, data: 0.005) loss_G_comp: 0.588 loss_G_anti_sc: 0.429 loss_G: 1.357 loss_D_real: 0.553 loss_D_fake: 0.588 loss_D: 2.010 acc_real: 0.951 acc_fake: 0.309 loss_G_conf: 0.340 loss_AUX: 0.701 loss_D_gr_fake: 0.168 acc_grfake: 0.889 
(epoch: 2, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.588 loss_G_anti_sc: 0.429 loss_G: 1.357 loss_D_real: 0.603 loss_D_fake: 0.518 loss_D: 2.037 acc_real: 0.951 acc_fake: 0.309 loss_G_conf: 0.340 loss_AUX: 0.729 loss_D_gr_fake: 0.187 acc_grfake: 0.889 
(epoch: 2, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.588 loss_G_anti_sc: 0.429 loss_G: 1.357 loss_D_real: 0.613 loss_D_fake: 0.394 loss_D: 1.878 acc_real: 0.951 acc_fake: 0.309 loss_G_conf: 0.340 loss_AUX: 0.734 loss_D_gr_fake: 0.138 acc_grfake: 0.889 
validation accuracies:
                gf: 0.94
                real: 0.91
                fake: 0.74

ran validation set (B:301) in                         45.6 s.
(epoch: 2, batches: 80, time: 0.006, data: 0.003) loss_G_comp: 0.863 loss_G_anti_sc: 0.164 loss_G: 1.377 loss_D_real: 0.527 loss_D_fake: 1.080 loss_D: 2.718 acc_real: 0.914 acc_fake: 0.736 loss_G_conf: 0.350 loss_AUX: 0.762 loss_D_gr_fake: 0.350 acc_grfake: 0.936 
(epoch: 2, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.613 loss_G_anti_sc: 0.299 loss_G: 1.249 loss_D_real: 0.621 loss_D_fake: 0.910 loss_D: 2.469 acc_real: 0.914 acc_fake: 0.736 loss_G_conf: 0.337 loss_AUX: 0.776 loss_D_gr_fake: 0.162 acc_grfake: 0.936 
(epoch: 2, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.599 loss_G_anti_sc: 0.243 loss_G: 1.172 loss_D_real: 0.570 loss_D_fake: 0.821 loss_D: 2.273 acc_real: 0.914 acc_fake: 0.736 loss_G_conf: 0.330 loss_AUX: 0.762 loss_D_gr_fake: 0.121 acc_grfake: 0.936 
(epoch: 2, batches: 140, time: 0.006, data: 0.004) loss_G_comp: 0.606 loss_G_anti_sc: 0.297 loss_G: 1.236 loss_D_real: 0.622 loss_D_fake: 0.805 loss_D: 2.354 acc_real: 0.914 acc_fake: 0.736 loss_G_conf: 0.332 loss_AUX: 0.770 loss_D_gr_fake: 0.158 acc_grfake: 0.936 
(epoch: 2, batches: 160, time: 0.006, data: 0.004) loss_G_comp: 0.586 loss_G_anti_sc: 0.294 loss_G: 1.211 loss_D_real: 0.600 loss_D_fake: 0.775 loss_D: 2.326 acc_real: 0.914 acc_fake: 0.736 loss_G_conf: 0.332 loss_AUX: 0.760 loss_D_gr_fake: 0.190 acc_grfake: 0.936 
validation accuracies:
                gf: 0.93
                real: 0.92
                fake: 0.25

ran validation set (B:401) in                         45.9 s.
(epoch: 2, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.689 loss_G_anti_sc: 0.180 loss_G: 1.201 loss_D_real: 0.581 loss_D_fake: 0.836 loss_D: 2.345 acc_real: 0.918 acc_fake: 0.246 loss_G_conf: 0.332 loss_AUX: 0.770 loss_D_gr_fake: 0.158 acc_grfake: 0.934 
(epoch: 2, batches: 200, time: 0.007, data: 0.001) loss_G_comp: 0.689 loss_G_anti_sc: 0.180 loss_G: 1.201 loss_D_real: 0.556 loss_D_fake: 0.762 loss_D: 2.156 acc_real: 0.918 acc_fake: 0.246 loss_G_conf: 0.332 loss_AUX: 0.766 loss_D_gr_fake: 0.072 acc_grfake: 0.934 
(epoch: 2, batches: 220, time: 0.007, data: 0.002) loss_G_comp: 0.689 loss_G_anti_sc: 0.180 loss_G: 1.201 loss_D_real: 0.577 loss_D_fake: 0.674 loss_D: 2.150 acc_real: 0.918 acc_fake: 0.246 loss_G_conf: 0.332 loss_AUX: 0.785 loss_D_gr_fake: 0.114 acc_grfake: 0.934 
learning rate 0.0001000 -> 0.0001000
End of epoch 2 / 30 	 Time Taken: 201 sec
(epoch: 3, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.689 loss_G_anti_sc: 0.180 loss_G: 1.201 loss_D_real: 0.558 loss_D_fake: 0.549 loss_D: 1.969 acc_real: 0.918 acc_fake: 0.246 loss_G_conf: 0.332 loss_AUX: 0.803 loss_D_gr_fake: 0.058 acc_grfake: 0.934 
validation accuracies:
                gf: 0.95
                real: 0.90
                fake: 0.63

ran validation set (B:501) in                         45.5 s.
(epoch: 3, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.620 loss_G_anti_sc: 0.278 loss_G: 1.244 loss_D_real: 0.586 loss_D_fake: 0.902 loss_D: 2.412 acc_real: 0.898 acc_fake: 0.632 loss_G_conf: 0.346 loss_AUX: 0.810 loss_D_gr_fake: 0.113 acc_grfake: 0.946 
(epoch: 3, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.809 loss_G_anti_sc: 0.151 loss_G: 1.292 loss_D_real: 0.520 loss_D_fake: 1.050 loss_D: 2.544 acc_real: 0.898 acc_fake: 0.632 loss_G_conf: 0.332 loss_AUX: 0.820 loss_D_gr_fake: 0.154 acc_grfake: 0.946 
(epoch: 3, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.572 loss_G_anti_sc: 0.276 loss_G: 1.188 loss_D_real: 0.585 loss_D_fake: 0.908 loss_D: 2.453 acc_real: 0.898 acc_fake: 0.632 loss_G_conf: 0.340 loss_AUX: 0.815 loss_D_gr_fake: 0.146 acc_grfake: 0.946 
(epoch: 3, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.542 loss_G_anti_sc: 0.418 loss_G: 1.283 loss_D_real: 0.561 loss_D_fake: 1.107 loss_D: 2.573 acc_real: 0.898 acc_fake: 0.632 loss_G_conf: 0.323 loss_AUX: 0.796 loss_D_gr_fake: 0.108 acc_grfake: 0.946 
(epoch: 3, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.706 loss_G_anti_sc: 0.193 loss_G: 1.218 loss_D_real: 0.551 loss_D_fake: 0.969 loss_D: 2.481 acc_real: 0.898 acc_fake: 0.632 loss_G_conf: 0.320 loss_AUX: 0.799 loss_D_gr_fake: 0.162 acc_grfake: 0.946 
validation accuracies:
                gf: 0.93
                real: 0.97
                fake: 0.18

ran validation set (B:601) in                         45.5 s.
(epoch: 3, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.626 loss_G_anti_sc: 0.125 loss_G: 1.062 loss_D_real: 0.561 loss_D_fake: 0.805 loss_D: 2.338 acc_real: 0.970 acc_fake: 0.182 loss_G_conf: 0.312 loss_AUX: 0.816 loss_D_gr_fake: 0.157 acc_grfake: 0.926 
(epoch: 3, batches: 160, time: 0.007, data: 0.002) loss_G_comp: 0.626 loss_G_anti_sc: 0.125 loss_G: 1.062 loss_D_real: 0.539 loss_D_fake: 0.706 loss_D: 2.202 acc_real: 0.970 acc_fake: 0.182 loss_G_conf: 0.312 loss_AUX: 0.816 loss_D_gr_fake: 0.141 acc_grfake: 0.926 
(epoch: 3, batches: 180, time: 0.007, data: 0.005) loss_G_comp: 0.626 loss_G_anti_sc: 0.125 loss_G: 1.062 loss_D_real: 0.523 loss_D_fake: 0.902 loss_D: 2.356 acc_real: 0.970 acc_fake: 0.182 loss_G_conf: 0.312 loss_AUX: 0.812 loss_D_gr_fake: 0.119 acc_grfake: 0.926 
(epoch: 3, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.626 loss_G_anti_sc: 0.125 loss_G: 1.062 loss_D_real: 0.535 loss_D_fake: 0.803 loss_D: 2.323 acc_real: 0.970 acc_fake: 0.182 loss_G_conf: 0.312 loss_AUX: 0.823 loss_D_gr_fake: 0.161 acc_grfake: 0.926 
(epoch: 3, batches: 220, time: 0.007, data: 0.006) loss_G_comp: 0.626 loss_G_anti_sc: 0.125 loss_G: 1.062 loss_D_real: 0.533 loss_D_fake: 0.692 loss_D: 2.184 acc_real: 0.970 acc_fake: 0.182 loss_G_conf: 0.312 loss_AUX: 0.853 loss_D_gr_fake: 0.106 acc_grfake: 0.926 
validation accuracies:
                gf: 0.96
                real: 0.88
                fake: 0.62

ran validation set (B:701) in                         45.5 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 3 / 30 	 Time Taken: 246 sec
(epoch: 4, batches: 20, time: 0.007, data: 0.002) loss_G_comp: 0.640 loss_G_anti_sc: 0.291 loss_G: 1.245 loss_D_real: 0.601 loss_D_fake: 0.747 loss_D: 2.369 acc_real: 0.878 acc_fake: 0.624 loss_G_conf: 0.314 loss_AUX: 0.818 loss_D_gr_fake: 0.203 acc_grfake: 0.957 
(epoch: 4, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.691 loss_G_anti_sc: 0.108 loss_G: 1.106 loss_D_real: 0.533 loss_D_fake: 1.174 loss_D: 2.675 acc_real: 0.878 acc_fake: 0.624 loss_G_conf: 0.307 loss_AUX: 0.785 loss_D_gr_fake: 0.184 acc_grfake: 0.957 
(epoch: 4, batches: 60, time: 0.006, data: 0.003) loss_G_comp: 0.690 loss_G_anti_sc: 0.142 loss_G: 1.136 loss_D_real: 0.528 loss_D_fake: 1.145 loss_D: 2.544 acc_real: 0.878 acc_fake: 0.624 loss_G_conf: 0.304 loss_AUX: 0.766 loss_D_gr_fake: 0.105 acc_grfake: 0.957 
(epoch: 4, batches: 80, time: 0.007, data: 0.011) loss_G_comp: 0.563 loss_G_anti_sc: 0.122 loss_G: 0.986 loss_D_real: 0.560 loss_D_fake: 1.003 loss_D: 2.412 acc_real: 0.878 acc_fake: 0.624 loss_G_conf: 0.300 loss_AUX: 0.742 loss_D_gr_fake: 0.107 acc_grfake: 0.957 
validation accuracies:
                gf: 0.93
                real: 0.94
                fake: 0.17

ran validation set (B:801) in                         45.5 s.
(epoch: 4, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.509 loss_D_fake: 1.239 loss_D: 2.670 acc_real: 0.941 acc_fake: 0.169 loss_G_conf: 0.299 loss_AUX: 0.722 loss_D_gr_fake: 0.199 acc_grfake: 0.930 
(epoch: 4, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.543 loss_D_fake: 0.920 loss_D: 2.291 acc_real: 0.941 acc_fake: 0.169 loss_G_conf: 0.299 loss_AUX: 0.742 loss_D_gr_fake: 0.085 acc_grfake: 0.930 
(epoch: 4, batches: 140, time: 0.008, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.526 loss_D_fake: 0.831 loss_D: 2.229 acc_real: 0.941 acc_fake: 0.169 loss_G_conf: 0.299 loss_AUX: 0.752 loss_D_gr_fake: 0.120 acc_grfake: 0.930 
(epoch: 4, batches: 160, time: 0.008, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.620 loss_D_fake: 0.686 loss_D: 2.148 acc_real: 0.941 acc_fake: 0.169 loss_G_conf: 0.299 loss_AUX: 0.742 loss_D_gr_fake: 0.100 acc_grfake: 0.930 
(epoch: 4, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.559 loss_D_fake: 0.774 loss_D: 2.182 acc_real: 0.941 acc_fake: 0.169 loss_G_conf: 0.299 loss_AUX: 0.754 loss_D_gr_fake: 0.095 acc_grfake: 0.930 
validation accuracies:
                gf: 0.94
                real: 0.97
                fake: 0.48

ran validation set (B:901) in                         45.4 s.
(epoch: 4, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.528 loss_D_fake: 0.755 loss_D: 2.097 acc_real: 0.969 acc_fake: 0.483 loss_G_conf: 0.299 loss_AUX: 0.758 loss_D_gr_fake: 0.057 acc_grfake: 0.935 
(epoch: 4, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.536 loss_D_fake: 0.715 loss_D: 2.146 acc_real: 0.969 acc_fake: 0.483 loss_G_conf: 0.299 loss_AUX: 0.765 loss_D_gr_fake: 0.130 acc_grfake: 0.935 
learning rate 0.0001000 -> 0.0001000
End of epoch 4 / 30 	 Time Taken: 202 sec
(epoch: 5, batches: 20, time: 0.007, data: 0.005) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.531 loss_D_fake: 0.690 loss_D: 2.091 acc_real: 0.969 acc_fake: 0.483 loss_G_conf: 0.299 loss_AUX: 0.769 loss_D_gr_fake: 0.101 acc_grfake: 0.935 
(epoch: 5, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.537 loss_D_fake: 0.543 loss_D: 1.909 acc_real: 0.969 acc_fake: 0.483 loss_G_conf: 0.299 loss_AUX: 0.767 loss_D_gr_fake: 0.063 acc_grfake: 0.935 
(epoch: 5, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.527 loss_D_fake: 0.666 loss_D: 2.135 acc_real: 0.969 acc_fake: 0.483 loss_G_conf: 0.299 loss_AUX: 0.783 loss_D_gr_fake: 0.159 acc_grfake: 0.935 
validation accuracies:
                gf: 0.93
                real: 0.98
                fake: 0.50

ran validation set (B:1001) in                         45.5 s.
(epoch: 5, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.540 loss_D_fake: 0.668 loss_D: 2.114 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.299 loss_AUX: 0.778 loss_D_gr_fake: 0.128 acc_grfake: 0.930 
(epoch: 5, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.540 loss_D_fake: 0.579 loss_D: 2.008 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.299 loss_AUX: 0.782 loss_D_gr_fake: 0.107 acc_grfake: 0.930 
(epoch: 5, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.564 loss_D_fake: 0.475 loss_D: 1.898 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.299 loss_AUX: 0.802 loss_D_gr_fake: 0.057 acc_grfake: 0.930 
(epoch: 5, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.535 loss_D_fake: 0.695 loss_D: 2.122 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.299 loss_AUX: 0.803 loss_D_gr_fake: 0.089 acc_grfake: 0.930 
(epoch: 5, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.652 loss_G_anti_sc: 0.096 loss_G: 1.046 loss_D_real: 0.564 loss_D_fake: 0.500 loss_D: 1.922 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.299 loss_AUX: 0.800 loss_D_gr_fake: 0.058 acc_grfake: 0.930 
validation accuracies:
                gf: 0.94
                real: 0.97
                fake: 0.60

ran validation set (B:1101) in                         45.7 s.
(epoch: 5, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.594 loss_G_anti_sc: 0.156 loss_G: 1.050 loss_D_real: 0.552 loss_D_fake: 1.010 loss_D: 2.541 acc_real: 0.965 acc_fake: 0.602 loss_G_conf: 0.300 loss_AUX: 0.817 loss_D_gr_fake: 0.162 acc_grfake: 0.943 
(epoch: 5, batches: 200, time: 0.008, data: 0.003) loss_G_comp: 0.691 loss_G_anti_sc: 0.064 loss_G: 1.043 loss_D_real: 0.529 loss_D_fake: 0.866 loss_D: 2.314 acc_real: 0.965 acc_fake: 0.602 loss_G_conf: 0.289 loss_AUX: 0.786 loss_D_gr_fake: 0.134 acc_grfake: 0.943 
(epoch: 5, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.728 loss_G_anti_sc: 0.115 loss_G: 1.123 loss_D_real: 0.523 loss_D_fake: 1.125 loss_D: 2.508 acc_real: 0.965 acc_fake: 0.602 loss_G_conf: 0.280 loss_AUX: 0.765 loss_D_gr_fake: 0.095 acc_grfake: 0.943 
saving the model at the end of epoch 5, iters 74880
learning rate 0.0001000 -> 0.0001000
End of epoch 5 / 30 	 Time Taken: 201 sec
(epoch: 6, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.574 loss_G_anti_sc: 0.216 loss_G: 1.047 loss_D_real: 0.517 loss_D_fake: 1.161 loss_D: 2.543 acc_real: 0.965 acc_fake: 0.602 loss_G_conf: 0.258 loss_AUX: 0.683 loss_D_gr_fake: 0.181 acc_grfake: 0.943 
validation accuracies:
                gf: 0.98
                real: 0.54
                fake: 0.62

ran validation set (B:1201) in                         45.6 s.
(epoch: 6, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.605 loss_G_anti_sc: 0.271 loss_G: 1.140 loss_D_real: 0.658 loss_D_fake: 0.755 loss_D: 2.288 acc_real: 0.543 acc_fake: 0.622 loss_G_conf: 0.264 loss_AUX: 0.705 loss_D_gr_fake: 0.171 acc_grfake: 0.979 
(epoch: 6, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.579 loss_G_anti_sc: 0.136 loss_G: 0.970 loss_D_real: 0.564 loss_D_fake: 0.995 loss_D: 2.366 acc_real: 0.543 acc_fake: 0.622 loss_G_conf: 0.255 loss_AUX: 0.682 loss_D_gr_fake: 0.125 acc_grfake: 0.979 
(epoch: 6, batches: 80, time: 0.007, data: 0.005) loss_G_comp: 0.567 loss_G_anti_sc: 0.224 loss_G: 1.034 loss_D_real: 0.536 loss_D_fake: 1.311 loss_D: 2.562 acc_real: 0.543 acc_fake: 0.622 loss_G_conf: 0.243 loss_AUX: 0.652 loss_D_gr_fake: 0.064 acc_grfake: 0.979 
(epoch: 6, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.593 loss_G_anti_sc: 0.150 loss_G: 0.984 loss_D_real: 0.544 loss_D_fake: 1.136 loss_D: 2.433 acc_real: 0.543 acc_fake: 0.622 loss_G_conf: 0.241 loss_AUX: 0.654 loss_D_gr_fake: 0.100 acc_grfake: 0.979 
(epoch: 6, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.578 loss_G_anti_sc: 0.173 loss_G: 0.978 loss_D_real: 0.520 loss_D_fake: 1.299 loss_D: 2.582 acc_real: 0.543 acc_fake: 0.622 loss_G_conf: 0.227 loss_AUX: 0.622 loss_D_gr_fake: 0.142 acc_grfake: 0.979 
validation accuracies:
                gf: 0.93
                real: 0.97
                fake: 0.10

ran validation set (B:1301) in                         45.5 s.
(epoch: 6, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.537 loss_D_fake: 1.120 loss_D: 2.388 acc_real: 0.965 acc_fake: 0.100 loss_G_conf: 0.230 loss_AUX: 0.632 loss_D_gr_fake: 0.100 acc_grfake: 0.933 
(epoch: 6, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.542 loss_D_fake: 0.935 loss_D: 2.179 acc_real: 0.965 acc_fake: 0.100 loss_G_conf: 0.230 loss_AUX: 0.649 loss_D_gr_fake: 0.053 acc_grfake: 0.933 
(epoch: 6, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.533 loss_D_fake: 0.926 loss_D: 2.178 acc_real: 0.965 acc_fake: 0.100 loss_G_conf: 0.230 loss_AUX: 0.639 loss_D_gr_fake: 0.079 acc_grfake: 0.933 
(epoch: 6, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.524 loss_D_fake: 1.028 loss_D: 2.287 acc_real: 0.965 acc_fake: 0.100 loss_G_conf: 0.230 loss_AUX: 0.630 loss_D_gr_fake: 0.105 acc_grfake: 0.933 
(epoch: 6, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.574 loss_D_fake: 0.762 loss_D: 2.097 acc_real: 0.965 acc_fake: 0.100 loss_G_conf: 0.230 loss_AUX: 0.659 loss_D_gr_fake: 0.102 acc_grfake: 0.933 
validation accuracies:
                gf: 0.96
                real: 0.97
                fake: 0.28

ran validation set (B:1401) in                         45.5 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 6 / 30 	 Time Taken: 246 sec
(epoch: 7, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.533 loss_D_fake: 0.910 loss_D: 2.231 acc_real: 0.969 acc_fake: 0.283 loss_G_conf: 0.230 loss_AUX: 0.662 loss_D_gr_fake: 0.125 acc_grfake: 0.955 
(epoch: 7, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.578 loss_D_fake: 0.791 loss_D: 2.103 acc_real: 0.969 acc_fake: 0.283 loss_G_conf: 0.230 loss_AUX: 0.650 loss_D_gr_fake: 0.083 acc_grfake: 0.955 
(epoch: 7, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.508 loss_D_fake: 0.840 loss_D: 2.103 acc_real: 0.969 acc_fake: 0.283 loss_G_conf: 0.230 loss_AUX: 0.672 loss_D_gr_fake: 0.083 acc_grfake: 0.955 
(epoch: 7, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.524 loss_D_fake: 0.768 loss_D: 2.000 acc_real: 0.969 acc_fake: 0.283 loss_G_conf: 0.230 loss_AUX: 0.674 loss_D_gr_fake: 0.034 acc_grfake: 0.955 
validation accuracies:
                gf: 0.95
                real: 0.94
                fake: 0.51

ran validation set (B:1501) in                         45.5 s.
(epoch: 7, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.517 loss_D_fake: 0.882 loss_D: 2.173 acc_real: 0.943 acc_fake: 0.511 loss_G_conf: 0.230 loss_AUX: 0.658 loss_D_gr_fake: 0.117 acc_grfake: 0.951 
(epoch: 7, batches: 120, time: 0.007, data: 0.002) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.536 loss_D_fake: 0.553 loss_D: 1.892 acc_real: 0.943 acc_fake: 0.511 loss_G_conf: 0.230 loss_AUX: 0.688 loss_D_gr_fake: 0.114 acc_grfake: 0.951 
(epoch: 7, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.535 loss_D_fake: 0.660 loss_D: 1.960 acc_real: 0.943 acc_fake: 0.511 loss_G_conf: 0.230 loss_AUX: 0.695 loss_D_gr_fake: 0.071 acc_grfake: 0.951 
(epoch: 7, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.548 loss_D_fake: 0.602 loss_D: 1.904 acc_real: 0.943 acc_fake: 0.511 loss_G_conf: 0.230 loss_AUX: 0.690 loss_D_gr_fake: 0.065 acc_grfake: 0.951 
(epoch: 7, batches: 180, time: 0.007, data: 0.002) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.522 loss_D_fake: 0.664 loss_D: 1.871 acc_real: 0.943 acc_fake: 0.511 loss_G_conf: 0.230 loss_AUX: 0.653 loss_D_gr_fake: 0.033 acc_grfake: 0.951 
validation accuracies:
                gf: 0.93
                real: 0.98
                fake: 0.46

ran validation set (B:1601) in                         45.5 s.
(epoch: 7, batches: 200, time: 0.007, data: 0.001) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.536 loss_D_fake: 0.738 loss_D: 2.024 acc_real: 0.984 acc_fake: 0.458 loss_G_conf: 0.230 loss_AUX: 0.665 loss_D_gr_fake: 0.085 acc_grfake: 0.934 
(epoch: 7, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.542 loss_D_fake: 0.679 loss_D: 2.007 acc_real: 0.984 acc_fake: 0.458 loss_G_conf: 0.230 loss_AUX: 0.701 loss_D_gr_fake: 0.085 acc_grfake: 0.934 
learning rate 0.0001000 -> 0.0001000
End of epoch 7 / 30 	 Time Taken: 201 sec
(epoch: 8, batches: 20, time: 0.008, data: 0.002) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.513 loss_D_fake: 0.739 loss_D: 2.134 acc_real: 0.984 acc_fake: 0.458 loss_G_conf: 0.230 loss_AUX: 0.690 loss_D_gr_fake: 0.193 acc_grfake: 0.934 
(epoch: 8, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.518 loss_D_fake: 0.670 loss_D: 1.912 acc_real: 0.984 acc_fake: 0.458 loss_G_conf: 0.230 loss_AUX: 0.687 loss_D_gr_fake: 0.038 acc_grfake: 0.934 
(epoch: 8, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.522 loss_D_fake: 0.623 loss_D: 1.918 acc_real: 0.984 acc_fake: 0.458 loss_G_conf: 0.230 loss_AUX: 0.685 loss_D_gr_fake: 0.087 acc_grfake: 0.934 
validation accuracies:
                gf: 0.94
                real: 0.98
                fake: 0.53

ran validation set (B:1701) in                         45.9 s.
(epoch: 8, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.524 loss_D_fake: 0.558 loss_D: 1.886 acc_real: 0.984 acc_fake: 0.529 loss_G_conf: 0.230 loss_AUX: 0.718 loss_D_gr_fake: 0.086 acc_grfake: 0.935 
(epoch: 8, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.538 loss_D_fake: 0.625 loss_D: 1.885 acc_real: 0.984 acc_fake: 0.529 loss_G_conf: 0.230 loss_AUX: 0.678 loss_D_gr_fake: 0.043 acc_grfake: 0.935 
(epoch: 8, batches: 120, time: 0.007, data: 0.020) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.523 loss_D_fake: 0.605 loss_D: 1.839 acc_real: 0.984 acc_fake: 0.529 loss_G_conf: 0.230 loss_AUX: 0.673 loss_D_gr_fake: 0.038 acc_grfake: 0.935 
(epoch: 8, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.521 loss_D_fake: 0.562 loss_D: 1.887 acc_real: 0.984 acc_fake: 0.529 loss_G_conf: 0.230 loss_AUX: 0.713 loss_D_gr_fake: 0.090 acc_grfake: 0.935 
(epoch: 8, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.509 loss_D_fake: 0.794 loss_D: 2.076 acc_real: 0.984 acc_fake: 0.529 loss_G_conf: 0.230 loss_AUX: 0.728 loss_D_gr_fake: 0.046 acc_grfake: 0.935 
validation accuracies:
                gf: 0.94
                real: 0.98
                fake: 0.58

ran validation set (B:1801) in                         45.5 s.
(epoch: 8, batches: 180, time: 0.008, data: 0.005) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.526 loss_D_fake: 0.522 loss_D: 1.830 acc_real: 0.984 acc_fake: 0.581 loss_G_conf: 0.230 loss_AUX: 0.733 loss_D_gr_fake: 0.049 acc_grfake: 0.939 
(epoch: 8, batches: 200, time: 0.008, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.506 loss_D_fake: 0.719 loss_D: 2.026 acc_real: 0.984 acc_fake: 0.581 loss_G_conf: 0.230 loss_AUX: 0.702 loss_D_gr_fake: 0.098 acc_grfake: 0.939 
(epoch: 8, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.627 loss_D_fake: 0.572 loss_D: 1.952 acc_real: 0.984 acc_fake: 0.581 loss_G_conf: 0.230 loss_AUX: 0.676 loss_D_gr_fake: 0.077 acc_grfake: 0.939 
learning rate 0.0001000 -> 0.0001000
End of epoch 8 / 30 	 Time Taken: 201 sec
(epoch: 9, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.566 loss_G_anti_sc: 0.173 loss_G: 0.969 loss_D_real: 0.512 loss_D_fake: 0.582 loss_D: 1.952 acc_real: 0.984 acc_fake: 0.581 loss_G_conf: 0.230 loss_AUX: 0.739 loss_D_gr_fake: 0.119 acc_grfake: 0.939 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.69

ran validation set (B:1901) in                         45.5 s.
(epoch: 9, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 1.420 loss_G_anti_sc: 0.101 loss_G: 1.760 loss_D_real: 0.517 loss_D_fake: 1.293 loss_D: 2.720 acc_real: 0.965 acc_fake: 0.689 loss_G_conf: 0.239 loss_AUX: 0.647 loss_D_gr_fake: 0.262 acc_grfake: 0.954 
(epoch: 9, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.687 loss_G_anti_sc: 0.321 loss_G: 1.244 loss_D_real: 0.544 loss_D_fake: 1.059 loss_D: 2.511 acc_real: 0.965 acc_fake: 0.689 loss_G_conf: 0.235 loss_AUX: 0.701 loss_D_gr_fake: 0.206 acc_grfake: 0.954 
(epoch: 9, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.637 loss_G_anti_sc: 0.155 loss_G: 1.021 loss_D_real: 0.535 loss_D_fake: 1.002 loss_D: 2.340 acc_real: 0.965 acc_fake: 0.689 loss_G_conf: 0.229 loss_AUX: 0.672 loss_D_gr_fake: 0.131 acc_grfake: 0.954 
(epoch: 9, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.611 loss_G_anti_sc: 0.172 loss_G: 1.005 loss_D_real: 0.592 loss_D_fake: 1.011 loss_D: 2.440 acc_real: 0.965 acc_fake: 0.689 loss_G_conf: 0.221 loss_AUX: 0.669 loss_D_gr_fake: 0.168 acc_grfake: 0.954 
(epoch: 9, batches: 120, time: 0.006, data: 0.004) loss_G_comp: 0.608 loss_G_anti_sc: 0.183 loss_G: 1.001 loss_D_real: 0.535 loss_D_fake: 1.164 loss_D: 2.445 acc_real: 0.965 acc_fake: 0.689 loss_G_conf: 0.211 loss_AUX: 0.644 loss_D_gr_fake: 0.103 acc_grfake: 0.954 
validation accuracies:
                gf: 0.92
                real: 0.99
                fake: 0.05

ran validation set (B:2001) in                         45.4 s.
(epoch: 9, batches: 140, time: 0.008, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.524 loss_D_fake: 1.029 loss_D: 2.366 acc_real: 0.988 acc_fake: 0.052 loss_G_conf: 0.208 loss_AUX: 0.673 loss_D_gr_fake: 0.140 acc_grfake: 0.921 
(epoch: 9, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.518 loss_D_fake: 1.000 loss_D: 2.203 acc_real: 0.988 acc_fake: 0.052 loss_G_conf: 0.208 loss_AUX: 0.652 loss_D_gr_fake: 0.032 acc_grfake: 0.921 
(epoch: 9, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.531 loss_D_fake: 0.917 loss_D: 2.193 acc_real: 0.988 acc_fake: 0.052 loss_G_conf: 0.208 loss_AUX: 0.661 loss_D_gr_fake: 0.084 acc_grfake: 0.921 
(epoch: 9, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.572 loss_D_fake: 0.756 loss_D: 2.010 acc_real: 0.988 acc_fake: 0.052 loss_G_conf: 0.208 loss_AUX: 0.674 loss_D_gr_fake: 0.008 acc_grfake: 0.921 
(epoch: 9, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.523 loss_D_fake: 0.747 loss_D: 1.969 acc_real: 0.988 acc_fake: 0.052 loss_G_conf: 0.208 loss_AUX: 0.668 loss_D_gr_fake: 0.031 acc_grfake: 0.921 
validation accuracies:
                gf: 0.94
                real: 0.98
                fake: 0.42

ran validation set (B:2101) in                         45.6 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 9 / 30 	 Time Taken: 247 sec
(epoch: 10, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.515 loss_D_fake: 0.832 loss_D: 2.110 acc_real: 0.976 acc_fake: 0.420 loss_G_conf: 0.208 loss_AUX: 0.652 loss_D_gr_fake: 0.111 acc_grfake: 0.938 
(epoch: 10, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.554 loss_D_fake: 0.534 loss_D: 1.813 acc_real: 0.976 acc_fake: 0.420 loss_G_conf: 0.208 loss_AUX: 0.663 loss_D_gr_fake: 0.061 acc_grfake: 0.938 
(epoch: 10, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.520 loss_D_fake: 0.787 loss_D: 2.082 acc_real: 0.976 acc_fake: 0.420 loss_G_conf: 0.208 loss_AUX: 0.671 loss_D_gr_fake: 0.105 acc_grfake: 0.938 
(epoch: 10, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.534 loss_D_fake: 0.730 loss_D: 2.019 acc_real: 0.976 acc_fake: 0.420 loss_G_conf: 0.208 loss_AUX: 0.643 loss_D_gr_fake: 0.112 acc_grfake: 0.938 
validation accuracies:
                gf: 0.95
                real: 0.96
                fake: 0.54

ran validation set (B:2201) in                         45.6 s.
(epoch: 10, batches: 100, time: 0.008, data: 0.001) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.517 loss_D_fake: 0.772 loss_D: 2.168 acc_real: 0.965 acc_fake: 0.538 loss_G_conf: 0.208 loss_AUX: 0.693 loss_D_gr_fake: 0.186 acc_grfake: 0.947 
(epoch: 10, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.516 loss_D_fake: 0.736 loss_D: 2.049 acc_real: 0.965 acc_fake: 0.538 loss_G_conf: 0.208 loss_AUX: 0.692 loss_D_gr_fake: 0.105 acc_grfake: 0.947 
(epoch: 10, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.536 loss_D_fake: 0.640 loss_D: 1.899 acc_real: 0.965 acc_fake: 0.538 loss_G_conf: 0.208 loss_AUX: 0.675 loss_D_gr_fake: 0.047 acc_grfake: 0.947 
(epoch: 10, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.520 loss_D_fake: 0.847 loss_D: 2.143 acc_real: 0.965 acc_fake: 0.538 loss_G_conf: 0.208 loss_AUX: 0.672 loss_D_gr_fake: 0.103 acc_grfake: 0.947 
(epoch: 10, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.559 loss_G_anti_sc: 0.328 loss_G: 1.095 loss_D_real: 0.520 loss_D_fake: 0.617 loss_D: 1.848 acc_real: 0.965 acc_fake: 0.538 loss_G_conf: 0.208 loss_AUX: 0.666 loss_D_gr_fake: 0.046 acc_grfake: 0.947 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.63

ran validation set (B:2301) in                         45.5 s.
(epoch: 10, batches: 200, time: 0.006, data: 0.002) loss_G_comp: 0.766 loss_G_anti_sc: 0.185 loss_G: 1.147 loss_D_real: 0.508 loss_D_fake: 1.133 loss_D: 2.455 acc_real: 0.974 acc_fake: 0.629 loss_G_conf: 0.196 loss_AUX: 0.600 loss_D_gr_fake: 0.214 acc_grfake: 0.949 
(epoch: 10, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.622 loss_G_anti_sc: 0.132 loss_G: 0.967 loss_D_real: 0.519 loss_D_fake: 1.232 loss_D: 2.619 acc_real: 0.974 acc_fake: 0.629 loss_G_conf: 0.212 loss_AUX: 0.643 loss_D_gr_fake: 0.225 acc_grfake: 0.949 
saving the model at the end of epoch 10, iters 149760
learning rate 0.0001000 -> 0.0001000
End of epoch 10 / 30 	 Time Taken: 202 sec
(epoch: 11, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.655 loss_G_anti_sc: 0.129 loss_G: 0.980 loss_D_real: 0.531 loss_D_fake: 1.161 loss_D: 2.433 acc_real: 0.974 acc_fake: 0.629 loss_G_conf: 0.197 loss_AUX: 0.613 loss_D_gr_fake: 0.128 acc_grfake: 0.949 
(epoch: 11, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.528 loss_G_anti_sc: 0.306 loss_G: 1.024 loss_D_real: 0.568 loss_D_fake: 1.059 loss_D: 2.333 acc_real: 0.974 acc_fake: 0.629 loss_G_conf: 0.189 loss_AUX: 0.618 loss_D_gr_fake: 0.089 acc_grfake: 0.949 
(epoch: 11, batches: 60, time: 0.009, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.532 loss_D_fake: 1.173 loss_D: 2.304 acc_real: 0.974 acc_fake: 0.629 loss_G_conf: 0.179 loss_AUX: 0.555 loss_D_gr_fake: 0.044 acc_grfake: 0.949 
validation accuracies:
                gf: 0.91
                real: 1.00
                fake: 0.03

ran validation set (B:2401) in                         45.5 s.
(epoch: 11, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.541 loss_D_fake: 1.116 loss_D: 2.306 acc_real: 0.997 acc_fake: 0.032 loss_G_conf: 0.179 loss_AUX: 0.589 loss_D_gr_fake: 0.060 acc_grfake: 0.908 
(epoch: 11, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.508 loss_D_fake: 1.071 loss_D: 2.314 acc_real: 0.997 acc_fake: 0.032 loss_G_conf: 0.179 loss_AUX: 0.591 loss_D_gr_fake: 0.144 acc_grfake: 0.908 
(epoch: 11, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.522 loss_D_fake: 1.039 loss_D: 2.207 acc_real: 0.997 acc_fake: 0.032 loss_G_conf: 0.179 loss_AUX: 0.591 loss_D_gr_fake: 0.055 acc_grfake: 0.908 
(epoch: 11, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.509 loss_D_fake: 1.137 loss_D: 2.293 acc_real: 0.997 acc_fake: 0.032 loss_G_conf: 0.179 loss_AUX: 0.575 loss_D_gr_fake: 0.072 acc_grfake: 0.908 
(epoch: 11, batches: 160, time: 0.009, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.517 loss_D_fake: 0.907 loss_D: 2.220 acc_real: 0.997 acc_fake: 0.032 loss_G_conf: 0.179 loss_AUX: 0.617 loss_D_gr_fake: 0.178 acc_grfake: 0.908 
validation accuracies:
                gf: 0.94
                real: 0.97
                fake: 0.29

ran validation set (B:2501) in                         45.6 s.
(epoch: 11, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.563 loss_D_fake: 0.802 loss_D: 2.002 acc_real: 0.974 acc_fake: 0.292 loss_G_conf: 0.179 loss_AUX: 0.608 loss_D_gr_fake: 0.028 acc_grfake: 0.943 
(epoch: 11, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.508 loss_D_fake: 1.009 loss_D: 2.239 acc_real: 0.974 acc_fake: 0.292 loss_G_conf: 0.179 loss_AUX: 0.608 loss_D_gr_fake: 0.114 acc_grfake: 0.943 
(epoch: 11, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.524 loss_D_fake: 0.778 loss_D: 1.956 acc_real: 0.974 acc_fake: 0.292 loss_G_conf: 0.179 loss_AUX: 0.627 loss_D_gr_fake: 0.027 acc_grfake: 0.943 
learning rate 0.0001000 -> 0.0001000
End of epoch 11 / 30 	 Time Taken: 200 sec
(epoch: 12, batches: 20, time: 0.008, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.520 loss_D_fake: 0.810 loss_D: 2.084 acc_real: 0.974 acc_fake: 0.292 loss_G_conf: 0.179 loss_AUX: 0.643 loss_D_gr_fake: 0.111 acc_grfake: 0.943 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.30

ran validation set (B:2601) in                         45.5 s.
(epoch: 12, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.508 loss_D_fake: 1.014 loss_D: 2.229 acc_real: 0.991 acc_fake: 0.295 loss_G_conf: 0.179 loss_AUX: 0.593 loss_D_gr_fake: 0.114 acc_grfake: 0.933 
(epoch: 12, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.519 loss_D_fake: 0.982 loss_D: 2.199 acc_real: 0.991 acc_fake: 0.295 loss_G_conf: 0.179 loss_AUX: 0.597 loss_D_gr_fake: 0.101 acc_grfake: 0.933 
(epoch: 12, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.519 loss_D_fake: 0.824 loss_D: 2.037 acc_real: 0.991 acc_fake: 0.295 loss_G_conf: 0.179 loss_AUX: 0.603 loss_D_gr_fake: 0.091 acc_grfake: 0.933 
(epoch: 12, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.506 loss_D_fake: 0.913 loss_D: 2.125 acc_real: 0.991 acc_fake: 0.295 loss_G_conf: 0.179 loss_AUX: 0.610 loss_D_gr_fake: 0.096 acc_grfake: 0.933 
(epoch: 12, batches: 120, time: 0.008, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.514 loss_D_fake: 0.820 loss_D: 2.067 acc_real: 0.991 acc_fake: 0.295 loss_G_conf: 0.179 loss_AUX: 0.629 loss_D_gr_fake: 0.105 acc_grfake: 0.933 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.34

ran validation set (B:2701) in                         45.5 s.
(epoch: 12, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.534 loss_D_fake: 0.836 loss_D: 2.040 acc_real: 0.988 acc_fake: 0.344 loss_G_conf: 0.179 loss_AUX: 0.617 loss_D_gr_fake: 0.054 acc_grfake: 0.948 
(epoch: 12, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.512 loss_D_fake: 0.881 loss_D: 2.132 acc_real: 0.988 acc_fake: 0.344 loss_G_conf: 0.179 loss_AUX: 0.612 loss_D_gr_fake: 0.126 acc_grfake: 0.948 
(epoch: 12, batches: 180, time: 0.008, data: 0.005) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.524 loss_D_fake: 0.859 loss_D: 2.030 acc_real: 0.988 acc_fake: 0.344 loss_G_conf: 0.179 loss_AUX: 0.590 loss_D_gr_fake: 0.057 acc_grfake: 0.948 
(epoch: 12, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.508 loss_D_fake: 0.942 loss_D: 2.128 acc_real: 0.988 acc_fake: 0.344 loss_G_conf: 0.179 loss_AUX: 0.618 loss_D_gr_fake: 0.060 acc_grfake: 0.948 
(epoch: 12, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.509 loss_D_fake: 0.863 loss_D: 2.052 acc_real: 0.988 acc_fake: 0.344 loss_G_conf: 0.179 loss_AUX: 0.621 loss_D_gr_fake: 0.059 acc_grfake: 0.948 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.45

ran validation set (B:2801) in                         45.4 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 12 / 30 	 Time Taken: 247 sec
(epoch: 13, batches: 20, time: 0.008, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.513 loss_D_fake: 0.919 loss_D: 2.080 acc_real: 0.989 acc_fake: 0.454 loss_G_conf: 0.179 loss_AUX: 0.599 loss_D_gr_fake: 0.049 acc_grfake: 0.939 
(epoch: 13, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.532 loss_D_fake: 0.680 loss_D: 1.931 acc_real: 0.989 acc_fake: 0.454 loss_G_conf: 0.179 loss_AUX: 0.650 loss_D_gr_fake: 0.070 acc_grfake: 0.939 
(epoch: 13, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.514 loss_D_fake: 0.769 loss_D: 1.971 acc_real: 0.989 acc_fake: 0.454 loss_G_conf: 0.179 loss_AUX: 0.596 loss_D_gr_fake: 0.091 acc_grfake: 0.939 
(epoch: 13, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.524 loss_D_fake: 0.665 loss_D: 1.843 acc_real: 0.989 acc_fake: 0.454 loss_G_conf: 0.179 loss_AUX: 0.612 loss_D_gr_fake: 0.042 acc_grfake: 0.939 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.43

ran validation set (B:2901) in                         45.5 s.
(epoch: 13, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.560 loss_D_fake: 0.812 loss_D: 2.135 acc_real: 0.991 acc_fake: 0.429 loss_G_conf: 0.179 loss_AUX: 0.620 loss_D_gr_fake: 0.143 acc_grfake: 0.940 
(epoch: 13, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.518 loss_D_fake: 0.826 loss_D: 2.142 acc_real: 0.991 acc_fake: 0.429 loss_G_conf: 0.179 loss_AUX: 0.629 loss_D_gr_fake: 0.169 acc_grfake: 0.940 
(epoch: 13, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.517 loss_D_fake: 0.713 loss_D: 1.925 acc_real: 0.991 acc_fake: 0.429 loss_G_conf: 0.179 loss_AUX: 0.610 loss_D_gr_fake: 0.085 acc_grfake: 0.940 
(epoch: 13, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.505 loss_D_fake: 0.995 loss_D: 2.152 acc_real: 0.991 acc_fake: 0.429 loss_G_conf: 0.179 loss_AUX: 0.605 loss_D_gr_fake: 0.047 acc_grfake: 0.940 
(epoch: 13, batches: 180, time: 0.008, data: 0.001) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.530 loss_D_fake: 0.682 loss_D: 1.931 acc_real: 0.991 acc_fake: 0.429 loss_G_conf: 0.179 loss_AUX: 0.647 loss_D_gr_fake: 0.072 acc_grfake: 0.940 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.35

ran validation set (B:3001) in                         45.5 s.
(epoch: 13, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.522 loss_D_fake: 0.694 loss_D: 1.920 acc_real: 0.992 acc_fake: 0.353 loss_G_conf: 0.179 loss_AUX: 0.621 loss_D_gr_fake: 0.083 acc_grfake: 0.939 
(epoch: 13, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.520 loss_D_fake: 0.838 loss_D: 2.015 acc_real: 0.992 acc_fake: 0.353 loss_G_conf: 0.179 loss_AUX: 0.588 loss_D_gr_fake: 0.070 acc_grfake: 0.939 
learning rate 0.0001000 -> 0.0001000
End of epoch 13 / 30 	 Time Taken: 202 sec
(epoch: 14, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.517 loss_D_fake: 0.788 loss_D: 1.981 acc_real: 0.992 acc_fake: 0.353 loss_G_conf: 0.179 loss_AUX: 0.624 loss_D_gr_fake: 0.052 acc_grfake: 0.939 
(epoch: 14, batches: 40, time: 0.007, data: 0.005) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.520 loss_D_fake: 0.738 loss_D: 2.019 acc_real: 0.992 acc_fake: 0.353 loss_G_conf: 0.179 loss_AUX: 0.623 loss_D_gr_fake: 0.138 acc_grfake: 0.939 
validation accuracies:
                gf: 0.96
                real: 0.96
                fake: 0.55

ran validation set (B:3101) in                         45.5 s.
(epoch: 14, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.513 loss_D_fake: 0.773 loss_D: 1.976 acc_real: 0.961 acc_fake: 0.548 loss_G_conf: 0.179 loss_AUX: 0.623 loss_D_gr_fake: 0.066 acc_grfake: 0.962 
(epoch: 14, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.522 loss_D_fake: 0.708 loss_D: 1.956 acc_real: 0.961 acc_fake: 0.548 loss_G_conf: 0.179 loss_AUX: 0.658 loss_D_gr_fake: 0.068 acc_grfake: 0.962 
(epoch: 14, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.507 loss_D_fake: 0.992 loss_D: 2.158 acc_real: 0.961 acc_fake: 0.548 loss_G_conf: 0.179 loss_AUX: 0.591 loss_D_gr_fake: 0.068 acc_grfake: 0.962 
(epoch: 14, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.508 loss_D_fake: 0.861 loss_D: 2.030 acc_real: 0.961 acc_fake: 0.548 loss_G_conf: 0.179 loss_AUX: 0.608 loss_D_gr_fake: 0.054 acc_grfake: 0.962 
(epoch: 14, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.512 loss_D_fake: 0.748 loss_D: 1.937 acc_real: 0.961 acc_fake: 0.548 loss_G_conf: 0.179 loss_AUX: 0.626 loss_D_gr_fake: 0.052 acc_grfake: 0.962 
validation accuracies:
                gf: 0.95
                real: 0.95
                fake: 0.56

ran validation set (B:3201) in                         45.6 s.
(epoch: 14, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.538 loss_D_fake: 0.714 loss_D: 1.903 acc_real: 0.952 acc_fake: 0.560 loss_G_conf: 0.179 loss_AUX: 0.625 loss_D_gr_fake: 0.027 acc_grfake: 0.955 
(epoch: 14, batches: 180, time: 0.007, data: 0.002) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.510 loss_D_fake: 0.590 loss_D: 1.834 acc_real: 0.952 acc_fake: 0.560 loss_G_conf: 0.179 loss_AUX: 0.642 loss_D_gr_fake: 0.092 acc_grfake: 0.955 
(epoch: 14, batches: 200, time: 0.007, data: 0.006) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.507 loss_D_fake: 0.796 loss_D: 2.058 acc_real: 0.952 acc_fake: 0.560 loss_G_conf: 0.179 loss_AUX: 0.615 loss_D_gr_fake: 0.139 acc_grfake: 0.955 
(epoch: 14, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.512 loss_D_fake: 0.623 loss_D: 1.801 acc_real: 0.952 acc_fake: 0.560 loss_G_conf: 0.179 loss_AUX: 0.635 loss_D_gr_fake: 0.030 acc_grfake: 0.955 
learning rate 0.0001000 -> 0.0001000
End of epoch 14 / 30 	 Time Taken: 202 sec
(epoch: 15, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.532 loss_G_anti_sc: 0.300 loss_G: 1.011 loss_D_real: 0.509 loss_D_fake: 0.667 loss_D: 1.917 acc_real: 0.952 acc_fake: 0.560 loss_G_conf: 0.179 loss_AUX: 0.652 loss_D_gr_fake: 0.089 acc_grfake: 0.955 
validation accuracies:
                gf: 0.95
                real: 0.94
                fake: 0.66

ran validation set (B:3301) in                         45.4 s.
(epoch: 15, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.857 loss_G_anti_sc: 0.152 loss_G: 1.211 loss_D_real: 0.538 loss_D_fake: 1.099 loss_D: 2.650 acc_real: 0.942 acc_fake: 0.665 loss_G_conf: 0.203 loss_AUX: 0.655 loss_D_gr_fake: 0.358 acc_grfake: 0.951 
(epoch: 15, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.524 loss_G_anti_sc: 0.392 loss_G: 1.104 loss_D_real: 0.678 loss_D_fake: 0.710 loss_D: 2.083 acc_real: 0.942 acc_fake: 0.665 loss_G_conf: 0.188 loss_AUX: 0.608 loss_D_gr_fake: 0.087 acc_grfake: 0.951 
(epoch: 15, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.664 loss_G_anti_sc: 0.085 loss_G: 0.932 loss_D_real: 0.526 loss_D_fake: 1.229 loss_D: 2.444 acc_real: 0.942 acc_fake: 0.665 loss_G_conf: 0.183 loss_AUX: 0.603 loss_D_gr_fake: 0.087 acc_grfake: 0.951 
(epoch: 15, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.535 loss_G_anti_sc: 0.168 loss_G: 0.884 loss_D_real: 0.538 loss_D_fake: 1.064 loss_D: 2.262 acc_real: 0.942 acc_fake: 0.665 loss_G_conf: 0.182 loss_AUX: 0.599 loss_D_gr_fake: 0.061 acc_grfake: 0.951 
(epoch: 15, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.585 loss_G_anti_sc: 0.232 loss_G: 0.991 loss_D_real: 0.602 loss_D_fake: 1.029 loss_D: 2.324 acc_real: 0.942 acc_fake: 0.665 loss_G_conf: 0.174 loss_AUX: 0.587 loss_D_gr_fake: 0.106 acc_grfake: 0.951 
validation accuracies:
                gf: 0.95
                real: 0.94
                fake: 0.16

ran validation set (B:3401) in                         45.4 s.
(epoch: 15, batches: 140, time: 0.007, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.543 loss_D_fake: 1.090 loss_D: 2.309 acc_real: 0.944 acc_fake: 0.163 loss_G_conf: 0.178 loss_AUX: 0.608 loss_D_gr_fake: 0.067 acc_grfake: 0.948 
(epoch: 15, batches: 160, time: 0.007, data: 0.001) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.510 loss_D_fake: 1.101 loss_D: 2.306 acc_real: 0.944 acc_fake: 0.163 loss_G_conf: 0.178 loss_AUX: 0.589 loss_D_gr_fake: 0.106 acc_grfake: 0.948 
(epoch: 15, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.528 loss_D_fake: 0.907 loss_D: 2.119 acc_real: 0.944 acc_fake: 0.163 loss_G_conf: 0.178 loss_AUX: 0.635 loss_D_gr_fake: 0.049 acc_grfake: 0.948 
(epoch: 15, batches: 200, time: 0.008, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.509 loss_D_fake: 1.014 loss_D: 2.238 acc_real: 0.944 acc_fake: 0.163 loss_G_conf: 0.178 loss_AUX: 0.622 loss_D_gr_fake: 0.093 acc_grfake: 0.948 
(epoch: 15, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.512 loss_D_fake: 1.010 loss_D: 2.259 acc_real: 0.944 acc_fake: 0.163 loss_G_conf: 0.178 loss_AUX: 0.618 loss_D_gr_fake: 0.119 acc_grfake: 0.948 
validation accuracies:
                gf: 0.94
                real: 0.98
                fake: 0.35

ran validation set (B:3501) in                         45.4 s.
saving the model at the end of epoch 15, iters 224640
learning rate 0.0001000 -> 0.0001000
End of epoch 15 / 30 	 Time Taken: 248 sec
(epoch: 16, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.509 loss_D_fake: 0.984 loss_D: 2.200 acc_real: 0.977 acc_fake: 0.352 loss_G_conf: 0.178 loss_AUX: 0.598 loss_D_gr_fake: 0.109 acc_grfake: 0.945 
(epoch: 16, batches: 40, time: 0.007, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.519 loss_D_fake: 0.793 loss_D: 1.948 acc_real: 0.977 acc_fake: 0.352 loss_G_conf: 0.178 loss_AUX: 0.592 loss_D_gr_fake: 0.045 acc_grfake: 0.945 
(epoch: 16, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.513 loss_D_fake: 0.877 loss_D: 2.052 acc_real: 0.977 acc_fake: 0.352 loss_G_conf: 0.178 loss_AUX: 0.612 loss_D_gr_fake: 0.049 acc_grfake: 0.945 
(epoch: 16, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.512 loss_D_fake: 0.800 loss_D: 1.990 acc_real: 0.977 acc_fake: 0.352 loss_G_conf: 0.178 loss_AUX: 0.609 loss_D_gr_fake: 0.069 acc_grfake: 0.945 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.45

ran validation set (B:3601) in                         45.4 s.
(epoch: 16, batches: 100, time: 0.007, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.528 loss_D_fake: 0.700 loss_D: 1.933 acc_real: 0.966 acc_fake: 0.452 loss_G_conf: 0.178 loss_AUX: 0.626 loss_D_gr_fake: 0.079 acc_grfake: 0.950 
(epoch: 16, batches: 120, time: 0.008, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.513 loss_D_fake: 0.814 loss_D: 2.038 acc_real: 0.966 acc_fake: 0.452 loss_G_conf: 0.178 loss_AUX: 0.618 loss_D_gr_fake: 0.093 acc_grfake: 0.950 
(epoch: 16, batches: 140, time: 0.008, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.507 loss_D_fake: 0.845 loss_D: 2.083 acc_real: 0.966 acc_fake: 0.452 loss_G_conf: 0.178 loss_AUX: 0.636 loss_D_gr_fake: 0.095 acc_grfake: 0.950 
(epoch: 16, batches: 160, time: 0.008, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.512 loss_D_fake: 0.786 loss_D: 2.005 acc_real: 0.966 acc_fake: 0.452 loss_G_conf: 0.178 loss_AUX: 0.636 loss_D_gr_fake: 0.070 acc_grfake: 0.950 
(epoch: 16, batches: 180, time: 0.008, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.517 loss_D_fake: 0.743 loss_D: 1.927 acc_real: 0.966 acc_fake: 0.452 loss_G_conf: 0.178 loss_AUX: 0.630 loss_D_gr_fake: 0.037 acc_grfake: 0.950 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.56

ran validation set (B:3701) in                         45.4 s.
(epoch: 16, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.504 loss_D_fake: 0.817 loss_D: 2.034 acc_real: 0.985 acc_fake: 0.561 loss_G_conf: 0.178 loss_AUX: 0.617 loss_D_gr_fake: 0.096 acc_grfake: 0.959 
(epoch: 16, batches: 220, time: 0.007, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.521 loss_D_fake: 0.649 loss_D: 1.870 acc_real: 0.985 acc_fake: 0.561 loss_G_conf: 0.178 loss_AUX: 0.657 loss_D_gr_fake: 0.043 acc_grfake: 0.959 
learning rate 0.0001000 -> 0.0001000
End of epoch 16 / 30 	 Time Taken: 204 sec
(epoch: 17, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.507 loss_D_fake: 0.704 loss_D: 1.940 acc_real: 0.985 acc_fake: 0.561 loss_G_conf: 0.178 loss_AUX: 0.607 loss_D_gr_fake: 0.122 acc_grfake: 0.959 
(epoch: 17, batches: 40, time: 0.007, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.566 loss_D_fake: 0.547 loss_D: 1.786 acc_real: 0.985 acc_fake: 0.561 loss_G_conf: 0.178 loss_AUX: 0.621 loss_D_gr_fake: 0.053 acc_grfake: 0.959 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.47

ran validation set (B:3801) in                         45.4 s.
(epoch: 17, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.508 loss_D_fake: 0.645 loss_D: 1.853 acc_real: 0.992 acc_fake: 0.466 loss_G_conf: 0.178 loss_AUX: 0.620 loss_D_gr_fake: 0.080 acc_grfake: 0.943 
(epoch: 17, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.513 loss_D_fake: 0.676 loss_D: 1.858 acc_real: 0.992 acc_fake: 0.466 loss_G_conf: 0.178 loss_AUX: 0.610 loss_D_gr_fake: 0.059 acc_grfake: 0.943 
(epoch: 17, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.512 loss_D_fake: 0.651 loss_D: 1.856 acc_real: 0.992 acc_fake: 0.466 loss_G_conf: 0.178 loss_AUX: 0.633 loss_D_gr_fake: 0.059 acc_grfake: 0.943 
(epoch: 17, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.512 loss_D_fake: 0.733 loss_D: 1.932 acc_real: 0.992 acc_fake: 0.466 loss_G_conf: 0.178 loss_AUX: 0.627 loss_D_gr_fake: 0.060 acc_grfake: 0.943 
(epoch: 17, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.530 loss_D_fake: 0.577 loss_D: 1.749 acc_real: 0.992 acc_fake: 0.466 loss_G_conf: 0.178 loss_AUX: 0.617 loss_D_gr_fake: 0.026 acc_grfake: 0.943 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.53

ran validation set (B:3901) in                         45.4 s.
(epoch: 17, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.504 loss_D_fake: 0.813 loss_D: 2.040 acc_real: 0.995 acc_fake: 0.525 loss_G_conf: 0.178 loss_AUX: 0.599 loss_D_gr_fake: 0.124 acc_grfake: 0.940 
(epoch: 17, batches: 180, time: 0.009, data: 0.024) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.507 loss_D_fake: 0.656 loss_D: 1.924 acc_real: 0.995 acc_fake: 0.525 loss_G_conf: 0.178 loss_AUX: 0.624 loss_D_gr_fake: 0.137 acc_grfake: 0.940 
(epoch: 17, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.559 loss_D_fake: 0.550 loss_D: 1.828 acc_real: 0.995 acc_fake: 0.525 loss_G_conf: 0.178 loss_AUX: 0.632 loss_D_gr_fake: 0.086 acc_grfake: 0.940 
(epoch: 17, batches: 220, time: 0.007, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.511 loss_D_fake: 0.625 loss_D: 1.831 acc_real: 0.995 acc_fake: 0.525 loss_G_conf: 0.178 loss_AUX: 0.631 loss_D_gr_fake: 0.064 acc_grfake: 0.940 
learning rate 0.0001000 -> 0.0001000
End of epoch 17 / 30 	 Time Taken: 201 sec
(epoch: 18, batches: 20, time: 0.007, data: 0.005) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.511 loss_D_fake: 0.639 loss_D: 1.853 acc_real: 0.995 acc_fake: 0.525 loss_G_conf: 0.178 loss_AUX: 0.627 loss_D_gr_fake: 0.077 acc_grfake: 0.940 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.55

ran validation set (B:4001) in                         45.4 s.
(epoch: 18, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.541 loss_D_fake: 0.531 loss_D: 1.760 acc_real: 0.989 acc_fake: 0.548 loss_G_conf: 0.178 loss_AUX: 0.627 loss_D_gr_fake: 0.061 acc_grfake: 0.953 
(epoch: 18, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.514 loss_D_fake: 0.707 loss_D: 1.929 acc_real: 0.989 acc_fake: 0.548 loss_G_conf: 0.178 loss_AUX: 0.613 loss_D_gr_fake: 0.095 acc_grfake: 0.953 
(epoch: 18, batches: 80, time: 0.007, data: 0.017) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.508 loss_D_fake: 0.661 loss_D: 1.962 acc_real: 0.989 acc_fake: 0.548 loss_G_conf: 0.178 loss_AUX: 0.656 loss_D_gr_fake: 0.138 acc_grfake: 0.953 
(epoch: 18, batches: 100, time: 0.008, data: 0.002) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.514 loss_D_fake: 0.584 loss_D: 1.757 acc_real: 0.989 acc_fake: 0.548 loss_G_conf: 0.178 loss_AUX: 0.627 loss_D_gr_fake: 0.032 acc_grfake: 0.953 
(epoch: 18, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.643 loss_G_anti_sc: 0.084 loss_G: 0.905 loss_D_real: 0.521 loss_D_fake: 0.613 loss_D: 1.831 acc_real: 0.989 acc_fake: 0.548 loss_G_conf: 0.178 loss_AUX: 0.647 loss_D_gr_fake: 0.050 acc_grfake: 0.953 
validation accuracies:
                gf: 0.95
                real: 0.96
                fake: 0.67

ran validation set (B:4101) in                         45.4 s.
(epoch: 18, batches: 140, time: 0.007, data: 0.001) loss_G_comp: 0.630 loss_G_anti_sc: 0.418 loss_G: 1.243 loss_D_real: 0.938 loss_D_fake: 0.414 loss_D: 2.037 acc_real: 0.963 acc_fake: 0.671 loss_G_conf: 0.195 loss_AUX: 0.615 loss_D_gr_fake: 0.069 acc_grfake: 0.952 
(epoch: 18, batches: 160, time: 0.008, data: 0.001) loss_G_comp: 0.609 loss_G_anti_sc: 0.165 loss_G: 0.952 loss_D_real: 0.534 loss_D_fake: 1.119 loss_D: 2.379 acc_real: 0.963 acc_fake: 0.671 loss_G_conf: 0.178 loss_AUX: 0.583 loss_D_gr_fake: 0.144 acc_grfake: 0.952 
(epoch: 18, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.687 loss_G_anti_sc: 0.145 loss_G: 1.005 loss_D_real: 0.538 loss_D_fake: 1.088 loss_D: 2.325 acc_real: 0.963 acc_fake: 0.671 loss_G_conf: 0.173 loss_AUX: 0.635 loss_D_gr_fake: 0.064 acc_grfake: 0.952 
(epoch: 18, batches: 200, time: 0.008, data: 0.003) loss_G_comp: 0.545 loss_G_anti_sc: 0.195 loss_G: 0.908 loss_D_real: 0.508 loss_D_fake: 1.324 loss_D: 2.559 acc_real: 0.963 acc_fake: 0.671 loss_G_conf: 0.168 loss_AUX: 0.582 loss_D_gr_fake: 0.146 acc_grfake: 0.952 
(epoch: 18, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.196 loss_G: 0.905 loss_D_real: 0.521 loss_D_fake: 1.199 loss_D: 2.356 acc_real: 0.963 acc_fake: 0.671 loss_G_conf: 0.170 loss_AUX: 0.581 loss_D_gr_fake: 0.055 acc_grfake: 0.952 
validation accuracies:
                gf: 0.95
                real: 0.92
                fake: 0.20

ran validation set (B:4201) in                         45.5 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 18 / 30 	 Time Taken: 249 sec
(epoch: 19, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.523 loss_D_fake: 1.031 loss_D: 2.230 acc_real: 0.918 acc_fake: 0.201 loss_G_conf: 0.176 loss_AUX: 0.607 loss_D_gr_fake: 0.070 acc_grfake: 0.951 
(epoch: 19, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.519 loss_D_fake: 0.922 loss_D: 2.157 acc_real: 0.918 acc_fake: 0.201 loss_G_conf: 0.176 loss_AUX: 0.624 loss_D_gr_fake: 0.092 acc_grfake: 0.951 
(epoch: 19, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.519 loss_D_fake: 0.867 loss_D: 2.057 acc_real: 0.918 acc_fake: 0.201 loss_G_conf: 0.176 loss_AUX: 0.626 loss_D_gr_fake: 0.046 acc_grfake: 0.951 
(epoch: 19, batches: 80, time: 0.008, data: 0.001) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.528 loss_D_fake: 0.761 loss_D: 1.945 acc_real: 0.918 acc_fake: 0.201 loss_G_conf: 0.176 loss_AUX: 0.598 loss_D_gr_fake: 0.058 acc_grfake: 0.951 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.31

ran validation set (B:4301) in                         45.4 s.
(epoch: 19, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.567 loss_D_fake: 0.718 loss_D: 1.957 acc_real: 0.993 acc_fake: 0.305 loss_G_conf: 0.176 loss_AUX: 0.630 loss_D_gr_fake: 0.043 acc_grfake: 0.945 
(epoch: 19, batches: 120, time: 0.009, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.524 loss_D_fake: 0.800 loss_D: 1.966 acc_real: 0.993 acc_fake: 0.305 loss_G_conf: 0.176 loss_AUX: 0.605 loss_D_gr_fake: 0.037 acc_grfake: 0.945 
(epoch: 19, batches: 140, time: 0.007, data: 0.001) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.517 loss_D_fake: 0.797 loss_D: 2.035 acc_real: 0.993 acc_fake: 0.305 loss_G_conf: 0.176 loss_AUX: 0.680 loss_D_gr_fake: 0.041 acc_grfake: 0.945 
(epoch: 19, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.531 loss_D_fake: 0.672 loss_D: 1.868 acc_real: 0.993 acc_fake: 0.305 loss_G_conf: 0.176 loss_AUX: 0.620 loss_D_gr_fake: 0.045 acc_grfake: 0.945 
(epoch: 19, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.517 loss_D_fake: 0.899 loss_D: 2.066 acc_real: 0.993 acc_fake: 0.305 loss_G_conf: 0.176 loss_AUX: 0.589 loss_D_gr_fake: 0.062 acc_grfake: 0.945 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.39

ran validation set (B:4401) in                         45.5 s.
(epoch: 19, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.514 loss_D_fake: 0.826 loss_D: 1.979 acc_real: 0.991 acc_fake: 0.388 loss_G_conf: 0.176 loss_AUX: 0.612 loss_D_gr_fake: 0.028 acc_grfake: 0.948 
(epoch: 19, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.509 loss_D_fake: 0.883 loss_D: 2.128 acc_real: 0.991 acc_fake: 0.388 loss_G_conf: 0.176 loss_AUX: 0.624 loss_D_gr_fake: 0.111 acc_grfake: 0.948 
learning rate 0.0001000 -> 0.0001000
End of epoch 19 / 30 	 Time Taken: 202 sec
(epoch: 20, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.524 loss_D_fake: 0.620 loss_D: 1.834 acc_real: 0.991 acc_fake: 0.388 loss_G_conf: 0.176 loss_AUX: 0.609 loss_D_gr_fake: 0.081 acc_grfake: 0.948 
(epoch: 20, batches: 40, time: 0.007, data: 0.005) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.531 loss_D_fake: 0.624 loss_D: 1.793 acc_real: 0.991 acc_fake: 0.388 loss_G_conf: 0.176 loss_AUX: 0.614 loss_D_gr_fake: 0.024 acc_grfake: 0.948 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.50

ran validation set (B:4501) in                         45.5 s.
(epoch: 20, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.522 loss_D_fake: 0.753 loss_D: 1.959 acc_real: 0.989 acc_fake: 0.504 loss_G_conf: 0.176 loss_AUX: 0.638 loss_D_gr_fake: 0.047 acc_grfake: 0.943 
(epoch: 20, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.504 loss_D_fake: 0.718 loss_D: 1.911 acc_real: 0.989 acc_fake: 0.504 loss_G_conf: 0.176 loss_AUX: 0.619 loss_D_gr_fake: 0.069 acc_grfake: 0.943 
(epoch: 20, batches: 100, time: 0.008, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.508 loss_D_fake: 0.710 loss_D: 1.849 acc_real: 0.989 acc_fake: 0.504 loss_G_conf: 0.176 loss_AUX: 0.602 loss_D_gr_fake: 0.029 acc_grfake: 0.943 
(epoch: 20, batches: 120, time: 0.008, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.517 loss_D_fake: 0.661 loss_D: 1.980 acc_real: 0.989 acc_fake: 0.504 loss_G_conf: 0.176 loss_AUX: 0.646 loss_D_gr_fake: 0.157 acc_grfake: 0.943 
(epoch: 20, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.556 loss_D_fake: 0.501 loss_D: 1.708 acc_real: 0.989 acc_fake: 0.504 loss_G_conf: 0.176 loss_AUX: 0.621 loss_D_gr_fake: 0.030 acc_grfake: 0.943 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.41

ran validation set (B:4601) in                         45.4 s.
(epoch: 20, batches: 160, time: 0.007, data: 0.005) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.507 loss_D_fake: 0.851 loss_D: 2.081 acc_real: 0.993 acc_fake: 0.413 loss_G_conf: 0.176 loss_AUX: 0.622 loss_D_gr_fake: 0.101 acc_grfake: 0.945 
(epoch: 20, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.518 loss_D_fake: 0.739 loss_D: 1.989 acc_real: 0.993 acc_fake: 0.413 loss_G_conf: 0.176 loss_AUX: 0.634 loss_D_gr_fake: 0.098 acc_grfake: 0.945 
(epoch: 20, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.507 loss_D_fake: 0.694 loss_D: 1.903 acc_real: 0.993 acc_fake: 0.413 loss_G_conf: 0.176 loss_AUX: 0.611 loss_D_gr_fake: 0.091 acc_grfake: 0.945 
(epoch: 20, batches: 220, time: 0.007, data: 0.001) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.504 loss_D_fake: 0.762 loss_D: 1.902 acc_real: 0.993 acc_fake: 0.413 loss_G_conf: 0.176 loss_AUX: 0.606 loss_D_gr_fake: 0.029 acc_grfake: 0.945 
saving the model at the end of epoch 20, iters 299520
learning rate 0.0001000 -> 0.0000800
End of epoch 20 / 30 	 Time Taken: 203 sec
(epoch: 21, batches: 20, time: 0.012, data: 0.006) loss_G_comp: 0.558 loss_G_anti_sc: 0.133 loss_G: 0.867 loss_D_real: 0.513 loss_D_fake: 0.739 loss_D: 1.983 acc_real: 0.993 acc_fake: 0.413 loss_G_conf: 0.176 loss_AUX: 0.645 loss_D_gr_fake: 0.085 acc_grfake: 0.945 
validation accuracies:
                gf: 0.95
                real: 0.98
                fake: 0.65

ran validation set (B:4701) in                         45.4 s.
(epoch: 21, batches: 40, time: 0.007, data: 0.002) loss_G_comp: 0.507 loss_G_anti_sc: 0.529 loss_G: 1.205 loss_D_real: 0.625 loss_D_fake: 0.982 loss_D: 2.259 acc_real: 0.985 acc_fake: 0.650 loss_G_conf: 0.169 loss_AUX: 0.603 loss_D_gr_fake: 0.049 acc_grfake: 0.953 
(epoch: 21, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.587 loss_G_anti_sc: 0.111 loss_G: 0.872 loss_D_real: 0.520 loss_D_fake: 1.144 loss_D: 2.314 acc_real: 0.985 acc_fake: 0.650 loss_G_conf: 0.173 loss_AUX: 0.607 loss_D_gr_fake: 0.044 acc_grfake: 0.953 
(epoch: 21, batches: 80, time: 0.007, data: 0.001) loss_G_comp: 0.559 loss_G_anti_sc: 0.197 loss_G: 0.919 loss_D_real: 0.540 loss_D_fake: 1.351 loss_D: 2.549 acc_real: 0.985 acc_fake: 0.650 loss_G_conf: 0.163 loss_AUX: 0.589 loss_D_gr_fake: 0.069 acc_grfake: 0.953 
(epoch: 21, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.596 loss_G_anti_sc: 0.143 loss_G: 0.902 loss_D_real: 0.513 loss_D_fake: 1.290 loss_D: 2.473 acc_real: 0.985 acc_fake: 0.650 loss_G_conf: 0.162 loss_AUX: 0.574 loss_D_gr_fake: 0.096 acc_grfake: 0.953 
(epoch: 21, batches: 120, time: 0.010, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.509 loss_D_fake: 1.284 loss_D: 2.393 acc_real: 0.985 acc_fake: 0.650 loss_G_conf: 0.158 loss_AUX: 0.567 loss_D_gr_fake: 0.034 acc_grfake: 0.953 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.07

ran validation set (B:4801) in                         45.5 s.
(epoch: 21, batches: 140, time: 0.008, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.537 loss_D_fake: 1.070 loss_D: 2.182 acc_real: 0.995 acc_fake: 0.070 loss_G_conf: 0.158 loss_AUX: 0.542 loss_D_gr_fake: 0.033 acc_grfake: 0.940 
(epoch: 21, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.519 loss_D_fake: 1.179 loss_D: 2.364 acc_real: 0.995 acc_fake: 0.070 loss_G_conf: 0.158 loss_AUX: 0.569 loss_D_gr_fake: 0.097 acc_grfake: 0.940 
(epoch: 21, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.542 loss_D_fake: 0.850 loss_D: 2.051 acc_real: 0.995 acc_fake: 0.070 loss_G_conf: 0.158 loss_AUX: 0.598 loss_D_gr_fake: 0.061 acc_grfake: 0.940 
(epoch: 21, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.523 loss_D_fake: 0.903 loss_D: 2.120 acc_real: 0.995 acc_fake: 0.070 loss_G_conf: 0.158 loss_AUX: 0.595 loss_D_gr_fake: 0.099 acc_grfake: 0.940 
(epoch: 21, batches: 220, time: 0.010, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.512 loss_D_fake: 0.968 loss_D: 2.082 acc_real: 0.995 acc_fake: 0.070 loss_G_conf: 0.158 loss_AUX: 0.559 loss_D_gr_fake: 0.043 acc_grfake: 0.940 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.35

ran validation set (B:4901) in                         45.4 s.
learning rate 0.0000800 -> 0.0000800
End of epoch 21 / 30 	 Time Taken: 245 sec
(epoch: 22, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.511 loss_D_fake: 0.948 loss_D: 2.076 acc_real: 0.980 acc_fake: 0.349 loss_G_conf: 0.158 loss_AUX: 0.569 loss_D_gr_fake: 0.047 acc_grfake: 0.958 
(epoch: 22, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.522 loss_D_fake: 0.753 loss_D: 1.931 acc_real: 0.980 acc_fake: 0.349 loss_G_conf: 0.158 loss_AUX: 0.585 loss_D_gr_fake: 0.071 acc_grfake: 0.958 
(epoch: 22, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.518 loss_D_fake: 0.794 loss_D: 1.975 acc_real: 0.980 acc_fake: 0.349 loss_G_conf: 0.158 loss_AUX: 0.556 loss_D_gr_fake: 0.107 acc_grfake: 0.958 
(epoch: 22, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.504 loss_D_fake: 1.032 loss_D: 2.181 acc_real: 0.980 acc_fake: 0.349 loss_G_conf: 0.158 loss_AUX: 0.568 loss_D_gr_fake: 0.078 acc_grfake: 0.958 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.35

ran validation set (B:5001) in                         45.4 s.
(epoch: 22, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.526 loss_D_fake: 0.711 loss_D: 1.867 acc_real: 0.993 acc_fake: 0.353 loss_G_conf: 0.158 loss_AUX: 0.582 loss_D_gr_fake: 0.048 acc_grfake: 0.947 
(epoch: 22, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.509 loss_D_fake: 0.839 loss_D: 2.000 acc_real: 0.993 acc_fake: 0.353 loss_G_conf: 0.158 loss_AUX: 0.575 loss_D_gr_fake: 0.078 acc_grfake: 0.947 
(epoch: 22, batches: 140, time: 0.007, data: 0.005) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.530 loss_D_fake: 0.773 loss_D: 1.966 acc_real: 0.993 acc_fake: 0.353 loss_G_conf: 0.158 loss_AUX: 0.604 loss_D_gr_fake: 0.060 acc_grfake: 0.947 
(epoch: 22, batches: 160, time: 0.007, data: 0.001) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.510 loss_D_fake: 0.640 loss_D: 1.828 acc_real: 0.993 acc_fake: 0.353 loss_G_conf: 0.158 loss_AUX: 0.585 loss_D_gr_fake: 0.093 acc_grfake: 0.947 
(epoch: 22, batches: 180, time: 0.007, data: 0.006) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.505 loss_D_fake: 0.800 loss_D: 1.979 acc_real: 0.993 acc_fake: 0.353 loss_G_conf: 0.158 loss_AUX: 0.582 loss_D_gr_fake: 0.092 acc_grfake: 0.947 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.46

ran validation set (B:5101) in                         45.5 s.
(epoch: 22, batches: 200, time: 0.008, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.530 loss_D_fake: 0.641 loss_D: 1.860 acc_real: 0.990 acc_fake: 0.459 loss_G_conf: 0.158 loss_AUX: 0.598 loss_D_gr_fake: 0.091 acc_grfake: 0.953 
(epoch: 22, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.508 loss_D_fake: 0.744 loss_D: 1.902 acc_real: 0.990 acc_fake: 0.459 loss_G_conf: 0.158 loss_AUX: 0.563 loss_D_gr_fake: 0.087 acc_grfake: 0.953 
learning rate 0.0000800 -> 0.0000800
End of epoch 22 / 30 	 Time Taken: 200 sec
(epoch: 23, batches: 20, time: 0.007, data: 0.026) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.527 loss_D_fake: 0.581 loss_D: 1.764 acc_real: 0.990 acc_fake: 0.459 loss_G_conf: 0.158 loss_AUX: 0.597 loss_D_gr_fake: 0.059 acc_grfake: 0.953 
(epoch: 23, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.517 loss_D_fake: 0.748 loss_D: 1.951 acc_real: 0.990 acc_fake: 0.459 loss_G_conf: 0.158 loss_AUX: 0.598 loss_D_gr_fake: 0.088 acc_grfake: 0.953 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.47

ran validation set (B:5201) in                         45.4 s.
(epoch: 23, batches: 60, time: 0.007, data: 0.002) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.526 loss_D_fake: 0.888 loss_D: 2.090 acc_real: 0.991 acc_fake: 0.465 loss_G_conf: 0.158 loss_AUX: 0.578 loss_D_gr_fake: 0.099 acc_grfake: 0.949 
(epoch: 23, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.508 loss_D_fake: 0.916 loss_D: 2.114 acc_real: 0.991 acc_fake: 0.465 loss_G_conf: 0.158 loss_AUX: 0.595 loss_D_gr_fake: 0.095 acc_grfake: 0.949 
(epoch: 23, batches: 100, time: 0.007, data: 0.015) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.526 loss_D_fake: 0.607 loss_D: 1.798 acc_real: 0.991 acc_fake: 0.465 loss_G_conf: 0.158 loss_AUX: 0.609 loss_D_gr_fake: 0.056 acc_grfake: 0.949 
(epoch: 23, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.507 loss_D_fake: 0.852 loss_D: 2.052 acc_real: 0.991 acc_fake: 0.465 loss_G_conf: 0.158 loss_AUX: 0.606 loss_D_gr_fake: 0.087 acc_grfake: 0.949 
(epoch: 23, batches: 140, time: 0.007, data: 0.002) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.505 loss_D_fake: 0.920 loss_D: 2.104 acc_real: 0.991 acc_fake: 0.465 loss_G_conf: 0.158 loss_AUX: 0.572 loss_D_gr_fake: 0.107 acc_grfake: 0.949 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.56

ran validation set (B:5301) in                         45.5 s.
(epoch: 23, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.513 loss_D_fake: 0.731 loss_D: 1.906 acc_real: 0.987 acc_fake: 0.559 loss_G_conf: 0.158 loss_AUX: 0.593 loss_D_gr_fake: 0.069 acc_grfake: 0.953 
(epoch: 23, batches: 180, time: 0.008, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.509 loss_D_fake: 0.613 loss_D: 1.761 acc_real: 0.987 acc_fake: 0.559 loss_G_conf: 0.158 loss_AUX: 0.582 loss_D_gr_fake: 0.058 acc_grfake: 0.953 
(epoch: 23, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.513 loss_D_fake: 0.686 loss_D: 1.868 acc_real: 0.987 acc_fake: 0.559 loss_G_conf: 0.158 loss_AUX: 0.583 loss_D_gr_fake: 0.087 acc_grfake: 0.953 
(epoch: 23, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.541 loss_G_anti_sc: 0.156 loss_G: 0.855 loss_D_real: 0.509 loss_D_fake: 0.747 loss_D: 1.921 acc_real: 0.987 acc_fake: 0.559 loss_G_conf: 0.158 loss_AUX: 0.584 loss_D_gr_fake: 0.081 acc_grfake: 0.953 
learning rate 0.0000800 -> 0.0000800
End of epoch 23 / 30 	 Time Taken: 202 sec
validation accuracies:
                gf: 0.95
                real: 0.98
                fake: 0.61

ran validation set (B:5401) in                         45.5 s.
(epoch: 24, batches: 20, time: 0.006, data: 0.003) loss_G_comp: 0.957 loss_G_anti_sc: 0.042 loss_G: 1.159 loss_D_real: 0.518 loss_D_fake: 0.556 loss_D: 1.720 acc_real: 0.980 acc_fake: 0.610 loss_G_conf: 0.160 loss_AUX: 0.584 loss_D_gr_fake: 0.062 acc_grfake: 0.953 
(epoch: 24, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.645 loss_G_anti_sc: 0.138 loss_G: 0.944 loss_D_real: 0.512 loss_D_fake: 1.191 loss_D: 2.343 acc_real: 0.980 acc_fake: 0.610 loss_G_conf: 0.160 loss_AUX: 0.564 loss_D_gr_fake: 0.076 acc_grfake: 0.953 
(epoch: 24, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.620 loss_G_anti_sc: 0.069 loss_G: 0.845 loss_D_real: 0.538 loss_D_fake: 1.239 loss_D: 2.534 acc_real: 0.980 acc_fake: 0.610 loss_G_conf: 0.157 loss_AUX: 0.583 loss_D_gr_fake: 0.174 acc_grfake: 0.953 
(epoch: 24, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.539 loss_G_anti_sc: 0.180 loss_G: 0.879 loss_D_real: 0.509 loss_D_fake: 1.319 loss_D: 2.529 acc_real: 0.980 acc_fake: 0.610 loss_G_conf: 0.160 loss_AUX: 0.610 loss_D_gr_fake: 0.091 acc_grfake: 0.953 
(epoch: 24, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.079 loss_G: 0.797 loss_D_real: 0.515 loss_D_fake: 1.245 loss_D: 2.350 acc_real: 0.980 acc_fake: 0.610 loss_G_conf: 0.156 loss_AUX: 0.568 loss_D_gr_fake: 0.022 acc_grfake: 0.953 
validation accuracies:
                gf: 0.94
                real: 0.97
                fake: 0.13

ran validation set (B:5501) in                         45.5 s.
(epoch: 24, batches: 120, time: 0.007, data: 0.018) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.524 loss_D_fake: 1.184 loss_D: 2.355 acc_real: 0.972 acc_fake: 0.134 loss_G_conf: 0.151 loss_AUX: 0.543 loss_D_gr_fake: 0.104 acc_grfake: 0.944 
(epoch: 24, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.524 loss_D_fake: 1.070 loss_D: 2.203 acc_real: 0.972 acc_fake: 0.134 loss_G_conf: 0.151 loss_AUX: 0.553 loss_D_gr_fake: 0.057 acc_grfake: 0.944 
(epoch: 24, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.504 loss_D_fake: 1.177 loss_D: 2.305 acc_real: 0.972 acc_fake: 0.134 loss_G_conf: 0.151 loss_AUX: 0.564 loss_D_gr_fake: 0.060 acc_grfake: 0.944 
(epoch: 24, batches: 180, time: 0.007, data: 0.012) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.519 loss_D_fake: 0.976 loss_D: 2.149 acc_real: 0.972 acc_fake: 0.134 loss_G_conf: 0.151 loss_AUX: 0.567 loss_D_gr_fake: 0.088 acc_grfake: 0.944 
(epoch: 24, batches: 200, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.505 loss_D_fake: 1.104 loss_D: 2.209 acc_real: 0.972 acc_fake: 0.134 loss_G_conf: 0.151 loss_AUX: 0.552 loss_D_gr_fake: 0.048 acc_grfake: 0.944 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.28

ran validation set (B:5601) in                         45.4 s.
(epoch: 24, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.514 loss_D_fake: 1.005 loss_D: 2.106 acc_real: 0.993 acc_fake: 0.281 loss_G_conf: 0.151 loss_AUX: 0.580 loss_D_gr_fake: 0.007 acc_grfake: 0.949 
learning rate 0.0000800 -> 0.0000800
End of epoch 24 / 30 	 Time Taken: 246 sec
(epoch: 25, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.566 loss_D_fake: 0.673 loss_D: 1.863 acc_real: 0.993 acc_fake: 0.281 loss_G_conf: 0.151 loss_AUX: 0.614 loss_D_gr_fake: 0.011 acc_grfake: 0.949 
(epoch: 25, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.519 loss_D_fake: 0.869 loss_D: 2.025 acc_real: 0.993 acc_fake: 0.281 loss_G_conf: 0.151 loss_AUX: 0.591 loss_D_gr_fake: 0.047 acc_grfake: 0.949 
(epoch: 25, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.510 loss_D_fake: 0.809 loss_D: 2.023 acc_real: 0.993 acc_fake: 0.281 loss_G_conf: 0.151 loss_AUX: 0.577 loss_D_gr_fake: 0.127 acc_grfake: 0.949 
(epoch: 25, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.508 loss_D_fake: 0.975 loss_D: 2.131 acc_real: 0.993 acc_fake: 0.281 loss_G_conf: 0.151 loss_AUX: 0.554 loss_D_gr_fake: 0.094 acc_grfake: 0.949 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.20

ran validation set (B:5701) in                         45.5 s.
(epoch: 25, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.506 loss_D_fake: 0.937 loss_D: 2.145 acc_real: 0.997 acc_fake: 0.203 loss_G_conf: 0.151 loss_AUX: 0.578 loss_D_gr_fake: 0.123 acc_grfake: 0.943 
(epoch: 25, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.504 loss_D_fake: 1.044 loss_D: 2.257 acc_real: 0.997 acc_fake: 0.203 loss_G_conf: 0.151 loss_AUX: 0.562 loss_D_gr_fake: 0.147 acc_grfake: 0.943 
(epoch: 25, batches: 140, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.505 loss_D_fake: 0.870 loss_D: 1.997 acc_real: 0.997 acc_fake: 0.203 loss_G_conf: 0.151 loss_AUX: 0.533 loss_D_gr_fake: 0.089 acc_grfake: 0.943 
(epoch: 25, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.515 loss_D_fake: 0.941 loss_D: 2.068 acc_real: 0.997 acc_fake: 0.203 loss_G_conf: 0.151 loss_AUX: 0.557 loss_D_gr_fake: 0.055 acc_grfake: 0.943 
(epoch: 25, batches: 180, time: 0.007, data: 0.002) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.524 loss_D_fake: 0.796 loss_D: 1.974 acc_real: 0.997 acc_fake: 0.203 loss_G_conf: 0.151 loss_AUX: 0.563 loss_D_gr_fake: 0.090 acc_grfake: 0.943 
validation accuracies:
                gf: 0.96
                real: 0.99
                fake: 0.39

ran validation set (B:5801) in                         45.4 s.
(epoch: 25, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.511 loss_D_fake: 0.916 loss_D: 2.106 acc_real: 0.993 acc_fake: 0.393 loss_G_conf: 0.151 loss_AUX: 0.581 loss_D_gr_fake: 0.098 acc_grfake: 0.961 
(epoch: 25, batches: 220, time: 0.008, data: 0.022) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.521 loss_D_fake: 0.768 loss_D: 1.898 acc_real: 0.993 acc_fake: 0.393 loss_G_conf: 0.151 loss_AUX: 0.543 loss_D_gr_fake: 0.066 acc_grfake: 0.961 
saving the model at the end of epoch 25, iters 374400
learning rate 0.0000800 -> 0.0000800
End of epoch 25 / 30 	 Time Taken: 202 sec
(epoch: 26, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.524 loss_D_fake: 0.687 loss_D: 1.794 acc_real: 0.993 acc_fake: 0.393 loss_G_conf: 0.151 loss_AUX: 0.555 loss_D_gr_fake: 0.027 acc_grfake: 0.961 
(epoch: 26, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.507 loss_D_fake: 0.864 loss_D: 1.945 acc_real: 0.993 acc_fake: 0.393 loss_G_conf: 0.151 loss_AUX: 0.560 loss_D_gr_fake: 0.014 acc_grfake: 0.961 
validation accuracies:
                gf: 0.96
                real: 0.99
                fake: 0.52

ran validation set (B:5901) in                         45.4 s.
(epoch: 26, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.507 loss_D_fake: 0.680 loss_D: 1.818 acc_real: 0.990 acc_fake: 0.516 loss_G_conf: 0.151 loss_AUX: 0.551 loss_D_gr_fake: 0.079 acc_grfake: 0.960 
(epoch: 26, batches: 80, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.512 loss_D_fake: 0.696 loss_D: 1.907 acc_real: 0.990 acc_fake: 0.516 loss_G_conf: 0.151 loss_AUX: 0.581 loss_D_gr_fake: 0.118 acc_grfake: 0.960 
(epoch: 26, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.503 loss_D_fake: 0.954 loss_D: 2.044 acc_real: 0.990 acc_fake: 0.516 loss_G_conf: 0.151 loss_AUX: 0.555 loss_D_gr_fake: 0.032 acc_grfake: 0.960 
(epoch: 26, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.527 loss_D_fake: 0.752 loss_D: 1.888 acc_real: 0.990 acc_fake: 0.516 loss_G_conf: 0.151 loss_AUX: 0.576 loss_D_gr_fake: 0.034 acc_grfake: 0.960 
(epoch: 26, batches: 140, time: 0.007, data: 0.002) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.526 loss_D_fake: 0.714 loss_D: 1.905 acc_real: 0.990 acc_fake: 0.516 loss_G_conf: 0.151 loss_AUX: 0.581 loss_D_gr_fake: 0.083 acc_grfake: 0.960 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.52

ran validation set (B:6001) in                         45.4 s.
(epoch: 26, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.508 loss_D_fake: 0.728 loss_D: 1.855 acc_real: 0.978 acc_fake: 0.522 loss_G_conf: 0.151 loss_AUX: 0.558 loss_D_gr_fake: 0.060 acc_grfake: 0.958 
(epoch: 26, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.504 loss_D_fake: 0.792 loss_D: 1.918 acc_real: 0.978 acc_fake: 0.522 loss_G_conf: 0.151 loss_AUX: 0.558 loss_D_gr_fake: 0.064 acc_grfake: 0.958 
(epoch: 26, batches: 200, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.534 loss_D_fake: 0.805 loss_D: 1.958 acc_real: 0.978 acc_fake: 0.522 loss_G_conf: 0.151 loss_AUX: 0.573 loss_D_gr_fake: 0.046 acc_grfake: 0.958 
(epoch: 26, batches: 220, time: 0.008, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.587 loss_D_fake: 0.473 loss_D: 1.716 acc_real: 0.978 acc_fake: 0.522 loss_G_conf: 0.151 loss_AUX: 0.594 loss_D_gr_fake: 0.062 acc_grfake: 0.958 
learning rate 0.0000800 -> 0.0000800
End of epoch 26 / 30 	 Time Taken: 202 sec
validation accuracies:
                gf: 0.96
                real: 0.99
                fake: 0.58

ran validation set (B:6101) in                         45.5 s.
(epoch: 27, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.512 loss_D_fake: 0.765 loss_D: 1.915 acc_real: 0.985 acc_fake: 0.580 loss_G_conf: 0.151 loss_AUX: 0.556 loss_D_gr_fake: 0.082 acc_grfake: 0.963 
(epoch: 27, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.515 loss_D_fake: 0.778 loss_D: 1.900 acc_real: 0.985 acc_fake: 0.580 loss_G_conf: 0.151 loss_AUX: 0.583 loss_D_gr_fake: 0.024 acc_grfake: 0.963 
(epoch: 27, batches: 60, time: 0.007, data: 0.005) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.507 loss_D_fake: 0.710 loss_D: 1.931 acc_real: 0.985 acc_fake: 0.580 loss_G_conf: 0.151 loss_AUX: 0.580 loss_D_gr_fake: 0.134 acc_grfake: 0.963 
(epoch: 27, batches: 80, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.514 loss_D_fake: 0.592 loss_D: 1.795 acc_real: 0.985 acc_fake: 0.580 loss_G_conf: 0.151 loss_AUX: 0.611 loss_D_gr_fake: 0.079 acc_grfake: 0.963 
(epoch: 27, batches: 100, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.504 loss_D_fake: 0.801 loss_D: 1.976 acc_real: 0.985 acc_fake: 0.580 loss_G_conf: 0.151 loss_AUX: 0.558 loss_D_gr_fake: 0.113 acc_grfake: 0.963 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.49

ran validation set (B:6201) in                         45.4 s.
(epoch: 27, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.512 loss_D_fake: 0.709 loss_D: 1.911 acc_real: 0.995 acc_fake: 0.494 loss_G_conf: 0.151 loss_AUX: 0.577 loss_D_gr_fake: 0.113 acc_grfake: 0.951 
(epoch: 27, batches: 140, time: 0.007, data: 0.022) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.509 loss_D_fake: 0.672 loss_D: 1.792 acc_real: 0.995 acc_fake: 0.494 loss_G_conf: 0.151 loss_AUX: 0.579 loss_D_gr_fake: 0.032 acc_grfake: 0.951 
(epoch: 27, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.506 loss_D_fake: 0.702 loss_D: 1.853 acc_real: 0.995 acc_fake: 0.494 loss_G_conf: 0.151 loss_AUX: 0.553 loss_D_gr_fake: 0.091 acc_grfake: 0.951 
(epoch: 27, batches: 180, time: 0.007, data: 0.016) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.515 loss_D_fake: 0.676 loss_D: 1.810 acc_real: 0.995 acc_fake: 0.494 loss_G_conf: 0.151 loss_AUX: 0.571 loss_D_gr_fake: 0.048 acc_grfake: 0.951 
(epoch: 27, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.545 loss_D_fake: 0.544 loss_D: 1.706 acc_real: 0.995 acc_fake: 0.494 loss_G_conf: 0.151 loss_AUX: 0.565 loss_D_gr_fake: 0.052 acc_grfake: 0.951 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.58

ran validation set (B:6301) in                         45.4 s.
(epoch: 27, batches: 220, time: 0.008, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.514 loss_D_fake: 0.517 loss_D: 1.638 acc_real: 0.993 acc_fake: 0.577 loss_G_conf: 0.151 loss_AUX: 0.579 loss_D_gr_fake: 0.028 acc_grfake: 0.948 
learning rate 0.0000800 -> 0.0000800
End of epoch 27 / 30 	 Time Taken: 248 sec
(epoch: 28, batches: 20, time: 0.008, data: 0.005) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.550 loss_D_fake: 0.515 loss_D: 1.737 acc_real: 0.993 acc_fake: 0.577 loss_G_conf: 0.151 loss_AUX: 0.601 loss_D_gr_fake: 0.071 acc_grfake: 0.948 
(epoch: 28, batches: 40, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.506 loss_D_fake: 0.659 loss_D: 1.795 acc_real: 0.993 acc_fake: 0.577 loss_G_conf: 0.151 loss_AUX: 0.580 loss_D_gr_fake: 0.050 acc_grfake: 0.948 
(epoch: 28, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.514 loss_D_fake: 0.600 loss_D: 1.695 acc_real: 0.993 acc_fake: 0.577 loss_G_conf: 0.151 loss_AUX: 0.562 loss_D_gr_fake: 0.018 acc_grfake: 0.948 
(epoch: 28, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.541 loss_D_fake: 0.615 loss_D: 1.744 acc_real: 0.993 acc_fake: 0.577 loss_G_conf: 0.151 loss_AUX: 0.565 loss_D_gr_fake: 0.022 acc_grfake: 0.948 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.48

ran validation set (B:6401) in                         45.4 s.
(epoch: 28, batches: 100, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.506 loss_D_fake: 0.727 loss_D: 1.898 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.151 loss_AUX: 0.551 loss_D_gr_fake: 0.114 acc_grfake: 0.947 
(epoch: 28, batches: 120, time: 0.007, data: 0.021) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.509 loss_D_fake: 0.783 loss_D: 1.974 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.151 loss_AUX: 0.561 loss_D_gr_fake: 0.122 acc_grfake: 0.947 
(epoch: 28, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.511 loss_D_fake: 0.566 loss_D: 1.746 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.151 loss_AUX: 0.559 loss_D_gr_fake: 0.110 acc_grfake: 0.947 
(epoch: 28, batches: 160, time: 0.008, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.540 loss_D_fake: 0.615 loss_D: 1.769 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.151 loss_AUX: 0.560 loss_D_gr_fake: 0.055 acc_grfake: 0.947 
(epoch: 28, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.521 loss_D_fake: 0.739 loss_D: 1.877 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.151 loss_AUX: 0.551 loss_D_gr_fake: 0.066 acc_grfake: 0.947 
validation accuracies:
                gf: 0.95
                real: 0.98
                fake: 0.54

ran validation set (B:6501) in                         45.4 s.
(epoch: 28, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.503 loss_D_fake: 0.848 loss_D: 1.986 acc_real: 0.983 acc_fake: 0.542 loss_G_conf: 0.151 loss_AUX: 0.549 loss_D_gr_fake: 0.086 acc_grfake: 0.954 
(epoch: 28, batches: 220, time: 0.007, data: 0.001) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.526 loss_D_fake: 0.570 loss_D: 1.735 acc_real: 0.983 acc_fake: 0.542 loss_G_conf: 0.151 loss_AUX: 0.556 loss_D_gr_fake: 0.082 acc_grfake: 0.954 
learning rate 0.0000800 -> 0.0000800
End of epoch 28 / 30 	 Time Taken: 205 sec
(epoch: 29, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.508 loss_D_fake: 0.670 loss_D: 1.895 acc_real: 0.983 acc_fake: 0.542 loss_G_conf: 0.151 loss_AUX: 0.607 loss_D_gr_fake: 0.110 acc_grfake: 0.954 
(epoch: 29, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.595 loss_G_anti_sc: 0.139 loss_G: 0.886 loss_D_real: 0.525 loss_D_fake: 0.657 loss_D: 1.825 acc_real: 0.983 acc_fake: 0.542 loss_G_conf: 0.151 loss_AUX: 0.556 loss_D_gr_fake: 0.087 acc_grfake: 0.954 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.68

ran validation set (B:6601) in                         45.5 s.
(epoch: 29, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.507 loss_G_anti_sc: 0.802 loss_G: 1.469 loss_D_real: 1.057 loss_D_fake: 0.353 loss_D: 2.190 acc_real: 0.983 acc_fake: 0.680 loss_G_conf: 0.161 loss_AUX: 0.703 loss_D_gr_fake: 0.077 acc_grfake: 0.959 
(epoch: 29, batches: 80, time: 0.006, data: 0.001) loss_G_comp: 0.571 loss_G_anti_sc: 0.200 loss_G: 0.937 loss_D_real: 0.510 loss_D_fake: 1.287 loss_D: 2.519 acc_real: 0.983 acc_fake: 0.680 loss_G_conf: 0.166 loss_AUX: 0.633 loss_D_gr_fake: 0.088 acc_grfake: 0.959 
(epoch: 29, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.601 loss_G_anti_sc: 0.153 loss_G: 0.917 loss_D_real: 0.505 loss_D_fake: 1.292 loss_D: 2.418 acc_real: 0.983 acc_fake: 0.680 loss_G_conf: 0.163 loss_AUX: 0.562 loss_D_gr_fake: 0.059 acc_grfake: 0.959 
(epoch: 29, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.580 loss_G_anti_sc: 0.190 loss_G: 0.927 loss_D_real: 0.521 loss_D_fake: 1.227 loss_D: 2.353 acc_real: 0.983 acc_fake: 0.680 loss_G_conf: 0.157 loss_AUX: 0.549 loss_D_gr_fake: 0.057 acc_grfake: 0.959 
(epoch: 29, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.526 loss_G_anti_sc: 0.174 loss_G: 0.851 loss_D_real: 0.551 loss_D_fake: 1.112 loss_D: 2.257 acc_real: 0.983 acc_fake: 0.680 loss_G_conf: 0.151 loss_AUX: 0.540 loss_D_gr_fake: 0.054 acc_grfake: 0.959 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.03

ran validation set (B:6701) in                         45.4 s.
(epoch: 29, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.524 loss_D_fake: 1.124 loss_D: 2.223 acc_real: 0.998 acc_fake: 0.030 loss_G_conf: 0.141 loss_AUX: 0.527 loss_D_gr_fake: 0.047 acc_grfake: 0.933 
(epoch: 29, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.519 loss_D_fake: 0.989 loss_D: 2.161 acc_real: 0.998 acc_fake: 0.030 loss_G_conf: 0.141 loss_AUX: 0.538 loss_D_gr_fake: 0.115 acc_grfake: 0.933 
(epoch: 29, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.503 loss_D_fake: 1.259 loss_D: 2.417 acc_real: 0.998 acc_fake: 0.030 loss_G_conf: 0.141 loss_AUX: 0.540 loss_D_gr_fake: 0.115 acc_grfake: 0.933 
(epoch: 29, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.506 loss_D_fake: 1.158 loss_D: 2.330 acc_real: 0.998 acc_fake: 0.030 loss_G_conf: 0.141 loss_AUX: 0.528 loss_D_gr_fake: 0.137 acc_grfake: 0.933 
learning rate 0.0000800 -> 0.0000800
End of epoch 29 / 30 	 Time Taken: 200 sec
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.22

ran validation set (B:6801) in                         45.5 s.
(epoch: 30, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.507 loss_D_fake: 1.129 loss_D: 2.311 acc_real: 0.992 acc_fake: 0.221 loss_G_conf: 0.141 loss_AUX: 0.575 loss_D_gr_fake: 0.099 acc_grfake: 0.954 
(epoch: 30, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.522 loss_D_fake: 0.999 loss_D: 2.178 acc_real: 0.992 acc_fake: 0.221 loss_G_conf: 0.141 loss_AUX: 0.559 loss_D_gr_fake: 0.096 acc_grfake: 0.954 
(epoch: 30, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.573 loss_D_fake: 0.687 loss_D: 1.903 acc_real: 0.992 acc_fake: 0.221 loss_G_conf: 0.141 loss_AUX: 0.590 loss_D_gr_fake: 0.053 acc_grfake: 0.954 
(epoch: 30, batches: 80, time: 0.008, data: 0.019) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.507 loss_D_fake: 0.859 loss_D: 2.004 acc_real: 0.992 acc_fake: 0.221 loss_G_conf: 0.141 loss_AUX: 0.537 loss_D_gr_fake: 0.102 acc_grfake: 0.954 
(epoch: 30, batches: 100, time: 0.008, data: 0.018) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.513 loss_D_fake: 0.945 loss_D: 2.127 acc_real: 0.992 acc_fake: 0.221 loss_G_conf: 0.141 loss_AUX: 0.589 loss_D_gr_fake: 0.079 acc_grfake: 0.954 
validation accuracies:
                gf: 0.96
                real: 0.97
                fake: 0.36

ran validation set (B:6901) in                         45.5 s.
(epoch: 30, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.519 loss_D_fake: 0.936 loss_D: 2.096 acc_real: 0.974 acc_fake: 0.357 loss_G_conf: 0.141 loss_AUX: 0.550 loss_D_gr_fake: 0.091 acc_grfake: 0.963 
(epoch: 30, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.521 loss_D_fake: 0.958 loss_D: 2.098 acc_real: 0.974 acc_fake: 0.357 loss_G_conf: 0.141 loss_AUX: 0.534 loss_D_gr_fake: 0.085 acc_grfake: 0.963 
(epoch: 30, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.527 loss_D_fake: 0.878 loss_D: 2.018 acc_real: 0.974 acc_fake: 0.357 loss_G_conf: 0.141 loss_AUX: 0.563 loss_D_gr_fake: 0.050 acc_grfake: 0.963 
(epoch: 30, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.564 loss_D_fake: 0.824 loss_D: 2.046 acc_real: 0.974 acc_fake: 0.357 loss_G_conf: 0.141 loss_AUX: 0.544 loss_D_gr_fake: 0.113 acc_grfake: 0.963 
(epoch: 30, batches: 200, time: 0.007, data: 0.005) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.519 loss_D_fake: 0.721 loss_D: 1.805 acc_real: 0.974 acc_fake: 0.357 loss_G_conf: 0.141 loss_AUX: 0.534 loss_D_gr_fake: 0.032 acc_grfake: 0.963 
validation accuracies:
                gf: 0.97
                real: 0.91
                fake: 0.55

ran validation set (B:7001) in                         45.4 s.
(epoch: 30, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.538 loss_G_anti_sc: 0.244 loss_G: 0.923 loss_D_real: 0.507 loss_D_fake: 0.922 loss_D: 2.013 acc_real: 0.912 acc_fake: 0.547 loss_G_conf: 0.141 loss_AUX: 0.556 loss_D_gr_fake: 0.028 acc_grfake: 0.972 
saving the model at the end of epoch 30, iters 449280
learning rate 0.0000800 -> 0.0000800
End of epoch 30 / 30 	 Time Taken: 247 sec
Finished training, model is saved
Batches trained - G: 650, D: 6370 
