starting training run 44
----------------- Options ---------------
              D_headstart: 0                             	[default: 1000]
              D_threshold: 0.5                           	[default: 0.6]
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
            flip_vertical: False                         
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 70                            
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: True                          	[default: False]
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 0.0                           	[default: 1.0]
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
----------------- Options ---------------
              D_headstart: 0                             	[default: 1000]
              D_threshold: 0.5                           	[default: 0.6]
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
            flip_vertical: False                         
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 70                            
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: True                          	[default: False]
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 0.0                           	[default: 1.0]
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [DoubleDataset] was created
dataset [DoubleDataset] was created
The number of training images = 15000
The number of epochs to run = 30
initialize network with normal
initialize network with normal
model [CopyPasteGANModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.469 M
DataParallel(
  (module): CopyDiscriminator(
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (sigmoid): Sigmoid()
    (avg): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (2): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 4.060 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 1.00
                real: 0.00
                fake: 1.00

ran validation set (B:1) in                         47.5 s.
(epoch: 1, batches: 20, time: 0.005, data: 0.018) loss_G_comp: 0.714 loss_G_anti_sc: 0.701 loss_G: 1.537 loss_D_real: 0.596 loss_D_fake: 0.716 loss_D: 1.500 acc_real: 0.000 acc_fake: 1.000 loss_G_conf: 0.122 loss_AUX: 0.188 loss_D_gr_fake: 0.000 acc_grfake: 1.000 
(epoch: 1, batches: 40, time: 0.005, data: 0.329) loss_G_comp: 0.758 loss_G_anti_sc: 0.649 loss_G: 1.491 loss_D_real: 0.559 loss_D_fake: 0.670 loss_D: 1.412 acc_real: 0.000 acc_fake: 1.000 loss_G_conf: 0.083 loss_AUX: 0.183 loss_D_gr_fake: 0.000 acc_grfake: 1.000 
(epoch: 1, batches: 60, time: 0.005, data: 0.001) loss_G_comp: 0.747 loss_G_anti_sc: 0.601 loss_G: 1.408 loss_D_real: 0.534 loss_D_fake: 0.656 loss_D: 1.374 acc_real: 0.000 acc_fake: 1.000 loss_G_conf: 0.060 loss_AUX: 0.185 loss_D_gr_fake: 0.000 acc_grfake: 1.000 
(epoch: 1, batches: 80, time: 0.005, data: 0.017) loss_G_comp: 0.747 loss_G_anti_sc: 0.595 loss_G: 1.391 loss_D_real: 0.538 loss_D_fake: 0.611 loss_D: 1.341 acc_real: 0.000 acc_fake: 1.000 loss_G_conf: 0.049 loss_AUX: 0.192 loss_D_gr_fake: 0.000 acc_grfake: 1.000 
(epoch: 1, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.775 loss_G_anti_sc: 0.542 loss_G: 1.359 loss_D_real: 0.532 loss_D_fake: 0.610 loss_D: 1.340 acc_real: 0.000 acc_fake: 1.000 loss_G_conf: 0.042 loss_AUX: 0.197 loss_D_gr_fake: 0.000 acc_grfake: 1.000 
validation accuracies:
                gf: 0.48
                real: 0.95
                fake: 0.92

ran validation set (B:101) in                         46.7 s.
(epoch: 1, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.848 loss_G_anti_sc: 0.437 loss_G: 1.329 loss_D_real: 0.704 loss_D_fake: 0.533 loss_D: 1.959 acc_real: 0.954 acc_fake: 0.924 loss_G_conf: 0.044 loss_AUX: 0.217 loss_D_gr_fake: 0.505 acc_grfake: 0.483 
(epoch: 1, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.866 loss_G_anti_sc: 0.401 loss_G: 1.307 loss_D_real: 0.671 loss_D_fake: 0.568 loss_D: 1.929 acc_real: 0.954 acc_fake: 0.924 loss_G_conf: 0.040 loss_AUX: 0.206 loss_D_gr_fake: 0.485 acc_grfake: 0.483 
(epoch: 1, batches: 160, time: 0.006, data: 0.003) loss_G_comp: 0.813 loss_G_anti_sc: 0.433 loss_G: 1.283 loss_D_real: 0.654 loss_D_fake: 0.598 loss_D: 1.876 acc_real: 0.954 acc_fake: 0.924 loss_G_conf: 0.036 loss_AUX: 0.204 loss_D_gr_fake: 0.420 acc_grfake: 0.483 
(epoch: 1, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.777 loss_G_anti_sc: 0.453 loss_G: 1.266 loss_D_real: 0.716 loss_D_fake: 0.546 loss_D: 1.794 acc_real: 0.954 acc_fake: 0.924 loss_G_conf: 0.037 loss_AUX: 0.195 loss_D_gr_fake: 0.338 acc_grfake: 0.483 
(epoch: 1, batches: 200, time: 0.009, data: 0.003) loss_G_comp: 0.787 loss_G_anti_sc: 0.413 loss_G: 1.233 loss_D_real: 0.657 loss_D_fake: 0.687 loss_D: 1.854 acc_real: 0.954 acc_fake: 0.924 loss_G_conf: 0.033 loss_AUX: 0.192 loss_D_gr_fake: 0.319 acc_grfake: 0.483 
validation accuracies:
                gf: 0.97
                real: 0.51
                fake: 0.97

ran validation set (B:201) in                         45.9 s.
(epoch: 1, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.746 loss_G_anti_sc: 0.403 loss_G: 1.180 loss_D_real: 0.619 loss_D_fake: 0.695 loss_D: 1.821 acc_real: 0.509 acc_fake: 0.972 loss_G_conf: 0.031 loss_AUX: 0.196 loss_D_gr_fake: 0.310 acc_grfake: 0.966 
learning rate 0.0001000 -> 0.0001000
End of epoch 1 / 30 	 Time Taken: 240 sec
(epoch: 2, batches: 20, time: 0.007, data: 0.004) loss_G_comp: 0.729 loss_G_anti_sc: 0.411 loss_G: 1.171 loss_D_real: 0.589 loss_D_fake: 0.791 loss_D: 1.911 acc_real: 0.509 acc_fake: 0.972 loss_G_conf: 0.032 loss_AUX: 0.195 loss_D_gr_fake: 0.336 acc_grfake: 0.966 
(epoch: 2, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.662 loss_G_anti_sc: 0.504 loss_G: 1.202 loss_D_real: 0.666 loss_D_fake: 0.743 loss_D: 1.822 acc_real: 0.509 acc_fake: 0.972 loss_G_conf: 0.036 loss_AUX: 0.203 loss_D_gr_fake: 0.209 acc_grfake: 0.966 
(epoch: 2, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.649 loss_G_anti_sc: 0.359 loss_G: 1.042 loss_D_real: 0.638 loss_D_fake: 0.757 loss_D: 1.809 acc_real: 0.509 acc_fake: 0.972 loss_G_conf: 0.034 loss_AUX: 0.193 loss_D_gr_fake: 0.220 acc_grfake: 0.966 
validation accuracies:
                gf: 0.96
                real: 0.58
                fake: 0.90

ran validation set (B:301) in                         46.1 s.
(epoch: 2, batches: 80, time: 0.006, data: 0.003) loss_G_comp: 0.716 loss_G_anti_sc: 0.293 loss_G: 1.040 loss_D_real: 0.578 loss_D_fake: 0.894 loss_D: 2.018 acc_real: 0.583 acc_fake: 0.898 loss_G_conf: 0.031 loss_AUX: 0.212 loss_D_gr_fake: 0.334 acc_grfake: 0.964 
(epoch: 2, batches: 100, time: 0.006, data: 0.001) loss_G_comp: 0.768 loss_G_anti_sc: 0.292 loss_G: 1.090 loss_D_real: 0.548 loss_D_fake: 0.935 loss_D: 1.937 acc_real: 0.583 acc_fake: 0.898 loss_G_conf: 0.029 loss_AUX: 0.199 loss_D_gr_fake: 0.255 acc_grfake: 0.964 
(epoch: 2, batches: 120, time: 0.007, data: 0.006) loss_G_comp: 0.664 loss_G_anti_sc: 0.260 loss_G: 0.957 loss_D_real: 0.570 loss_D_fake: 0.862 loss_D: 1.875 acc_real: 0.583 acc_fake: 0.898 loss_G_conf: 0.032 loss_AUX: 0.211 loss_D_gr_fake: 0.233 acc_grfake: 0.964 
(epoch: 2, batches: 140, time: 0.008, data: 0.004) loss_G_comp: 0.680 loss_G_anti_sc: 0.373 loss_G: 1.081 loss_D_real: 0.615 loss_D_fake: 0.840 loss_D: 1.858 acc_real: 0.583 acc_fake: 0.898 loss_G_conf: 0.028 loss_AUX: 0.210 loss_D_gr_fake: 0.194 acc_grfake: 0.964 
(epoch: 2, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.545 loss_G_anti_sc: 0.625 loss_G: 1.201 loss_D_real: 0.805 loss_D_fake: 0.704 loss_D: 1.812 acc_real: 0.583 acc_fake: 0.898 loss_G_conf: 0.031 loss_AUX: 0.196 loss_D_gr_fake: 0.107 acc_grfake: 0.964 
validation accuracies:
                gf: 0.95
                real: 0.77
                fake: 0.68

ran validation set (B:401) in                         45.8 s.
(epoch: 2, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.685 loss_G_anti_sc: 0.250 loss_G: 0.964 loss_D_real: 0.556 loss_D_fake: 1.036 loss_D: 1.985 acc_real: 0.770 acc_fake: 0.681 loss_G_conf: 0.028 loss_AUX: 0.202 loss_D_gr_fake: 0.191 acc_grfake: 0.955 
(epoch: 2, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.611 loss_G_anti_sc: 0.237 loss_G: 0.878 loss_D_real: 0.628 loss_D_fake: 0.908 loss_D: 1.917 acc_real: 0.770 acc_fake: 0.681 loss_G_conf: 0.030 loss_AUX: 0.235 loss_D_gr_fake: 0.147 acc_grfake: 0.955 
(epoch: 2, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.752 loss_G_anti_sc: 0.256 loss_G: 1.036 loss_D_real: 0.529 loss_D_fake: 1.128 loss_D: 2.234 acc_real: 0.770 acc_fake: 0.681 loss_G_conf: 0.028 loss_AUX: 0.228 loss_D_gr_fake: 0.348 acc_grfake: 0.955 
learning rate 0.0001000 -> 0.0001000
End of epoch 2 / 30 	 Time Taken: 201 sec
(epoch: 3, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.664 loss_G_anti_sc: 0.260 loss_G: 0.956 loss_D_real: 0.554 loss_D_fake: 1.013 loss_D: 1.973 acc_real: 0.770 acc_fake: 0.681 loss_G_conf: 0.032 loss_AUX: 0.245 loss_D_gr_fake: 0.162 acc_grfake: 0.955 
validation accuracies:
                gf: 0.94
                real: 0.89
                fake: 0.65

ran validation set (B:501) in                         46.0 s.
(epoch: 3, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.613 loss_G_anti_sc: 0.241 loss_G: 0.883 loss_D_real: 0.590 loss_D_fake: 1.051 loss_D: 1.966 acc_real: 0.889 acc_fake: 0.646 loss_G_conf: 0.029 loss_AUX: 0.200 loss_D_gr_fake: 0.125 acc_grfake: 0.939 
(epoch: 3, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.593 loss_G_anti_sc: 0.216 loss_G: 0.839 loss_D_real: 0.607 loss_D_fake: 0.944 loss_D: 1.898 acc_real: 0.889 acc_fake: 0.646 loss_G_conf: 0.030 loss_AUX: 0.203 loss_D_gr_fake: 0.144 acc_grfake: 0.939 
(epoch: 3, batches: 80, time: 0.007, data: 0.045) loss_G_comp: 0.576 loss_G_anti_sc: 0.315 loss_G: 0.920 loss_D_real: 0.552 loss_D_fake: 1.071 loss_D: 2.100 acc_real: 0.889 acc_fake: 0.646 loss_G_conf: 0.030 loss_AUX: 0.236 loss_D_gr_fake: 0.241 acc_grfake: 0.939 
(epoch: 3, batches: 100, time: 0.008, data: 0.004) loss_G_comp: 0.559 loss_G_anti_sc: 0.364 loss_G: 0.954 loss_D_real: 0.604 loss_D_fake: 1.006 loss_D: 1.957 acc_real: 0.889 acc_fake: 0.646 loss_G_conf: 0.031 loss_AUX: 0.235 loss_D_gr_fake: 0.111 acc_grfake: 0.939 
(epoch: 3, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.745 loss_G_anti_sc: 0.249 loss_G: 1.026 loss_D_real: 0.549 loss_D_fake: 1.014 loss_D: 1.909 acc_real: 0.889 acc_fake: 0.646 loss_G_conf: 0.032 loss_AUX: 0.247 loss_D_gr_fake: 0.099 acc_grfake: 0.939 
validation accuracies:
                gf: 0.95
                real: 0.85
                fake: 0.44

ran validation set (B:601) in                         46.2 s.
(epoch: 3, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.588 loss_G_anti_sc: 0.261 loss_G: 0.876 loss_D_real: 0.539 loss_D_fake: 1.015 loss_D: 1.928 acc_real: 0.852 acc_fake: 0.440 loss_G_conf: 0.027 loss_AUX: 0.219 loss_D_gr_fake: 0.156 acc_grfake: 0.954 
(epoch: 3, batches: 160, time: 0.007, data: 0.005) loss_G_comp: 0.588 loss_G_anti_sc: 0.261 loss_G: 0.876 loss_D_real: 0.522 loss_D_fake: 0.977 loss_D: 1.959 acc_real: 0.852 acc_fake: 0.440 loss_G_conf: 0.027 loss_AUX: 0.241 loss_D_gr_fake: 0.220 acc_grfake: 0.954 
(epoch: 3, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.588 loss_G_anti_sc: 0.261 loss_G: 0.876 loss_D_real: 0.511 loss_D_fake: 0.993 loss_D: 2.052 acc_real: 0.852 acc_fake: 0.440 loss_G_conf: 0.027 loss_AUX: 0.241 loss_D_gr_fake: 0.306 acc_grfake: 0.954 
(epoch: 3, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.588 loss_G_anti_sc: 0.261 loss_G: 0.876 loss_D_real: 0.541 loss_D_fake: 0.668 loss_D: 1.558 acc_real: 0.852 acc_fake: 0.440 loss_G_conf: 0.027 loss_AUX: 0.232 loss_D_gr_fake: 0.118 acc_grfake: 0.954 
(epoch: 3, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.588 loss_G_anti_sc: 0.261 loss_G: 0.876 loss_D_real: 0.524 loss_D_fake: 0.610 loss_D: 1.539 acc_real: 0.852 acc_fake: 0.440 loss_G_conf: 0.027 loss_AUX: 0.245 loss_D_gr_fake: 0.160 acc_grfake: 0.954 
validation accuracies:
                gf: 0.97
                real: 0.67
                fake: 0.96

ran validation set (B:701) in                         46.0 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 3 / 30 	 Time Taken: 248 sec
(epoch: 4, batches: 20, time: 0.006, data: 0.003) loss_G_comp: 0.545 loss_G_anti_sc: 0.444 loss_G: 1.017 loss_D_real: 0.758 loss_D_fake: 0.876 loss_D: 1.896 acc_real: 0.668 acc_fake: 0.957 loss_G_conf: 0.028 loss_AUX: 0.209 loss_D_gr_fake: 0.053 acc_grfake: 0.970 
(epoch: 4, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.623 loss_G_anti_sc: 0.186 loss_G: 0.836 loss_D_real: 0.525 loss_D_fake: 1.098 loss_D: 1.974 acc_real: 0.668 acc_fake: 0.957 loss_G_conf: 0.027 loss_AUX: 0.221 loss_D_gr_fake: 0.130 acc_grfake: 0.970 
(epoch: 4, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.580 loss_G_anti_sc: 0.197 loss_G: 0.805 loss_D_real: 0.550 loss_D_fake: 1.045 loss_D: 1.920 acc_real: 0.668 acc_fake: 0.957 loss_G_conf: 0.028 loss_AUX: 0.224 loss_D_gr_fake: 0.100 acc_grfake: 0.970 
(epoch: 4, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.611 loss_G_anti_sc: 0.204 loss_G: 0.841 loss_D_real: 0.513 loss_D_fake: 1.180 loss_D: 2.100 acc_real: 0.668 acc_fake: 0.957 loss_G_conf: 0.026 loss_AUX: 0.242 loss_D_gr_fake: 0.164 acc_grfake: 0.970 
validation accuracies:
                gf: 0.97
                real: 0.70
                fake: 0.57

ran validation set (B:801) in                         46.0 s.
(epoch: 4, batches: 100, time: 0.006, data: 0.003) loss_G_comp: 0.542 loss_G_anti_sc: 0.244 loss_G: 0.813 loss_D_real: 0.613 loss_D_fake: 1.029 loss_D: 1.940 acc_real: 0.700 acc_fake: 0.572 loss_G_conf: 0.027 loss_AUX: 0.236 loss_D_gr_fake: 0.062 acc_grfake: 0.966 
(epoch: 4, batches: 120, time: 0.007, data: 0.002) loss_G_comp: 0.546 loss_G_anti_sc: 0.328 loss_G: 0.901 loss_D_real: 0.686 loss_D_fake: 1.058 loss_D: 2.128 acc_real: 0.700 acc_fake: 0.572 loss_G_conf: 0.028 loss_AUX: 0.277 loss_D_gr_fake: 0.107 acc_grfake: 0.966 
(epoch: 4, batches: 140, time: 0.006, data: 0.004) loss_G_comp: 0.597 loss_G_anti_sc: 0.189 loss_G: 0.814 loss_D_real: 0.537 loss_D_fake: 1.231 loss_D: 2.137 acc_real: 0.700 acc_fake: 0.572 loss_G_conf: 0.028 loss_AUX: 0.259 loss_D_gr_fake: 0.110 acc_grfake: 0.966 
(epoch: 4, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.529 loss_G_anti_sc: 0.351 loss_G: 0.903 loss_D_real: 0.578 loss_D_fake: 1.051 loss_D: 1.932 acc_real: 0.700 acc_fake: 0.572 loss_G_conf: 0.024 loss_AUX: 0.211 loss_D_gr_fake: 0.092 acc_grfake: 0.966 
(epoch: 4, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.565 loss_G_anti_sc: 0.138 loss_G: 0.728 loss_D_real: 0.572 loss_D_fake: 1.259 loss_D: 2.201 acc_real: 0.700 acc_fake: 0.572 loss_G_conf: 0.026 loss_AUX: 0.261 loss_D_gr_fake: 0.109 acc_grfake: 0.966 
validation accuracies:
                gf: 0.93
                real: 0.96
                fake: 0.20

ran validation set (B:901) in                         46.4 s.
(epoch: 4, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.213 loss_G: 0.773 loss_D_real: 0.523 loss_D_fake: 1.170 loss_D: 2.113 acc_real: 0.958 acc_fake: 0.198 loss_G_conf: 0.025 loss_AUX: 0.275 loss_D_gr_fake: 0.144 acc_grfake: 0.930 
(epoch: 4, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.213 loss_G: 0.773 loss_D_real: 0.527 loss_D_fake: 1.039 loss_D: 1.988 acc_real: 0.958 acc_fake: 0.198 loss_G_conf: 0.025 loss_AUX: 0.266 loss_D_gr_fake: 0.157 acc_grfake: 0.930 
learning rate 0.0001000 -> 0.0001000
End of epoch 4 / 30 	 Time Taken: 203 sec
(epoch: 5, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.213 loss_G: 0.773 loss_D_real: 0.534 loss_D_fake: 0.828 loss_D: 1.684 acc_real: 0.958 acc_fake: 0.198 loss_G_conf: 0.025 loss_AUX: 0.252 loss_D_gr_fake: 0.070 acc_grfake: 0.930 
(epoch: 5, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.535 loss_G_anti_sc: 0.213 loss_G: 0.773 loss_D_real: 0.542 loss_D_fake: 0.832 loss_D: 1.808 acc_real: 0.958 acc_fake: 0.198 loss_G_conf: 0.025 loss_AUX: 0.267 loss_D_gr_fake: 0.168 acc_grfake: 0.930 
(epoch: 5, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.213 loss_G: 0.773 loss_D_real: 0.559 loss_D_fake: 0.683 loss_D: 1.632 acc_real: 0.958 acc_fake: 0.198 loss_G_conf: 0.025 loss_AUX: 0.295 loss_D_gr_fake: 0.095 acc_grfake: 0.930 
validation accuracies:
                gf: 0.95
                real: 0.93
                fake: 0.81

ran validation set (B:1001) in                         46.3 s.
(epoch: 5, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.615 loss_G_anti_sc: 0.182 loss_G: 0.820 loss_D_real: 0.520 loss_D_fake: 1.207 loss_D: 2.113 acc_real: 0.935 acc_fake: 0.813 loss_G_conf: 0.024 loss_AUX: 0.234 loss_D_gr_fake: 0.152 acc_grfake: 0.947 
(epoch: 5, batches: 100, time: 0.007, data: 0.002) loss_G_comp: 0.522 loss_G_anti_sc: 0.320 loss_G: 0.868 loss_D_real: 0.557 loss_D_fake: 1.091 loss_D: 2.080 acc_real: 0.935 acc_fake: 0.813 loss_G_conf: 0.027 loss_AUX: 0.264 loss_D_gr_fake: 0.167 acc_grfake: 0.947 
(epoch: 5, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.747 loss_G_anti_sc: 0.197 loss_G: 0.968 loss_D_real: 0.588 loss_D_fake: 0.932 loss_D: 1.868 acc_real: 0.935 acc_fake: 0.813 loss_G_conf: 0.024 loss_AUX: 0.217 loss_D_gr_fake: 0.131 acc_grfake: 0.947 
(epoch: 5, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.261 loss_G: 0.828 loss_D_real: 0.524 loss_D_fake: 1.218 loss_D: 2.196 acc_real: 0.935 acc_fake: 0.813 loss_G_conf: 0.026 loss_AUX: 0.263 loss_D_gr_fake: 0.191 acc_grfake: 0.947 
(epoch: 5, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.572 loss_G_anti_sc: 0.187 loss_G: 0.784 loss_D_real: 0.528 loss_D_fake: 1.314 loss_D: 2.258 acc_real: 0.935 acc_fake: 0.813 loss_G_conf: 0.025 loss_AUX: 0.276 loss_D_gr_fake: 0.140 acc_grfake: 0.947 
validation accuracies:
                gf: 0.95
                real: 0.93
                fake: 0.32

ran validation set (B:1101) in                         45.8 s.
(epoch: 5, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.572 loss_G_anti_sc: 0.207 loss_G: 0.803 loss_D_real: 0.521 loss_D_fake: 0.988 loss_D: 1.890 acc_real: 0.932 acc_fake: 0.321 loss_G_conf: 0.024 loss_AUX: 0.268 loss_D_gr_fake: 0.113 acc_grfake: 0.946 
(epoch: 5, batches: 200, time: 0.007, data: 0.005) loss_G_comp: 0.572 loss_G_anti_sc: 0.207 loss_G: 0.803 loss_D_real: 0.512 loss_D_fake: 1.035 loss_D: 1.871 acc_real: 0.932 acc_fake: 0.321 loss_G_conf: 0.024 loss_AUX: 0.256 loss_D_gr_fake: 0.068 acc_grfake: 0.946 
(epoch: 5, batches: 220, time: 0.008, data: 0.007) loss_G_comp: 0.572 loss_G_anti_sc: 0.207 loss_G: 0.803 loss_D_real: 0.534 loss_D_fake: 0.763 loss_D: 1.774 acc_real: 0.932 acc_fake: 0.321 loss_G_conf: 0.024 loss_AUX: 0.294 loss_D_gr_fake: 0.184 acc_grfake: 0.946 
saving the model at the end of epoch 5, iters 74880
learning rate 0.0001000 -> 0.0001000
End of epoch 5 / 30 	 Time Taken: 203 sec
(epoch: 6, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.572 loss_G_anti_sc: 0.207 loss_G: 0.803 loss_D_real: 0.518 loss_D_fake: 0.812 loss_D: 1.659 acc_real: 0.932 acc_fake: 0.321 loss_G_conf: 0.024 loss_AUX: 0.252 loss_D_gr_fake: 0.077 acc_grfake: 0.946 
validation accuracies:
                gf: 0.95
                real: 0.86
                fake: 0.87

ran validation set (B:1201) in                         46.2 s.
(epoch: 6, batches: 40, time: 0.008, data: 0.005) loss_G_comp: 0.535 loss_G_anti_sc: 0.437 loss_G: 0.996 loss_D_real: 0.832 loss_D_fake: 0.878 loss_D: 2.005 acc_real: 0.860 acc_fake: 0.874 loss_G_conf: 0.024 loss_AUX: 0.244 loss_D_gr_fake: 0.051 acc_grfake: 0.953 
(epoch: 6, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.548 loss_G_anti_sc: 0.306 loss_G: 0.878 loss_D_real: 0.554 loss_D_fake: 1.103 loss_D: 2.091 acc_real: 0.860 acc_fake: 0.874 loss_G_conf: 0.024 loss_AUX: 0.287 loss_D_gr_fake: 0.148 acc_grfake: 0.953 
(epoch: 6, batches: 80, time: 0.008, data: 0.003) loss_G_comp: 0.643 loss_G_anti_sc: 0.236 loss_G: 0.905 loss_D_real: 0.557 loss_D_fake: 1.155 loss_D: 2.125 acc_real: 0.860 acc_fake: 0.874 loss_G_conf: 0.027 loss_AUX: 0.284 loss_D_gr_fake: 0.129 acc_grfake: 0.953 
(epoch: 6, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.551 loss_G_anti_sc: 0.170 loss_G: 0.747 loss_D_real: 0.552 loss_D_fake: 1.179 loss_D: 2.098 acc_real: 0.860 acc_fake: 0.874 loss_G_conf: 0.026 loss_AUX: 0.288 loss_D_gr_fake: 0.079 acc_grfake: 0.953 
(epoch: 6, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.555 loss_G_anti_sc: 0.276 loss_G: 0.853 loss_D_real: 0.566 loss_D_fake: 1.243 loss_D: 2.173 acc_real: 0.860 acc_fake: 0.874 loss_G_conf: 0.022 loss_AUX: 0.291 loss_D_gr_fake: 0.073 acc_grfake: 0.953 
validation accuracies:
                gf: 0.95
                real: 0.96
                fake: 0.24

ran validation set (B:1301) in                         46.2 s.
(epoch: 6, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.540 loss_G_anti_sc: 0.214 loss_G: 0.778 loss_D_real: 0.522 loss_D_fake: 0.917 loss_D: 1.876 acc_real: 0.958 acc_fake: 0.239 loss_G_conf: 0.024 loss_AUX: 0.287 loss_D_gr_fake: 0.150 acc_grfake: 0.952 
(epoch: 6, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.540 loss_G_anti_sc: 0.214 loss_G: 0.778 loss_D_real: 0.509 loss_D_fake: 1.021 loss_D: 1.864 acc_real: 0.958 acc_fake: 0.239 loss_G_conf: 0.024 loss_AUX: 0.266 loss_D_gr_fake: 0.068 acc_grfake: 0.952 
(epoch: 6, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.540 loss_G_anti_sc: 0.214 loss_G: 0.778 loss_D_real: 0.548 loss_D_fake: 0.761 loss_D: 1.602 acc_real: 0.958 acc_fake: 0.239 loss_G_conf: 0.024 loss_AUX: 0.260 loss_D_gr_fake: 0.033 acc_grfake: 0.952 
(epoch: 6, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.540 loss_G_anti_sc: 0.214 loss_G: 0.778 loss_D_real: 0.519 loss_D_fake: 0.794 loss_D: 1.720 acc_real: 0.958 acc_fake: 0.239 loss_G_conf: 0.024 loss_AUX: 0.287 loss_D_gr_fake: 0.119 acc_grfake: 0.952 
(epoch: 6, batches: 220, time: 0.007, data: 0.020) loss_G_comp: 0.540 loss_G_anti_sc: 0.214 loss_G: 0.778 loss_D_real: 0.509 loss_D_fake: 0.858 loss_D: 1.726 acc_real: 0.958 acc_fake: 0.239 loss_G_conf: 0.024 loss_AUX: 0.276 loss_D_gr_fake: 0.083 acc_grfake: 0.952 
validation accuracies:
                gf: 0.97
                real: 0.87
                fake: 0.85

ran validation set (B:1401) in                         45.9 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 6 / 30 	 Time Taken: 249 sec
(epoch: 7, batches: 20, time: 0.007, data: 0.008) loss_G_comp: 0.649 loss_G_anti_sc: 0.138 loss_G: 0.814 loss_D_real: 0.546 loss_D_fake: 1.108 loss_D: 2.079 acc_real: 0.872 acc_fake: 0.854 loss_G_conf: 0.026 loss_AUX: 0.302 loss_D_gr_fake: 0.123 acc_grfake: 0.967 
(epoch: 7, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.542 loss_G_anti_sc: 0.225 loss_G: 0.790 loss_D_real: 0.614 loss_D_fake: 1.021 loss_D: 1.914 acc_real: 0.872 acc_fake: 0.854 loss_G_conf: 0.023 loss_AUX: 0.234 loss_D_gr_fake: 0.045 acc_grfake: 0.967 
(epoch: 7, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.557 loss_G_anti_sc: 0.199 loss_G: 0.778 loss_D_real: 0.522 loss_D_fake: 1.262 loss_D: 2.120 acc_real: 0.872 acc_fake: 0.854 loss_G_conf: 0.021 loss_AUX: 0.238 loss_D_gr_fake: 0.099 acc_grfake: 0.967 
(epoch: 7, batches: 80, time: 0.006, data: 0.004) loss_G_comp: 0.540 loss_G_anti_sc: 0.252 loss_G: 0.814 loss_D_real: 0.572 loss_D_fake: 1.234 loss_D: 2.224 acc_real: 0.872 acc_fake: 0.854 loss_G_conf: 0.022 loss_AUX: 0.313 loss_D_gr_fake: 0.106 acc_grfake: 0.967 
validation accuracies:
                gf: 0.98
                real: 0.67
                fake: 0.47

ran validation set (B:1501) in                         46.0 s.
(epoch: 7, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.511 loss_D_fake: 1.440 loss_D: 2.368 acc_real: 0.669 acc_fake: 0.474 loss_G_conf: 0.023 loss_AUX: 0.256 loss_D_gr_fake: 0.161 acc_grfake: 0.980 
(epoch: 7, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.526 loss_D_fake: 1.376 loss_D: 2.325 acc_real: 0.669 acc_fake: 0.474 loss_G_conf: 0.023 loss_AUX: 0.289 loss_D_gr_fake: 0.134 acc_grfake: 0.980 
(epoch: 7, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.511 loss_D_fake: 1.381 loss_D: 2.302 acc_real: 0.669 acc_fake: 0.474 loss_G_conf: 0.023 loss_AUX: 0.257 loss_D_gr_fake: 0.153 acc_grfake: 0.980 
(epoch: 7, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.534 loss_D_fake: 1.251 loss_D: 2.166 acc_real: 0.669 acc_fake: 0.474 loss_G_conf: 0.023 loss_AUX: 0.276 loss_D_gr_fake: 0.105 acc_grfake: 0.980 
(epoch: 7, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.514 loss_D_fake: 1.289 loss_D: 2.082 acc_real: 0.669 acc_fake: 0.474 loss_G_conf: 0.023 loss_AUX: 0.254 loss_D_gr_fake: 0.026 acc_grfake: 0.980 
validation accuracies:
                gf: 0.95
                real: 0.98
                fake: 0.38

ran validation set (B:1601) in                         46.0 s.
(epoch: 7, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.511 loss_D_fake: 1.206 loss_D: 2.041 acc_real: 0.980 acc_fake: 0.378 loss_G_conf: 0.023 loss_AUX: 0.276 loss_D_gr_fake: 0.048 acc_grfake: 0.951 
(epoch: 7, batches: 220, time: 0.007, data: 0.007) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.512 loss_D_fake: 1.217 loss_D: 2.151 acc_real: 0.980 acc_fake: 0.378 loss_G_conf: 0.023 loss_AUX: 0.292 loss_D_gr_fake: 0.131 acc_grfake: 0.951 
learning rate 0.0001000 -> 0.0001000
End of epoch 7 / 30 	 Time Taken: 203 sec
(epoch: 8, batches: 20, time: 0.007, data: 0.005) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.549 loss_D_fake: 0.977 loss_D: 1.918 acc_real: 0.980 acc_fake: 0.378 loss_G_conf: 0.023 loss_AUX: 0.260 loss_D_gr_fake: 0.133 acc_grfake: 0.951 
(epoch: 8, batches: 40, time: 0.008, data: 0.002) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.515 loss_D_fake: 1.013 loss_D: 1.908 acc_real: 0.980 acc_fake: 0.378 loss_G_conf: 0.023 loss_AUX: 0.282 loss_D_gr_fake: 0.098 acc_grfake: 0.951 
(epoch: 8, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.653 loss_G_anti_sc: 0.090 loss_G: 0.766 loss_D_real: 0.514 loss_D_fake: 1.064 loss_D: 1.931 acc_real: 0.980 acc_fake: 0.378 loss_G_conf: 0.023 loss_AUX: 0.258 loss_D_gr_fake: 0.095 acc_grfake: 0.951 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.64

ran validation set (B:1701) in                         45.9 s.
(epoch: 8, batches: 80, time: 0.007, data: 0.001) loss_G_comp: 0.524 loss_G_anti_sc: 0.266 loss_G: 0.812 loss_D_real: 0.573 loss_D_fake: 1.154 loss_D: 2.033 acc_real: 0.968 acc_fake: 0.636 loss_G_conf: 0.022 loss_AUX: 0.279 loss_D_gr_fake: 0.027 acc_grfake: 0.948 
(epoch: 8, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.642 loss_G_anti_sc: 0.133 loss_G: 0.798 loss_D_real: 0.510 loss_D_fake: 1.370 loss_D: 2.277 acc_real: 0.968 acc_fake: 0.636 loss_G_conf: 0.023 loss_AUX: 0.289 loss_D_gr_fake: 0.108 acc_grfake: 0.948 
(epoch: 8, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.597 loss_G_anti_sc: 0.126 loss_G: 0.746 loss_D_real: 0.537 loss_D_fake: 1.229 loss_D: 2.065 acc_real: 0.968 acc_fake: 0.636 loss_G_conf: 0.023 loss_AUX: 0.279 loss_D_gr_fake: 0.020 acc_grfake: 0.948 
(epoch: 8, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.520 loss_G_anti_sc: 0.271 loss_G: 0.813 loss_D_real: 0.591 loss_D_fake: 1.069 loss_D: 2.032 acc_real: 0.968 acc_fake: 0.636 loss_G_conf: 0.021 loss_AUX: 0.275 loss_D_gr_fake: 0.097 acc_grfake: 0.948 
(epoch: 8, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.541 loss_G_anti_sc: 0.205 loss_G: 0.768 loss_D_real: 0.520 loss_D_fake: 1.435 loss_D: 2.343 acc_real: 0.968 acc_fake: 0.636 loss_G_conf: 0.023 loss_AUX: 0.283 loss_D_gr_fake: 0.105 acc_grfake: 0.948 
validation accuracies:
                gf: 0.98
                real: 0.71
                fake: 0.52

ran validation set (B:1801) in                         46.3 s.
(epoch: 8, batches: 180, time: 0.007, data: 0.018) loss_G_comp: 0.557 loss_G_anti_sc: 0.171 loss_G: 0.752 loss_D_real: 0.515 loss_D_fake: 1.282 loss_D: 2.281 acc_real: 0.707 acc_fake: 0.518 loss_G_conf: 0.024 loss_AUX: 0.340 loss_D_gr_fake: 0.145 acc_grfake: 0.979 
(epoch: 8, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.513 loss_G_anti_sc: 0.227 loss_G: 0.762 loss_D_real: 0.573 loss_D_fake: 1.206 loss_D: 2.105 acc_real: 0.707 acc_fake: 0.518 loss_G_conf: 0.022 loss_AUX: 0.278 loss_D_gr_fake: 0.048 acc_grfake: 0.979 
(epoch: 8, batches: 220, time: 0.008, data: 0.005) loss_G_comp: 0.535 loss_G_anti_sc: 0.168 loss_G: 0.725 loss_D_real: 0.546 loss_D_fake: 1.128 loss_D: 2.035 acc_real: 0.707 acc_fake: 0.518 loss_G_conf: 0.021 loss_AUX: 0.282 loss_D_gr_fake: 0.078 acc_grfake: 0.979 
learning rate 0.0001000 -> 0.0001000
End of epoch 8 / 30 	 Time Taken: 203 sec
(epoch: 9, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.532 loss_G_anti_sc: 0.326 loss_G: 0.879 loss_D_real: 0.507 loss_D_fake: 1.609 loss_D: 2.543 acc_real: 0.707 acc_fake: 0.518 loss_G_conf: 0.021 loss_AUX: 0.298 loss_D_gr_fake: 0.129 acc_grfake: 0.979 
validation accuracies:
                gf: 0.97
                real: 0.78
                fake: 0.42

ran validation set (B:1901) in                         46.3 s.
(epoch: 9, batches: 40, time: 0.007, data: 0.005) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.512 loss_D_fake: 1.374 loss_D: 2.358 acc_real: 0.781 acc_fake: 0.421 loss_G_conf: 0.022 loss_AUX: 0.286 loss_D_gr_fake: 0.186 acc_grfake: 0.967 
(epoch: 9, batches: 60, time: 0.007, data: 0.006) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.532 loss_D_fake: 1.384 loss_D: 2.266 acc_real: 0.781 acc_fake: 0.421 loss_G_conf: 0.022 loss_AUX: 0.277 loss_D_gr_fake: 0.073 acc_grfake: 0.967 
(epoch: 9, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.513 loss_D_fake: 1.360 loss_D: 2.289 acc_real: 0.781 acc_fake: 0.421 loss_G_conf: 0.022 loss_AUX: 0.276 loss_D_gr_fake: 0.140 acc_grfake: 0.967 
(epoch: 9, batches: 100, time: 0.008, data: 0.004) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.513 loss_D_fake: 1.300 loss_D: 2.195 acc_real: 0.781 acc_fake: 0.421 loss_G_conf: 0.022 loss_AUX: 0.274 loss_D_gr_fake: 0.108 acc_grfake: 0.967 
(epoch: 9, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.510 loss_D_fake: 1.313 loss_D: 2.230 acc_real: 0.781 acc_fake: 0.421 loss_G_conf: 0.022 loss_AUX: 0.279 loss_D_gr_fake: 0.129 acc_grfake: 0.967 
validation accuracies:
                gf: 0.95
                real: 0.94
                fake: 0.38

ran validation set (B:2001) in                         46.2 s.
(epoch: 9, batches: 140, time: 0.008, data: 0.003) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.521 loss_D_fake: 1.157 loss_D: 2.077 acc_real: 0.938 acc_fake: 0.376 loss_G_conf: 0.022 loss_AUX: 0.308 loss_D_gr_fake: 0.092 acc_grfake: 0.951 
(epoch: 9, batches: 160, time: 0.008, data: 0.003) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.512 loss_D_fake: 1.149 loss_D: 2.068 acc_real: 0.938 acc_fake: 0.376 loss_G_conf: 0.022 loss_AUX: 0.318 loss_D_gr_fake: 0.089 acc_grfake: 0.951 
(epoch: 9, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.525 loss_D_fake: 1.098 loss_D: 1.903 acc_real: 0.938 acc_fake: 0.376 loss_G_conf: 0.022 loss_AUX: 0.266 loss_D_gr_fake: 0.014 acc_grfake: 0.951 
(epoch: 9, batches: 200, time: 0.009, data: 0.019) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.545 loss_D_fake: 1.036 loss_D: 1.906 acc_real: 0.938 acc_fake: 0.376 loss_G_conf: 0.022 loss_AUX: 0.276 loss_D_gr_fake: 0.049 acc_grfake: 0.951 
(epoch: 9, batches: 220, time: 0.007, data: 0.005) loss_G_comp: 0.614 loss_G_anti_sc: 0.122 loss_G: 0.758 loss_D_real: 0.512 loss_D_fake: 1.041 loss_D: 1.863 acc_real: 0.938 acc_fake: 0.376 loss_G_conf: 0.022 loss_AUX: 0.258 loss_D_gr_fake: 0.052 acc_grfake: 0.951 
validation accuracies:
                gf: 0.96
                real: 0.91
                fake: 0.57

ran validation set (B:2101) in                         46.0 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 9 / 30 	 Time Taken: 251 sec
(epoch: 10, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.554 loss_G_anti_sc: 0.184 loss_G: 0.760 loss_D_real: 0.531 loss_D_fake: 1.212 loss_D: 2.144 acc_real: 0.906 acc_fake: 0.574 loss_G_conf: 0.022 loss_AUX: 0.295 loss_D_gr_fake: 0.105 acc_grfake: 0.957 
(epoch: 10, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.531 loss_G_anti_sc: 0.190 loss_G: 0.742 loss_D_real: 0.535 loss_D_fake: 1.373 loss_D: 2.344 acc_real: 0.906 acc_fake: 0.574 loss_G_conf: 0.021 loss_AUX: 0.317 loss_D_gr_fake: 0.120 acc_grfake: 0.957 
(epoch: 10, batches: 60, time: 0.007, data: 0.001) loss_G_comp: 0.519 loss_G_anti_sc: 0.509 loss_G: 1.047 loss_D_real: 0.675 loss_D_fake: 0.900 loss_D: 1.919 acc_real: 0.906 acc_fake: 0.574 loss_G_conf: 0.019 loss_AUX: 0.252 loss_D_gr_fake: 0.092 acc_grfake: 0.957 
(epoch: 10, batches: 80, time: 0.006, data: 0.003) loss_G_comp: 0.622 loss_G_anti_sc: 0.122 loss_G: 0.764 loss_D_real: 0.520 loss_D_fake: 1.277 loss_D: 2.257 acc_real: 0.906 acc_fake: 0.574 loss_G_conf: 0.020 loss_AUX: 0.351 loss_D_gr_fake: 0.109 acc_grfake: 0.957 
validation accuracies:
                gf: 0.98
                real: 0.69
                fake: 0.29

ran validation set (B:2201) in                         45.8 s.
(epoch: 10, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.566 loss_D_fake: 1.528 loss_D: 2.418 acc_real: 0.694 acc_fake: 0.287 loss_G_conf: 0.019 loss_AUX: 0.297 loss_D_gr_fake: 0.027 acc_grfake: 0.980 
(epoch: 10, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.508 loss_D_fake: 1.475 loss_D: 2.422 acc_real: 0.694 acc_fake: 0.287 loss_G_conf: 0.019 loss_AUX: 0.326 loss_D_gr_fake: 0.113 acc_grfake: 0.980 
(epoch: 10, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.510 loss_D_fake: 1.466 loss_D: 2.396 acc_real: 0.694 acc_fake: 0.287 loss_G_conf: 0.019 loss_AUX: 0.280 loss_D_gr_fake: 0.140 acc_grfake: 0.980 
(epoch: 10, batches: 160, time: 0.008, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.528 loss_D_fake: 1.408 loss_D: 2.310 acc_real: 0.694 acc_fake: 0.287 loss_G_conf: 0.019 loss_AUX: 0.297 loss_D_gr_fake: 0.077 acc_grfake: 0.980 
(epoch: 10, batches: 180, time: 0.008, data: 0.017) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.514 loss_D_fake: 1.319 loss_D: 2.112 acc_real: 0.694 acc_fake: 0.287 loss_G_conf: 0.019 loss_AUX: 0.250 loss_D_gr_fake: 0.029 acc_grfake: 0.980 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.16

ran validation set (B:2301) in                         46.2 s.
(epoch: 10, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.517 loss_D_fake: 1.366 loss_D: 2.263 acc_real: 0.967 acc_fake: 0.161 loss_G_conf: 0.019 loss_AUX: 0.282 loss_D_gr_fake: 0.099 acc_grfake: 0.954 
(epoch: 10, batches: 220, time: 0.008, data: 0.004) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.507 loss_D_fake: 1.329 loss_D: 2.224 acc_real: 0.967 acc_fake: 0.161 loss_G_conf: 0.019 loss_AUX: 0.305 loss_D_gr_fake: 0.083 acc_grfake: 0.954 
saving the model at the end of epoch 10, iters 149760
learning rate 0.0001000 -> 0.0001000
End of epoch 10 / 30 	 Time Taken: 204 sec
(epoch: 11, batches: 20, time: 0.007, data: 0.011) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.507 loss_D_fake: 1.347 loss_D: 2.260 acc_real: 0.967 acc_fake: 0.161 loss_G_conf: 0.019 loss_AUX: 0.281 loss_D_gr_fake: 0.125 acc_grfake: 0.954 
(epoch: 11, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.521 loss_D_fake: 1.289 loss_D: 2.239 acc_real: 0.967 acc_fake: 0.161 loss_G_conf: 0.019 loss_AUX: 0.291 loss_D_gr_fake: 0.137 acc_grfake: 0.954 
(epoch: 11, batches: 60, time: 0.011, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.514 loss_D_fake: 1.294 loss_D: 2.180 acc_real: 0.967 acc_fake: 0.161 loss_G_conf: 0.019 loss_AUX: 0.284 loss_D_gr_fake: 0.088 acc_grfake: 0.954 
validation accuracies:
                gf: 0.95
                real: 0.95
                fake: 0.36

ran validation set (B:2401) in                         46.2 s.
(epoch: 11, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.534 loss_D_fake: 1.189 loss_D: 2.118 acc_real: 0.954 acc_fake: 0.362 loss_G_conf: 0.019 loss_AUX: 0.280 loss_D_gr_fake: 0.115 acc_grfake: 0.955 
(epoch: 11, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.512 loss_D_fake: 1.149 loss_D: 2.020 acc_real: 0.954 acc_fake: 0.362 loss_G_conf: 0.019 loss_AUX: 0.261 loss_D_gr_fake: 0.098 acc_grfake: 0.955 
(epoch: 11, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.508 loss_D_fake: 1.291 loss_D: 2.147 acc_real: 0.954 acc_fake: 0.362 loss_G_conf: 0.019 loss_AUX: 0.254 loss_D_gr_fake: 0.094 acc_grfake: 0.955 
(epoch: 11, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.515 loss_D_fake: 1.200 loss_D: 2.063 acc_real: 0.954 acc_fake: 0.362 loss_G_conf: 0.019 loss_AUX: 0.258 loss_D_gr_fake: 0.090 acc_grfake: 0.955 
(epoch: 11, batches: 160, time: 0.010, data: 0.003) loss_G_comp: 0.561 loss_G_anti_sc: 0.045 loss_G: 0.625 loss_D_real: 0.508 loss_D_fake: 1.097 loss_D: 2.004 acc_real: 0.954 acc_fake: 0.362 loss_G_conf: 0.019 loss_AUX: 0.263 loss_D_gr_fake: 0.137 acc_grfake: 0.955 
validation accuracies:
                gf: 0.97
                real: 0.90
                fake: 0.56

ran validation set (B:2501) in                         46.0 s.
(epoch: 11, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.560 loss_G_anti_sc: 0.109 loss_G: 0.690 loss_D_real: 0.516 loss_D_fake: 1.452 loss_D: 2.318 acc_real: 0.902 acc_fake: 0.564 loss_G_conf: 0.021 loss_AUX: 0.293 loss_D_gr_fake: 0.057 acc_grfake: 0.968 
(epoch: 11, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.619 loss_G_anti_sc: 0.145 loss_G: 0.784 loss_D_real: 0.526 loss_D_fake: 1.369 loss_D: 2.342 acc_real: 0.902 acc_fake: 0.564 loss_G_conf: 0.021 loss_AUX: 0.382 loss_D_gr_fake: 0.065 acc_grfake: 0.968 
(epoch: 11, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.591 loss_G_anti_sc: 0.165 loss_G: 0.775 loss_D_real: 0.527 loss_D_fake: 1.433 loss_D: 2.336 acc_real: 0.902 acc_fake: 0.564 loss_G_conf: 0.019 loss_AUX: 0.271 loss_D_gr_fake: 0.105 acc_grfake: 0.968 
learning rate 0.0001000 -> 0.0001000
End of epoch 11 / 30 	 Time Taken: 203 sec
(epoch: 12, batches: 20, time: 0.007, data: 0.019) loss_G_comp: 0.548 loss_G_anti_sc: 0.481 loss_G: 1.048 loss_D_real: 0.739 loss_D_fake: 0.981 loss_D: 2.264 acc_real: 0.902 acc_fake: 0.564 loss_G_conf: 0.019 loss_AUX: 0.394 loss_D_gr_fake: 0.150 acc_grfake: 0.968 
validation accuracies:
                gf: 0.95
                real: 0.89
                fake: 0.23

ran validation set (B:2601) in                         46.1 s.
(epoch: 12, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.512 loss_D_fake: 1.327 loss_D: 2.428 acc_real: 0.887 acc_fake: 0.225 loss_G_conf: 0.020 loss_AUX: 0.387 loss_D_gr_fake: 0.202 acc_grfake: 0.948 
(epoch: 12, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.505 loss_D_fake: 1.349 loss_D: 2.218 acc_real: 0.887 acc_fake: 0.225 loss_G_conf: 0.020 loss_AUX: 0.259 loss_D_gr_fake: 0.104 acc_grfake: 0.948 
(epoch: 12, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.511 loss_D_fake: 1.141 loss_D: 1.957 acc_real: 0.887 acc_fake: 0.225 loss_G_conf: 0.020 loss_AUX: 0.275 loss_D_gr_fake: 0.030 acc_grfake: 0.948 
(epoch: 12, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.529 loss_D_fake: 1.024 loss_D: 1.899 acc_real: 0.887 acc_fake: 0.225 loss_G_conf: 0.020 loss_AUX: 0.319 loss_D_gr_fake: 0.026 acc_grfake: 0.948 
(epoch: 12, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.522 loss_D_fake: 1.068 loss_D: 1.897 acc_real: 0.887 acc_fake: 0.225 loss_G_conf: 0.020 loss_AUX: 0.299 loss_D_gr_fake: 0.008 acc_grfake: 0.948 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.40

ran validation set (B:2701) in                         46.1 s.
(epoch: 12, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.516 loss_D_fake: 1.225 loss_D: 2.205 acc_real: 0.990 acc_fake: 0.399 loss_G_conf: 0.020 loss_AUX: 0.274 loss_D_gr_fake: 0.190 acc_grfake: 0.955 
(epoch: 12, batches: 160, time: 0.008, data: 0.001) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.509 loss_D_fake: 1.113 loss_D: 2.041 acc_real: 0.990 acc_fake: 0.399 loss_G_conf: 0.020 loss_AUX: 0.323 loss_D_gr_fake: 0.096 acc_grfake: 0.955 
(epoch: 12, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.533 loss_D_fake: 0.980 loss_D: 1.875 acc_real: 0.990 acc_fake: 0.399 loss_G_conf: 0.020 loss_AUX: 0.303 loss_D_gr_fake: 0.059 acc_grfake: 0.955 
(epoch: 12, batches: 200, time: 0.008, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.507 loss_D_fake: 1.073 loss_D: 1.934 acc_real: 0.990 acc_fake: 0.399 loss_G_conf: 0.020 loss_AUX: 0.275 loss_D_gr_fake: 0.079 acc_grfake: 0.955 
(epoch: 12, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.535 loss_G_anti_sc: 0.182 loss_G: 0.737 loss_D_real: 0.512 loss_D_fake: 1.069 loss_D: 1.949 acc_real: 0.990 acc_fake: 0.399 loss_G_conf: 0.020 loss_AUX: 0.297 loss_D_gr_fake: 0.070 acc_grfake: 0.955 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.53

ran validation set (B:2801) in                         46.2 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 12 / 30 	 Time Taken: 250 sec
(epoch: 13, batches: 20, time: 0.007, data: 0.016) loss_G_comp: 0.645 loss_G_anti_sc: 0.078 loss_G: 0.744 loss_D_real: 0.519 loss_D_fake: 1.305 loss_D: 2.277 acc_real: 0.988 acc_fake: 0.530 loss_G_conf: 0.021 loss_AUX: 0.327 loss_D_gr_fake: 0.125 acc_grfake: 0.949 
(epoch: 13, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.534 loss_G_anti_sc: 0.151 loss_G: 0.704 loss_D_real: 0.520 loss_D_fake: 1.434 loss_D: 2.447 acc_real: 0.988 acc_fake: 0.530 loss_G_conf: 0.020 loss_AUX: 0.327 loss_D_gr_fake: 0.166 acc_grfake: 0.949 
(epoch: 13, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.140 loss_G: 0.683 loss_D_real: 0.508 loss_D_fake: 1.395 loss_D: 2.247 acc_real: 0.988 acc_fake: 0.530 loss_G_conf: 0.020 loss_AUX: 0.301 loss_D_gr_fake: 0.042 acc_grfake: 0.949 
(epoch: 13, batches: 80, time: 0.006, data: 0.004) loss_G_comp: 0.522 loss_G_anti_sc: 0.147 loss_G: 0.689 loss_D_real: 0.531 loss_D_fake: 1.343 loss_D: 2.353 acc_real: 0.988 acc_fake: 0.530 loss_G_conf: 0.020 loss_AUX: 0.328 loss_D_gr_fake: 0.150 acc_grfake: 0.949 
validation accuracies:
                gf: 0.96
                real: 0.88
                fake: 0.13

ran validation set (B:2901) in                         46.1 s.
(epoch: 13, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.517 loss_D_fake: 1.459 loss_D: 2.348 acc_real: 0.880 acc_fake: 0.132 loss_G_conf: 0.020 loss_AUX: 0.312 loss_D_gr_fake: 0.060 acc_grfake: 0.960 
(epoch: 13, batches: 120, time: 0.009, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.516 loss_D_fake: 1.442 loss_D: 2.299 acc_real: 0.880 acc_fake: 0.132 loss_G_conf: 0.020 loss_AUX: 0.315 loss_D_gr_fake: 0.026 acc_grfake: 0.960 
(epoch: 13, batches: 140, time: 0.008, data: 0.007) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.504 loss_D_fake: 1.493 loss_D: 2.433 acc_real: 0.880 acc_fake: 0.132 loss_G_conf: 0.020 loss_AUX: 0.321 loss_D_gr_fake: 0.115 acc_grfake: 0.960 
(epoch: 13, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.532 loss_D_fake: 1.279 loss_D: 2.220 acc_real: 0.880 acc_fake: 0.132 loss_G_conf: 0.020 loss_AUX: 0.338 loss_D_gr_fake: 0.071 acc_grfake: 0.960 
(epoch: 13, batches: 180, time: 0.007, data: 0.001) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.528 loss_D_fake: 1.400 loss_D: 2.358 acc_real: 0.880 acc_fake: 0.132 loss_G_conf: 0.020 loss_AUX: 0.300 loss_D_gr_fake: 0.130 acc_grfake: 0.960 
validation accuracies:
                gf: 0.96
                real: 0.96
                fake: 0.28

ran validation set (B:3001) in                         46.0 s.
(epoch: 13, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.513 loss_D_fake: 1.352 loss_D: 2.219 acc_real: 0.961 acc_fake: 0.282 loss_G_conf: 0.020 loss_AUX: 0.282 loss_D_gr_fake: 0.072 acc_grfake: 0.961 
(epoch: 13, batches: 220, time: 0.009, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.526 loss_D_fake: 1.264 loss_D: 2.108 acc_real: 0.961 acc_fake: 0.282 loss_G_conf: 0.020 loss_AUX: 0.276 loss_D_gr_fake: 0.042 acc_grfake: 0.961 
learning rate 0.0001000 -> 0.0001000
End of epoch 13 / 30 	 Time Taken: 203 sec
(epoch: 14, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.511 loss_D_fake: 1.241 loss_D: 2.088 acc_real: 0.961 acc_fake: 0.282 loss_G_conf: 0.020 loss_AUX: 0.299 loss_D_gr_fake: 0.037 acc_grfake: 0.961 
(epoch: 14, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.525 loss_D_fake: 1.182 loss_D: 2.048 acc_real: 0.961 acc_fake: 0.282 loss_G_conf: 0.020 loss_AUX: 0.292 loss_D_gr_fake: 0.048 acc_grfake: 0.961 
validation accuracies:
                gf: 0.98
                real: 0.89
                fake: 0.48

ran validation set (B:3101) in                         46.2 s.
(epoch: 14, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.520 loss_D_fake: 1.201 loss_D: 2.037 acc_real: 0.889 acc_fake: 0.481 loss_G_conf: 0.020 loss_AUX: 0.295 loss_D_gr_fake: 0.022 acc_grfake: 0.976 
(epoch: 14, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.510 loss_D_fake: 1.210 loss_D: 2.168 acc_real: 0.889 acc_fake: 0.481 loss_G_conf: 0.020 loss_AUX: 0.297 loss_D_gr_fake: 0.152 acc_grfake: 0.976 
(epoch: 14, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.513 loss_D_fake: 1.160 loss_D: 2.054 acc_real: 0.889 acc_fake: 0.481 loss_G_conf: 0.020 loss_AUX: 0.270 loss_D_gr_fake: 0.111 acc_grfake: 0.976 
(epoch: 14, batches: 120, time: 0.008, data: 0.005) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.506 loss_D_fake: 1.251 loss_D: 2.096 acc_real: 0.889 acc_fake: 0.481 loss_G_conf: 0.020 loss_AUX: 0.281 loss_D_gr_fake: 0.058 acc_grfake: 0.976 
(epoch: 14, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.530 loss_G_anti_sc: 0.193 loss_G: 0.743 loss_D_real: 0.509 loss_D_fake: 1.140 loss_D: 2.199 acc_real: 0.889 acc_fake: 0.481 loss_G_conf: 0.020 loss_AUX: 0.359 loss_D_gr_fake: 0.192 acc_grfake: 0.976 
validation accuracies:
                gf: 0.97
                real: 0.87
                fake: 0.64

ran validation set (B:3201) in                         46.1 s.
(epoch: 14, batches: 160, time: 0.006, data: 0.003) loss_G_comp: 0.692 loss_G_anti_sc: 0.128 loss_G: 0.838 loss_D_real: 0.553 loss_D_fake: 0.945 loss_D: 1.934 acc_real: 0.866 acc_fake: 0.639 loss_G_conf: 0.019 loss_AUX: 0.353 loss_D_gr_fake: 0.082 acc_grfake: 0.970 
(epoch: 14, batches: 180, time: 0.008, data: 0.003) loss_G_comp: 0.609 loss_G_anti_sc: 0.109 loss_G: 0.737 loss_D_real: 0.516 loss_D_fake: 1.310 loss_D: 2.190 acc_real: 0.866 acc_fake: 0.639 loss_G_conf: 0.019 loss_AUX: 0.326 loss_D_gr_fake: 0.038 acc_grfake: 0.970 
(epoch: 14, batches: 200, time: 0.007, data: 0.001) loss_G_comp: 0.575 loss_G_anti_sc: 0.124 loss_G: 0.719 loss_D_real: 0.512 loss_D_fake: 1.303 loss_D: 2.150 acc_real: 0.866 acc_fake: 0.639 loss_G_conf: 0.020 loss_AUX: 0.286 loss_D_gr_fake: 0.049 acc_grfake: 0.970 
(epoch: 14, batches: 220, time: 0.008, data: 0.004) loss_G_comp: 0.674 loss_G_anti_sc: 0.112 loss_G: 0.804 loss_D_real: 0.507 loss_D_fake: 1.507 loss_D: 2.505 acc_real: 0.866 acc_fake: 0.639 loss_G_conf: 0.019 loss_AUX: 0.329 loss_D_gr_fake: 0.162 acc_grfake: 0.970 
learning rate 0.0001000 -> 0.0001000
End of epoch 14 / 30 	 Time Taken: 204 sec
(epoch: 15, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.518 loss_G_anti_sc: 0.412 loss_G: 0.950 loss_D_real: 0.640 loss_D_fake: 0.825 loss_D: 1.806 acc_real: 0.866 acc_fake: 0.639 loss_G_conf: 0.020 loss_AUX: 0.323 loss_D_gr_fake: 0.018 acc_grfake: 0.970 
validation accuracies:
                gf: 0.99
                real: 0.08
                fake: 0.54

ran validation set (B:3301) in                         45.7 s.
(epoch: 15, batches: 40, time: 0.005, data: 0.017) loss_G_comp: 0.606 loss_G_anti_sc: 0.179 loss_G: 0.803 loss_D_real: 0.518 loss_D_fake: 1.216 loss_D: 1.987 acc_real: 0.084 acc_fake: 0.536 loss_G_conf: 0.019 loss_AUX: 0.253 loss_D_gr_fake: 0.134 acc_grfake: 0.994 
(epoch: 15, batches: 60, time: 0.005, data: 0.005) loss_G_comp: 0.551 loss_G_anti_sc: 0.152 loss_G: 0.722 loss_D_real: 0.510 loss_D_fake: 1.317 loss_D: 2.124 acc_real: 0.084 acc_fake: 0.536 loss_G_conf: 0.018 loss_AUX: 0.297 loss_D_gr_fake: 0.134 acc_grfake: 0.994 
(epoch: 15, batches: 80, time: 0.005, data: 0.001) loss_G_comp: 0.522 loss_G_anti_sc: 0.140 loss_G: 0.681 loss_D_real: 0.515 loss_D_fake: 1.179 loss_D: 1.980 acc_real: 0.084 acc_fake: 0.536 loss_G_conf: 0.018 loss_AUX: 0.285 loss_D_gr_fake: 0.134 acc_grfake: 0.994 
(epoch: 15, batches: 100, time: 0.005, data: 0.543) loss_G_comp: 0.526 loss_G_anti_sc: 0.197 loss_G: 0.741 loss_D_real: 0.515 loss_D_fake: 1.306 loss_D: 2.105 acc_real: 0.084 acc_fake: 0.536 loss_G_conf: 0.017 loss_AUX: 0.283 loss_D_gr_fake: 0.134 acc_grfake: 0.994 
(epoch: 15, batches: 120, time: 0.005, data: 0.254) loss_G_comp: 0.534 loss_G_anti_sc: 0.153 loss_G: 0.704 loss_D_real: 0.508 loss_D_fake: 1.413 loss_D: 2.217 acc_real: 0.084 acc_fake: 0.536 loss_G_conf: 0.018 loss_AUX: 0.296 loss_D_gr_fake: 0.134 acc_grfake: 0.994 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.10

ran validation set (B:3401) in                         46.8 s.
(epoch: 15, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.544 loss_G_anti_sc: 0.067 loss_G: 0.628 loss_D_real: 0.600 loss_D_fake: 0.778 loss_D: 1.825 acc_real: 0.992 acc_fake: 0.104 loss_G_conf: 0.018 loss_AUX: 0.353 loss_D_gr_fake: 0.095 acc_grfake: 0.935 
(epoch: 15, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.544 loss_G_anti_sc: 0.067 loss_G: 0.628 loss_D_real: 0.513 loss_D_fake: 0.839 loss_D: 1.791 acc_real: 0.992 acc_fake: 0.104 loss_G_conf: 0.018 loss_AUX: 0.357 loss_D_gr_fake: 0.082 acc_grfake: 0.935 
(epoch: 15, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.544 loss_G_anti_sc: 0.067 loss_G: 0.628 loss_D_real: 0.567 loss_D_fake: 0.818 loss_D: 1.818 acc_real: 0.992 acc_fake: 0.104 loss_G_conf: 0.018 loss_AUX: 0.360 loss_D_gr_fake: 0.073 acc_grfake: 0.935 
(epoch: 15, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.544 loss_G_anti_sc: 0.067 loss_G: 0.628 loss_D_real: 0.515 loss_D_fake: 0.848 loss_D: 1.712 acc_real: 0.992 acc_fake: 0.104 loss_G_conf: 0.018 loss_AUX: 0.319 loss_D_gr_fake: 0.030 acc_grfake: 0.935 
(epoch: 15, batches: 220, time: 0.007, data: 0.001) loss_G_comp: 0.544 loss_G_anti_sc: 0.067 loss_G: 0.628 loss_D_real: 0.507 loss_D_fake: 0.966 loss_D: 1.873 acc_real: 0.992 acc_fake: 0.104 loss_G_conf: 0.018 loss_AUX: 0.319 loss_D_gr_fake: 0.082 acc_grfake: 0.935 
validation accuracies:
                gf: 0.95
                real: 0.98
                fake: 0.69

ran validation set (B:3501) in                         45.8 s.
saving the model at the end of epoch 15, iters 224640
learning rate 0.0001000 -> 0.0001000
End of epoch 15 / 30 	 Time Taken: 239 sec
(epoch: 16, batches: 20, time: 0.007, data: 0.007) loss_G_comp: 0.543 loss_G_anti_sc: 0.138 loss_G: 0.700 loss_D_real: 0.526 loss_D_fake: 1.286 loss_D: 2.238 acc_real: 0.980 acc_fake: 0.688 loss_G_conf: 0.019 loss_AUX: 0.299 loss_D_gr_fake: 0.126 acc_grfake: 0.946 
(epoch: 16, batches: 40, time: 0.008, data: 0.001) loss_G_comp: 0.530 loss_G_anti_sc: 0.110 loss_G: 0.657 loss_D_real: 0.522 loss_D_fake: 1.288 loss_D: 2.163 acc_real: 0.980 acc_fake: 0.688 loss_G_conf: 0.017 loss_AUX: 0.324 loss_D_gr_fake: 0.029 acc_grfake: 0.946 
(epoch: 16, batches: 60, time: 0.007, data: 0.023) loss_G_comp: 0.595 loss_G_anti_sc: 0.047 loss_G: 0.660 loss_D_real: 0.530 loss_D_fake: 1.357 loss_D: 2.399 acc_real: 0.980 acc_fake: 0.688 loss_G_conf: 0.018 loss_AUX: 0.392 loss_D_gr_fake: 0.120 acc_grfake: 0.946 
(epoch: 16, batches: 80, time: 0.007, data: 0.001) loss_G_comp: 0.559 loss_G_anti_sc: 0.110 loss_G: 0.686 loss_D_real: 0.530 loss_D_fake: 1.257 loss_D: 2.171 acc_real: 0.980 acc_fake: 0.688 loss_G_conf: 0.017 loss_AUX: 0.315 loss_D_gr_fake: 0.068 acc_grfake: 0.946 
validation accuracies:
                gf: 0.94
                real: 0.96
                fake: 0.12

ran validation set (B:3601) in                         46.3 s.
(epoch: 16, batches: 100, time: 0.008, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.521 loss_D_fake: 1.380 loss_D: 2.327 acc_real: 0.956 acc_fake: 0.124 loss_G_conf: 0.018 loss_AUX: 0.380 loss_D_gr_fake: 0.047 acc_grfake: 0.941 
(epoch: 16, batches: 120, time: 0.007, data: 0.002) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.508 loss_D_fake: 1.245 loss_D: 2.170 acc_real: 0.956 acc_fake: 0.124 loss_G_conf: 0.018 loss_AUX: 0.338 loss_D_gr_fake: 0.079 acc_grfake: 0.941 
(epoch: 16, batches: 140, time: 0.007, data: 0.002) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.518 loss_D_fake: 1.210 loss_D: 2.175 acc_real: 0.956 acc_fake: 0.124 loss_G_conf: 0.018 loss_AUX: 0.374 loss_D_gr_fake: 0.073 acc_grfake: 0.941 
(epoch: 16, batches: 160, time: 0.008, data: 0.004) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.507 loss_D_fake: 1.318 loss_D: 2.257 acc_real: 0.956 acc_fake: 0.124 loss_G_conf: 0.018 loss_AUX: 0.306 loss_D_gr_fake: 0.125 acc_grfake: 0.941 
(epoch: 16, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.519 loss_D_fake: 1.142 loss_D: 2.014 acc_real: 0.956 acc_fake: 0.124 loss_G_conf: 0.018 loss_AUX: 0.280 loss_D_gr_fake: 0.074 acc_grfake: 0.941 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.25

ran validation set (B:3701) in                         45.9 s.
(epoch: 16, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.522 loss_D_fake: 1.153 loss_D: 2.100 acc_real: 0.974 acc_fake: 0.250 loss_G_conf: 0.018 loss_AUX: 0.345 loss_D_gr_fake: 0.081 acc_grfake: 0.949 
(epoch: 16, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.507 loss_D_fake: 1.228 loss_D: 2.114 acc_real: 0.974 acc_fake: 0.250 loss_G_conf: 0.018 loss_AUX: 0.298 loss_D_gr_fake: 0.080 acc_grfake: 0.949 
learning rate 0.0001000 -> 0.0001000
End of epoch 16 / 30 	 Time Taken: 204 sec
(epoch: 17, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.520 loss_D_fake: 1.183 loss_D: 2.146 acc_real: 0.974 acc_fake: 0.250 loss_G_conf: 0.018 loss_AUX: 0.332 loss_D_gr_fake: 0.111 acc_grfake: 0.949 
(epoch: 17, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.508 loss_D_fake: 1.099 loss_D: 1.985 acc_real: 0.974 acc_fake: 0.250 loss_G_conf: 0.018 loss_AUX: 0.320 loss_D_gr_fake: 0.058 acc_grfake: 0.949 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.48

ran validation set (B:3801) in                         46.1 s.
(epoch: 17, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.531 loss_D_fake: 0.973 loss_D: 1.978 acc_real: 0.978 acc_fake: 0.476 loss_G_conf: 0.018 loss_AUX: 0.346 loss_D_gr_fake: 0.129 acc_grfake: 0.957 
(epoch: 17, batches: 80, time: 0.008, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.508 loss_D_fake: 1.078 loss_D: 1.956 acc_real: 0.978 acc_fake: 0.476 loss_G_conf: 0.018 loss_AUX: 0.302 loss_D_gr_fake: 0.069 acc_grfake: 0.957 
(epoch: 17, batches: 100, time: 0.008, data: 0.003) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.526 loss_D_fake: 1.128 loss_D: 2.043 acc_real: 0.978 acc_fake: 0.476 loss_G_conf: 0.018 loss_AUX: 0.336 loss_D_gr_fake: 0.054 acc_grfake: 0.957 
(epoch: 17, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.545 loss_D_fake: 0.758 loss_D: 1.707 acc_real: 0.978 acc_fake: 0.476 loss_G_conf: 0.018 loss_AUX: 0.365 loss_D_gr_fake: 0.039 acc_grfake: 0.957 
(epoch: 17, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.536 loss_G_anti_sc: 0.128 loss_G: 0.682 loss_D_real: 0.519 loss_D_fake: 0.960 loss_D: 1.828 acc_real: 0.978 acc_fake: 0.476 loss_G_conf: 0.018 loss_AUX: 0.318 loss_D_gr_fake: 0.030 acc_grfake: 0.957 
validation accuracies:
                gf: 0.96
                real: 0.96
                fake: 0.59

ran validation set (B:3901) in                         46.2 s.
(epoch: 17, batches: 160, time: 0.006, data: 0.003) loss_G_comp: 0.513 loss_G_anti_sc: 0.659 loss_G: 1.189 loss_D_real: 0.522 loss_D_fake: 1.046 loss_D: 1.939 acc_real: 0.961 acc_fake: 0.589 loss_G_conf: 0.017 loss_AUX: 0.280 loss_D_gr_fake: 0.092 acc_grfake: 0.961 
(epoch: 17, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.527 loss_G_anti_sc: 0.110 loss_G: 0.655 loss_D_real: 0.507 loss_D_fake: 1.468 loss_D: 2.589 acc_real: 0.961 acc_fake: 0.589 loss_G_conf: 0.018 loss_AUX: 0.383 loss_D_gr_fake: 0.232 acc_grfake: 0.961 
(epoch: 17, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.546 loss_G_anti_sc: 0.058 loss_G: 0.622 loss_D_real: 0.511 loss_D_fake: 1.384 loss_D: 2.299 acc_real: 0.961 acc_fake: 0.589 loss_G_conf: 0.018 loss_AUX: 0.325 loss_D_gr_fake: 0.079 acc_grfake: 0.961 
(epoch: 17, batches: 220, time: 0.007, data: 0.001) loss_G_comp: 0.537 loss_G_anti_sc: 0.144 loss_G: 0.700 loss_D_real: 0.533 loss_D_fake: 1.340 loss_D: 2.363 acc_real: 0.961 acc_fake: 0.589 loss_G_conf: 0.019 loss_AUX: 0.403 loss_D_gr_fake: 0.088 acc_grfake: 0.961 
learning rate 0.0001000 -> 0.0001000
End of epoch 17 / 30 	 Time Taken: 203 sec
(epoch: 18, batches: 20, time: 0.007, data: 0.033) loss_G_comp: 0.573 loss_G_anti_sc: 0.057 loss_G: 0.647 loss_D_real: 0.530 loss_D_fake: 1.509 loss_D: 2.382 acc_real: 0.961 acc_fake: 0.589 loss_G_conf: 0.017 loss_AUX: 0.285 loss_D_gr_fake: 0.058 acc_grfake: 0.961 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.04

ran validation set (B:4001) in                         46.4 s.
(epoch: 18, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.511 loss_D_fake: 1.417 loss_D: 2.401 acc_real: 0.990 acc_fake: 0.036 loss_G_conf: 0.018 loss_AUX: 0.345 loss_D_gr_fake: 0.128 acc_grfake: 0.951 
(epoch: 18, batches: 60, time: 0.007, data: 0.006) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.518 loss_D_fake: 1.450 loss_D: 2.423 acc_real: 0.990 acc_fake: 0.036 loss_G_conf: 0.018 loss_AUX: 0.322 loss_D_gr_fake: 0.133 acc_grfake: 0.951 
(epoch: 18, batches: 80, time: 0.007, data: 0.001) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.518 loss_D_fake: 1.370 loss_D: 2.261 acc_real: 0.990 acc_fake: 0.036 loss_G_conf: 0.018 loss_AUX: 0.320 loss_D_gr_fake: 0.053 acc_grfake: 0.951 
(epoch: 18, batches: 100, time: 0.007, data: 0.006) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.528 loss_D_fake: 1.322 loss_D: 2.276 acc_real: 0.990 acc_fake: 0.036 loss_G_conf: 0.018 loss_AUX: 0.343 loss_D_gr_fake: 0.083 acc_grfake: 0.951 
(epoch: 18, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.521 loss_D_fake: 1.290 loss_D: 2.214 acc_real: 0.990 acc_fake: 0.036 loss_G_conf: 0.018 loss_AUX: 0.330 loss_D_gr_fake: 0.073 acc_grfake: 0.951 
validation accuracies:
                gf: 0.97
                real: 0.92
                fake: 0.27

ran validation set (B:4101) in                         46.2 s.
(epoch: 18, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.526 loss_D_fake: 1.346 loss_D: 2.278 acc_real: 0.917 acc_fake: 0.268 loss_G_conf: 0.018 loss_AUX: 0.313 loss_D_gr_fake: 0.092 acc_grfake: 0.968 
(epoch: 18, batches: 160, time: 0.008, data: 0.005) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.524 loss_D_fake: 1.392 loss_D: 2.275 acc_real: 0.917 acc_fake: 0.268 loss_G_conf: 0.018 loss_AUX: 0.315 loss_D_gr_fake: 0.044 acc_grfake: 0.968 
(epoch: 18, batches: 180, time: 0.007, data: 0.002) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.522 loss_D_fake: 1.269 loss_D: 2.188 acc_real: 0.917 acc_fake: 0.268 loss_G_conf: 0.018 loss_AUX: 0.290 loss_D_gr_fake: 0.106 acc_grfake: 0.968 
(epoch: 18, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.507 loss_D_fake: 1.311 loss_D: 2.152 acc_real: 0.917 acc_fake: 0.268 loss_G_conf: 0.018 loss_AUX: 0.295 loss_D_gr_fake: 0.039 acc_grfake: 0.968 
(epoch: 18, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.505 loss_D_fake: 1.386 loss_D: 2.266 acc_real: 0.917 acc_fake: 0.268 loss_G_conf: 0.018 loss_AUX: 0.300 loss_D_gr_fake: 0.076 acc_grfake: 0.968 
validation accuracies:
                gf: 0.96
                real: 0.97
                fake: 0.27

ran validation set (B:4201) in                         46.3 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 18 / 30 	 Time Taken: 251 sec
(epoch: 19, batches: 20, time: 0.008, data: 0.001) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.505 loss_D_fake: 1.305 loss_D: 2.220 acc_real: 0.973 acc_fake: 0.266 loss_G_conf: 0.018 loss_AUX: 0.262 loss_D_gr_fake: 0.147 acc_grfake: 0.956 
(epoch: 19, batches: 40, time: 0.007, data: 0.005) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.519 loss_D_fake: 1.223 loss_D: 2.082 acc_real: 0.973 acc_fake: 0.266 loss_G_conf: 0.018 loss_AUX: 0.281 loss_D_gr_fake: 0.060 acc_grfake: 0.956 
(epoch: 19, batches: 60, time: 0.007, data: 0.007) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.505 loss_D_fake: 1.302 loss_D: 2.177 acc_real: 0.973 acc_fake: 0.266 loss_G_conf: 0.018 loss_AUX: 0.287 loss_D_gr_fake: 0.083 acc_grfake: 0.956 
(epoch: 19, batches: 80, time: 0.008, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.511 loss_D_fake: 1.182 loss_D: 2.033 acc_real: 0.973 acc_fake: 0.266 loss_G_conf: 0.018 loss_AUX: 0.290 loss_D_gr_fake: 0.049 acc_grfake: 0.956 
validation accuracies:
                gf: 0.96
                real: 0.95
                fake: 0.35

ran validation set (B:4301) in                         46.2 s.
(epoch: 19, batches: 100, time: 0.008, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.512 loss_D_fake: 1.176 loss_D: 2.037 acc_real: 0.951 acc_fake: 0.355 loss_G_conf: 0.018 loss_AUX: 0.302 loss_D_gr_fake: 0.047 acc_grfake: 0.960 
(epoch: 19, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.528 loss_D_fake: 1.044 loss_D: 1.878 acc_real: 0.951 acc_fake: 0.355 loss_G_conf: 0.018 loss_AUX: 0.287 loss_D_gr_fake: 0.020 acc_grfake: 0.960 
(epoch: 19, batches: 140, time: 0.008, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.530 loss_D_fake: 1.198 loss_D: 2.098 acc_real: 0.951 acc_fake: 0.355 loss_G_conf: 0.018 loss_AUX: 0.336 loss_D_gr_fake: 0.034 acc_grfake: 0.960 
(epoch: 19, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.513 loss_D_fake: 1.261 loss_D: 2.219 acc_real: 0.951 acc_fake: 0.355 loss_G_conf: 0.018 loss_AUX: 0.331 loss_D_gr_fake: 0.113 acc_grfake: 0.960 
(epoch: 19, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.511 loss_D_fake: 1.153 loss_D: 2.048 acc_real: 0.951 acc_fake: 0.355 loss_G_conf: 0.018 loss_AUX: 0.333 loss_D_gr_fake: 0.051 acc_grfake: 0.960 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.38

ran validation set (B:4401) in                         45.9 s.
(epoch: 19, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.505 loss_D_fake: 1.261 loss_D: 2.219 acc_real: 0.984 acc_fake: 0.378 loss_G_conf: 0.018 loss_AUX: 0.318 loss_D_gr_fake: 0.135 acc_grfake: 0.960 
(epoch: 19, batches: 220, time: 0.007, data: 0.027) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.516 loss_D_fake: 1.021 loss_D: 1.979 acc_real: 0.984 acc_fake: 0.378 loss_G_conf: 0.018 loss_AUX: 0.348 loss_D_gr_fake: 0.095 acc_grfake: 0.960 
learning rate 0.0001000 -> 0.0001000
End of epoch 19 / 30 	 Time Taken: 204 sec
(epoch: 20, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.513 loss_D_fake: 1.123 loss_D: 2.071 acc_real: 0.984 acc_fake: 0.378 loss_G_conf: 0.018 loss_AUX: 0.338 loss_D_gr_fake: 0.098 acc_grfake: 0.960 
(epoch: 20, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.251 loss_G: 0.780 loss_D_real: 0.537 loss_D_fake: 0.934 loss_D: 1.927 acc_real: 0.984 acc_fake: 0.378 loss_G_conf: 0.018 loss_AUX: 0.348 loss_D_gr_fake: 0.108 acc_grfake: 0.960 
validation accuracies:
                gf: 0.96
                real: 0.97
                fake: 0.63

ran validation set (B:4501) in                         46.2 s.
(epoch: 20, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.530 loss_G_anti_sc: 0.200 loss_G: 0.748 loss_D_real: 0.506 loss_D_fake: 1.612 loss_D: 2.476 acc_real: 0.965 acc_fake: 0.629 loss_G_conf: 0.018 loss_AUX: 0.284 loss_D_gr_fake: 0.074 acc_grfake: 0.961 
(epoch: 20, batches: 80, time: 0.007, data: 0.002) loss_G_comp: 0.621 loss_G_anti_sc: 0.237 loss_G: 0.876 loss_D_real: 0.638 loss_D_fake: 0.922 loss_D: 2.190 acc_real: 0.965 acc_fake: 0.629 loss_G_conf: 0.017 loss_AUX: 0.408 loss_D_gr_fake: 0.223 acc_grfake: 0.961 
(epoch: 20, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.619 loss_G_anti_sc: 0.161 loss_G: 0.796 loss_D_real: 0.580 loss_D_fake: 1.170 loss_D: 2.275 acc_real: 0.965 acc_fake: 0.629 loss_G_conf: 0.017 loss_AUX: 0.374 loss_D_gr_fake: 0.151 acc_grfake: 0.961 
(epoch: 20, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.602 loss_G_anti_sc: 0.126 loss_G: 0.744 loss_D_real: 0.522 loss_D_fake: 1.473 loss_D: 2.517 acc_real: 0.965 acc_fake: 0.629 loss_G_conf: 0.017 loss_AUX: 0.353 loss_D_gr_fake: 0.169 acc_grfake: 0.961 
(epoch: 20, batches: 140, time: 0.008, data: 0.003) loss_G_comp: 0.603 loss_G_anti_sc: 0.085 loss_G: 0.706 loss_D_real: 0.533 loss_D_fake: 1.360 loss_D: 2.275 acc_real: 0.965 acc_fake: 0.629 loss_G_conf: 0.018 loss_AUX: 0.328 loss_D_gr_fake: 0.055 acc_grfake: 0.961 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.06

ran validation set (B:4601) in                         46.2 s.
(epoch: 20, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.520 loss_G_anti_sc: 0.160 loss_G: 0.696 loss_D_real: 0.523 loss_D_fake: 1.165 loss_D: 2.153 acc_real: 0.991 acc_fake: 0.059 loss_G_conf: 0.016 loss_AUX: 0.308 loss_D_gr_fake: 0.158 acc_grfake: 0.930 
(epoch: 20, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.520 loss_G_anti_sc: 0.160 loss_G: 0.696 loss_D_real: 0.584 loss_D_fake: 0.921 loss_D: 1.835 acc_real: 0.991 acc_fake: 0.059 loss_G_conf: 0.016 loss_AUX: 0.290 loss_D_gr_fake: 0.040 acc_grfake: 0.930 
(epoch: 20, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.520 loss_G_anti_sc: 0.160 loss_G: 0.696 loss_D_real: 0.517 loss_D_fake: 1.129 loss_D: 2.150 acc_real: 0.991 acc_fake: 0.059 loss_G_conf: 0.016 loss_AUX: 0.374 loss_D_gr_fake: 0.131 acc_grfake: 0.930 
(epoch: 20, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.520 loss_G_anti_sc: 0.160 loss_G: 0.696 loss_D_real: 0.515 loss_D_fake: 1.030 loss_D: 1.991 acc_real: 0.991 acc_fake: 0.059 loss_G_conf: 0.016 loss_AUX: 0.360 loss_D_gr_fake: 0.087 acc_grfake: 0.930 
saving the model at the end of epoch 20, iters 299520
learning rate 0.0001000 -> 0.0000800
End of epoch 20 / 30 	 Time Taken: 204 sec
(epoch: 21, batches: 20, time: 0.012, data: 0.001) loss_G_comp: 0.520 loss_G_anti_sc: 0.160 loss_G: 0.696 loss_D_real: 0.522 loss_D_fake: 0.946 loss_D: 1.806 acc_real: 0.991 acc_fake: 0.059 loss_G_conf: 0.016 loss_AUX: 0.334 loss_D_gr_fake: 0.004 acc_grfake: 0.930 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.53

ran validation set (B:4701) in                         46.1 s.
(epoch: 21, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.551 loss_G_anti_sc: 0.238 loss_G: 0.807 loss_D_real: 0.528 loss_D_fake: 1.328 loss_D: 2.278 acc_real: 0.970 acc_fake: 0.533 loss_G_conf: 0.017 loss_AUX: 0.317 loss_D_gr_fake: 0.106 acc_grfake: 0.951 
(epoch: 21, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.511 loss_G_anti_sc: 0.214 loss_G: 0.741 loss_D_real: 0.584 loss_D_fake: 1.234 loss_D: 2.197 acc_real: 0.970 acc_fake: 0.533 loss_G_conf: 0.015 loss_AUX: 0.293 loss_D_gr_fake: 0.086 acc_grfake: 0.951 
(epoch: 21, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.516 loss_G_anti_sc: 0.180 loss_G: 0.711 loss_D_real: 0.505 loss_D_fake: 1.627 loss_D: 2.626 acc_real: 0.970 acc_fake: 0.533 loss_G_conf: 0.015 loss_AUX: 0.344 loss_D_gr_fake: 0.150 acc_grfake: 0.951 
(epoch: 21, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.545 loss_G_anti_sc: 0.113 loss_G: 0.675 loss_D_real: 0.511 loss_D_fake: 1.514 loss_D: 2.426 acc_real: 0.970 acc_fake: 0.533 loss_G_conf: 0.017 loss_AUX: 0.310 loss_D_gr_fake: 0.091 acc_grfake: 0.951 
(epoch: 21, batches: 120, time: 0.010, data: 0.003) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.518 loss_D_fake: 1.326 loss_D: 2.165 acc_real: 0.970 acc_fake: 0.533 loss_G_conf: 0.017 loss_AUX: 0.307 loss_D_gr_fake: 0.013 acc_grfake: 0.951 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.13

ran validation set (B:4801) in                         46.1 s.
(epoch: 21, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.516 loss_D_fake: 1.135 loss_D: 2.056 acc_real: 0.980 acc_fake: 0.134 loss_G_conf: 0.017 loss_AUX: 0.376 loss_D_gr_fake: 0.029 acc_grfake: 0.957 
(epoch: 21, batches: 160, time: 0.008, data: 0.001) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.548 loss_D_fake: 1.086 loss_D: 2.050 acc_real: 0.980 acc_fake: 0.134 loss_G_conf: 0.017 loss_AUX: 0.361 loss_D_gr_fake: 0.055 acc_grfake: 0.957 
(epoch: 21, batches: 180, time: 0.008, data: 0.004) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.532 loss_D_fake: 0.931 loss_D: 1.909 acc_real: 0.980 acc_fake: 0.134 loss_G_conf: 0.017 loss_AUX: 0.371 loss_D_gr_fake: 0.074 acc_grfake: 0.957 
(epoch: 21, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.528 loss_D_fake: 0.997 loss_D: 2.018 acc_real: 0.980 acc_fake: 0.134 loss_G_conf: 0.017 loss_AUX: 0.373 loss_D_gr_fake: 0.119 acc_grfake: 0.957 
(epoch: 21, batches: 220, time: 0.011, data: 0.003) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.571 loss_D_fake: 1.004 loss_D: 1.962 acc_real: 0.980 acc_fake: 0.134 loss_G_conf: 0.017 loss_AUX: 0.289 loss_D_gr_fake: 0.098 acc_grfake: 0.957 
validation accuracies:
                gf: 0.96
                real: 0.99
                fake: 0.37

ran validation set (B:4901) in                         46.2 s.
learning rate 0.0000800 -> 0.0000800
End of epoch 21 / 30 	 Time Taken: 249 sec
(epoch: 22, batches: 20, time: 0.007, data: 0.005) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.512 loss_D_fake: 1.028 loss_D: 1.893 acc_real: 0.993 acc_fake: 0.370 loss_G_conf: 0.017 loss_AUX: 0.323 loss_D_gr_fake: 0.030 acc_grfake: 0.956 
(epoch: 22, batches: 40, time: 0.008, data: 0.003) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.515 loss_D_fake: 0.957 loss_D: 2.028 acc_real: 0.993 acc_fake: 0.370 loss_G_conf: 0.017 loss_AUX: 0.383 loss_D_gr_fake: 0.173 acc_grfake: 0.956 
(epoch: 22, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.632 loss_D_fake: 0.777 loss_D: 1.755 acc_real: 0.993 acc_fake: 0.370 loss_G_conf: 0.017 loss_AUX: 0.316 loss_D_gr_fake: 0.031 acc_grfake: 0.956 
(epoch: 22, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.534 loss_G_anti_sc: 0.155 loss_G: 0.706 loss_D_real: 0.541 loss_D_fake: 0.846 loss_D: 1.732 acc_real: 0.993 acc_fake: 0.370 loss_G_conf: 0.017 loss_AUX: 0.329 loss_D_gr_fake: 0.016 acc_grfake: 0.956 
validation accuracies:
                gf: 0.97
                real: 0.98
                fake: 0.59

ran validation set (B:5001) in                         46.1 s.
(epoch: 22, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.611 loss_G_anti_sc: 0.133 loss_G: 0.762 loss_D_real: 0.515 loss_D_fake: 1.315 loss_D: 2.186 acc_real: 0.976 acc_fake: 0.591 loss_G_conf: 0.019 loss_AUX: 0.283 loss_D_gr_fake: 0.073 acc_grfake: 0.967 
(epoch: 22, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.570 loss_G_anti_sc: 0.105 loss_G: 0.691 loss_D_real: 0.519 loss_D_fake: 1.320 loss_D: 2.228 acc_real: 0.976 acc_fake: 0.591 loss_G_conf: 0.016 loss_AUX: 0.293 loss_D_gr_fake: 0.095 acc_grfake: 0.967 
(epoch: 22, batches: 140, time: 0.007, data: 0.001) loss_G_comp: 0.559 loss_G_anti_sc: 0.110 loss_G: 0.685 loss_D_real: 0.519 loss_D_fake: 1.326 loss_D: 2.214 acc_real: 0.976 acc_fake: 0.591 loss_G_conf: 0.016 loss_AUX: 0.310 loss_D_gr_fake: 0.060 acc_grfake: 0.967 
(epoch: 22, batches: 160, time: 0.007, data: 0.001) loss_G_comp: 0.514 loss_G_anti_sc: 0.181 loss_G: 0.710 loss_D_real: 0.525 loss_D_fake: 1.410 loss_D: 2.303 acc_real: 0.976 acc_fake: 0.591 loss_G_conf: 0.015 loss_AUX: 0.342 loss_D_gr_fake: 0.026 acc_grfake: 0.967 
(epoch: 22, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.580 loss_G_anti_sc: 0.116 loss_G: 0.711 loss_D_real: 0.517 loss_D_fake: 1.421 loss_D: 2.399 acc_real: 0.976 acc_fake: 0.591 loss_G_conf: 0.016 loss_AUX: 0.382 loss_D_gr_fake: 0.079 acc_grfake: 0.967 
validation accuracies:
                gf: 0.96
                real: 0.95
                fake: 0.22

ran validation set (B:5101) in                         46.2 s.
(epoch: 22, batches: 200, time: 0.007, data: 0.020) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.508 loss_D_fake: 1.509 loss_D: 2.456 acc_real: 0.949 acc_fake: 0.223 loss_G_conf: 0.016 loss_AUX: 0.314 loss_D_gr_fake: 0.124 acc_grfake: 0.955 
(epoch: 22, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.506 loss_D_fake: 1.506 loss_D: 2.483 acc_real: 0.949 acc_fake: 0.223 loss_G_conf: 0.016 loss_AUX: 0.343 loss_D_gr_fake: 0.128 acc_grfake: 0.955 
learning rate 0.0000800 -> 0.0000800
End of epoch 22 / 30 	 Time Taken: 204 sec
(epoch: 23, batches: 20, time: 0.007, data: 0.002) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.515 loss_D_fake: 1.352 loss_D: 2.276 acc_real: 0.949 acc_fake: 0.223 loss_G_conf: 0.016 loss_AUX: 0.344 loss_D_gr_fake: 0.065 acc_grfake: 0.955 
(epoch: 23, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.511 loss_D_fake: 1.334 loss_D: 2.150 acc_real: 0.949 acc_fake: 0.223 loss_G_conf: 0.016 loss_AUX: 0.274 loss_D_gr_fake: 0.032 acc_grfake: 0.955 
validation accuracies:
                gf: 0.96
                real: 0.95
                fake: 0.22

ran validation set (B:5201) in                         46.2 s.
(epoch: 23, batches: 60, time: 0.008, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.527 loss_D_fake: 1.415 loss_D: 2.370 acc_real: 0.955 acc_fake: 0.218 loss_G_conf: 0.016 loss_AUX: 0.325 loss_D_gr_fake: 0.102 acc_grfake: 0.958 
(epoch: 23, batches: 80, time: 0.007, data: 0.005) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.512 loss_D_fake: 1.353 loss_D: 2.262 acc_real: 0.955 acc_fake: 0.218 loss_G_conf: 0.016 loss_AUX: 0.306 loss_D_gr_fake: 0.091 acc_grfake: 0.958 
(epoch: 23, batches: 100, time: 0.007, data: 0.001) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.514 loss_D_fake: 1.161 loss_D: 2.086 acc_real: 0.955 acc_fake: 0.218 loss_G_conf: 0.016 loss_AUX: 0.357 loss_D_gr_fake: 0.053 acc_grfake: 0.958 
(epoch: 23, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.506 loss_D_fake: 1.379 loss_D: 2.267 acc_real: 0.955 acc_fake: 0.218 loss_G_conf: 0.016 loss_AUX: 0.353 loss_D_gr_fake: 0.028 acc_grfake: 0.958 
(epoch: 23, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.514 loss_D_fake: 1.235 loss_D: 2.097 acc_real: 0.955 acc_fake: 0.218 loss_G_conf: 0.016 loss_AUX: 0.334 loss_D_gr_fake: 0.013 acc_grfake: 0.958 
validation accuracies:
                gf: 0.96
                real: 0.96
                fake: 0.33

ran validation set (B:5301) in                         46.0 s.
(epoch: 23, batches: 160, time: 0.008, data: 0.002) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.509 loss_D_fake: 1.316 loss_D: 2.241 acc_real: 0.956 acc_fake: 0.325 loss_G_conf: 0.016 loss_AUX: 0.341 loss_D_gr_fake: 0.074 acc_grfake: 0.961 
(epoch: 23, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.523 loss_D_fake: 1.090 loss_D: 1.964 acc_real: 0.956 acc_fake: 0.325 loss_G_conf: 0.016 loss_AUX: 0.280 loss_D_gr_fake: 0.071 acc_grfake: 0.961 
(epoch: 23, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.513 loss_D_fake: 1.258 loss_D: 2.219 acc_real: 0.956 acc_fake: 0.325 loss_G_conf: 0.016 loss_AUX: 0.363 loss_D_gr_fake: 0.085 acc_grfake: 0.961 
(epoch: 23, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.507 loss_D_fake: 1.288 loss_D: 2.233 acc_real: 0.956 acc_fake: 0.325 loss_G_conf: 0.016 loss_AUX: 0.401 loss_D_gr_fake: 0.037 acc_grfake: 0.961 
learning rate 0.0000800 -> 0.0000800
End of epoch 23 / 30 	 Time Taken: 205 sec
validation accuracies:
                gf: 0.97
                real: 0.96
                fake: 0.40

ran validation set (B:5401) in                         46.0 s.
(epoch: 24, batches: 20, time: 0.007, data: 0.004) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.530 loss_D_fake: 1.103 loss_D: 2.067 acc_real: 0.963 acc_fake: 0.400 loss_G_conf: 0.016 loss_AUX: 0.379 loss_D_gr_fake: 0.056 acc_grfake: 0.969 
(epoch: 24, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.509 loss_D_fake: 1.233 loss_D: 2.158 acc_real: 0.963 acc_fake: 0.400 loss_G_conf: 0.016 loss_AUX: 0.334 loss_D_gr_fake: 0.082 acc_grfake: 0.969 
(epoch: 24, batches: 60, time: 0.008, data: 0.011) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.513 loss_D_fake: 1.132 loss_D: 2.004 acc_real: 0.963 acc_fake: 0.400 loss_G_conf: 0.016 loss_AUX: 0.306 loss_D_gr_fake: 0.053 acc_grfake: 0.969 
(epoch: 24, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.512 loss_D_fake: 1.140 loss_D: 2.064 acc_real: 0.963 acc_fake: 0.400 loss_G_conf: 0.016 loss_AUX: 0.341 loss_D_gr_fake: 0.071 acc_grfake: 0.969 
(epoch: 24, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.523 loss_D_fake: 1.088 loss_D: 2.000 acc_real: 0.963 acc_fake: 0.400 loss_G_conf: 0.016 loss_AUX: 0.355 loss_D_gr_fake: 0.034 acc_grfake: 0.969 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.31

ran validation set (B:5501) in                         46.0 s.
(epoch: 24, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.504 loss_D_fake: 1.318 loss_D: 2.218 acc_real: 0.989 acc_fake: 0.309 loss_G_conf: 0.016 loss_AUX: 0.254 loss_D_gr_fake: 0.143 acc_grfake: 0.952 
(epoch: 24, batches: 140, time: 0.008, data: 0.026) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.539 loss_D_fake: 0.957 loss_D: 1.914 acc_real: 0.989 acc_fake: 0.309 loss_G_conf: 0.016 loss_AUX: 0.364 loss_D_gr_fake: 0.054 acc_grfake: 0.952 
(epoch: 24, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.510 loss_D_fake: 1.301 loss_D: 2.220 acc_real: 0.989 acc_fake: 0.309 loss_G_conf: 0.016 loss_AUX: 0.329 loss_D_gr_fake: 0.081 acc_grfake: 0.952 
(epoch: 24, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.513 loss_D_fake: 1.091 loss_D: 2.074 acc_real: 0.989 acc_fake: 0.309 loss_G_conf: 0.016 loss_AUX: 0.388 loss_D_gr_fake: 0.082 acc_grfake: 0.952 
(epoch: 24, batches: 200, time: 0.007, data: 0.003) loss_G_comp: 0.549 loss_G_anti_sc: 0.077 loss_G: 0.641 loss_D_real: 0.511 loss_D_fake: 0.931 loss_D: 1.880 acc_real: 0.989 acc_fake: 0.309 loss_G_conf: 0.016 loss_AUX: 0.351 loss_D_gr_fake: 0.086 acc_grfake: 0.952 
validation accuracies:
                gf: 0.97
                real: 0.91
                fake: 0.71

ran validation set (B:5601) in                         46.2 s.
(epoch: 24, batches: 220, time: 0.006, data: 0.003) loss_G_comp: 0.750 loss_G_anti_sc: 0.045 loss_G: 0.811 loss_D_real: 0.535 loss_D_fake: 0.886 loss_D: 1.754 acc_real: 0.909 acc_fake: 0.710 loss_G_conf: 0.015 loss_AUX: 0.292 loss_D_gr_fake: 0.041 acc_grfake: 0.974 
learning rate 0.0000800 -> 0.0000800
End of epoch 24 / 30 	 Time Taken: 251 sec
(epoch: 25, batches: 20, time: 0.008, data: 0.005) loss_G_comp: 0.517 loss_G_anti_sc: 0.184 loss_G: 0.716 loss_D_real: 0.510 loss_D_fake: 1.539 loss_D: 2.560 acc_real: 0.909 acc_fake: 0.710 loss_G_conf: 0.015 loss_AUX: 0.396 loss_D_gr_fake: 0.115 acc_grfake: 0.974 
(epoch: 25, batches: 40, time: 0.007, data: 0.004) loss_G_comp: 0.530 loss_G_anti_sc: 0.125 loss_G: 0.670 loss_D_real: 0.520 loss_D_fake: 1.454 loss_D: 2.362 acc_real: 0.909 acc_fake: 0.710 loss_G_conf: 0.015 loss_AUX: 0.342 loss_D_gr_fake: 0.046 acc_grfake: 0.974 
(epoch: 25, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.540 loss_G_anti_sc: 0.096 loss_G: 0.652 loss_D_real: 0.541 loss_D_fake: 1.425 loss_D: 2.421 acc_real: 0.909 acc_fake: 0.710 loss_G_conf: 0.016 loss_AUX: 0.430 loss_D_gr_fake: 0.024 acc_grfake: 0.974 
(epoch: 25, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.522 loss_G_anti_sc: 0.151 loss_G: 0.689 loss_D_real: 0.529 loss_D_fake: 1.155 loss_D: 2.008 acc_real: 0.909 acc_fake: 0.710 loss_G_conf: 0.016 loss_AUX: 0.296 loss_D_gr_fake: 0.027 acc_grfake: 0.974 
validation accuracies:
                gf: 0.97
                real: 0.97
                fake: 0.10

ran validation set (B:5701) in                         46.1 s.
(epoch: 25, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.504 loss_D_fake: 1.517 loss_D: 2.493 acc_real: 0.966 acc_fake: 0.100 loss_G_conf: 0.015 loss_AUX: 0.349 loss_D_gr_fake: 0.123 acc_grfake: 0.972 
(epoch: 25, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.509 loss_D_fake: 1.223 loss_D: 2.222 acc_real: 0.966 acc_fake: 0.100 loss_G_conf: 0.015 loss_AUX: 0.394 loss_D_gr_fake: 0.095 acc_grfake: 0.972 
(epoch: 25, batches: 140, time: 0.008, data: 0.015) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.504 loss_D_fake: 1.300 loss_D: 2.166 acc_real: 0.966 acc_fake: 0.100 loss_G_conf: 0.015 loss_AUX: 0.313 loss_D_gr_fake: 0.049 acc_grfake: 0.972 
(epoch: 25, batches: 160, time: 0.007, data: 0.006) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.505 loss_D_fake: 1.239 loss_D: 2.138 acc_real: 0.966 acc_fake: 0.100 loss_G_conf: 0.015 loss_AUX: 0.314 loss_D_gr_fake: 0.080 acc_grfake: 0.972 
(epoch: 25, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.513 loss_D_fake: 1.236 loss_D: 2.174 acc_real: 0.966 acc_fake: 0.100 loss_G_conf: 0.015 loss_AUX: 0.346 loss_D_gr_fake: 0.079 acc_grfake: 0.972 
validation accuracies:
                gf: 0.97
                real: 0.95
                fake: 0.39

ran validation set (B:5801) in                         46.1 s.
(epoch: 25, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.512 loss_D_fake: 1.382 loss_D: 2.213 acc_real: 0.945 acc_fake: 0.386 loss_G_conf: 0.015 loss_AUX: 0.302 loss_D_gr_fake: 0.018 acc_grfake: 0.972 
(epoch: 25, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.508 loss_D_fake: 1.253 loss_D: 2.073 acc_real: 0.945 acc_fake: 0.386 loss_G_conf: 0.015 loss_AUX: 0.308 loss_D_gr_fake: 0.003 acc_grfake: 0.972 
saving the model at the end of epoch 25, iters 374400
learning rate 0.0000800 -> 0.0000800
End of epoch 25 / 30 	 Time Taken: 204 sec
(epoch: 26, batches: 20, time: 0.008, data: 0.005) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.507 loss_D_fake: 1.236 loss_D: 2.198 acc_real: 0.945 acc_fake: 0.386 loss_G_conf: 0.015 loss_AUX: 0.339 loss_D_gr_fake: 0.117 acc_grfake: 0.972 
(epoch: 26, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.504 loss_D_fake: 1.178 loss_D: 2.130 acc_real: 0.945 acc_fake: 0.386 loss_G_conf: 0.015 loss_AUX: 0.357 loss_D_gr_fake: 0.091 acc_grfake: 0.972 
validation accuracies:
                gf: 0.97
                real: 0.97
                fake: 0.36

ran validation set (B:5901) in                         46.2 s.
(epoch: 26, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.511 loss_D_fake: 1.293 loss_D: 2.317 acc_real: 0.969 acc_fake: 0.359 loss_G_conf: 0.015 loss_AUX: 0.441 loss_D_gr_fake: 0.073 acc_grfake: 0.966 
(epoch: 26, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.508 loss_D_fake: 1.189 loss_D: 2.101 acc_real: 0.969 acc_fake: 0.359 loss_G_conf: 0.015 loss_AUX: 0.339 loss_D_gr_fake: 0.066 acc_grfake: 0.966 
(epoch: 26, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.516 loss_D_fake: 1.213 loss_D: 2.137 acc_real: 0.969 acc_fake: 0.359 loss_G_conf: 0.015 loss_AUX: 0.305 loss_D_gr_fake: 0.103 acc_grfake: 0.966 
(epoch: 26, batches: 120, time: 0.007, data: 0.001) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.511 loss_D_fake: 1.101 loss_D: 1.964 acc_real: 0.969 acc_fake: 0.359 loss_G_conf: 0.015 loss_AUX: 0.339 loss_D_gr_fake: 0.013 acc_grfake: 0.966 
(epoch: 26, batches: 140, time: 0.007, data: 0.002) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.507 loss_D_fake: 1.090 loss_D: 2.010 acc_real: 0.969 acc_fake: 0.359 loss_G_conf: 0.015 loss_AUX: 0.319 loss_D_gr_fake: 0.094 acc_grfake: 0.966 
validation accuracies:
                gf: 0.97
                real: 0.96
                fake: 0.50

ran validation set (B:6001) in                         46.1 s.
(epoch: 26, batches: 160, time: 0.007, data: 0.005) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.508 loss_D_fake: 1.078 loss_D: 2.027 acc_real: 0.962 acc_fake: 0.497 loss_G_conf: 0.015 loss_AUX: 0.327 loss_D_gr_fake: 0.114 acc_grfake: 0.970 
(epoch: 26, batches: 180, time: 0.007, data: 0.001) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.514 loss_D_fake: 1.139 loss_D: 2.016 acc_real: 0.962 acc_fake: 0.497 loss_G_conf: 0.015 loss_AUX: 0.300 loss_D_gr_fake: 0.064 acc_grfake: 0.970 
(epoch: 26, batches: 200, time: 0.007, data: 0.004) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.510 loss_D_fake: 1.020 loss_D: 1.904 acc_real: 0.962 acc_fake: 0.497 loss_G_conf: 0.015 loss_AUX: 0.281 loss_D_gr_fake: 0.094 acc_grfake: 0.970 
(epoch: 26, batches: 220, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.511 loss_D_fake: 1.209 loss_D: 2.112 acc_real: 0.962 acc_fake: 0.497 loss_G_conf: 0.015 loss_AUX: 0.292 loss_D_gr_fake: 0.100 acc_grfake: 0.970 
learning rate 0.0000800 -> 0.0000800
End of epoch 26 / 30 	 Time Taken: 204 sec
validation accuracies:
                gf: 0.96
                real: 0.99
                fake: 0.37

ran validation set (B:6101) in                         46.4 s.
(epoch: 27, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.504 loss_D_fake: 1.166 loss_D: 2.036 acc_real: 0.988 acc_fake: 0.366 loss_G_conf: 0.015 loss_AUX: 0.289 loss_D_gr_fake: 0.077 acc_grfake: 0.963 
(epoch: 27, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.508 loss_D_fake: 1.215 loss_D: 2.090 acc_real: 0.988 acc_fake: 0.366 loss_G_conf: 0.015 loss_AUX: 0.291 loss_D_gr_fake: 0.075 acc_grfake: 0.963 
(epoch: 27, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.506 loss_D_fake: 1.034 loss_D: 1.952 acc_real: 0.988 acc_fake: 0.366 loss_G_conf: 0.015 loss_AUX: 0.304 loss_D_gr_fake: 0.108 acc_grfake: 0.963 
(epoch: 27, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.531 loss_D_fake: 0.844 loss_D: 1.761 acc_real: 0.988 acc_fake: 0.366 loss_G_conf: 0.015 loss_AUX: 0.345 loss_D_gr_fake: 0.041 acc_grfake: 0.963 
(epoch: 27, batches: 100, time: 0.007, data: 0.002) loss_G_comp: 0.523 loss_G_anti_sc: 0.142 loss_G: 0.680 loss_D_real: 0.518 loss_D_fake: 0.840 loss_D: 1.722 acc_real: 0.988 acc_fake: 0.366 loss_G_conf: 0.015 loss_AUX: 0.336 loss_D_gr_fake: 0.029 acc_grfake: 0.963 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.50

ran validation set (B:6201) in                         45.9 s.
(epoch: 27, batches: 120, time: 0.006, data: 0.003) loss_G_comp: 0.511 loss_G_anti_sc: 0.448 loss_G: 0.974 loss_D_real: 0.529 loss_D_fake: 1.085 loss_D: 1.910 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.015 loss_AUX: 0.289 loss_D_gr_fake: 0.006 acc_grfake: 0.960 
(epoch: 27, batches: 140, time: 0.007, data: 0.001) loss_G_comp: 0.512 loss_G_anti_sc: 0.155 loss_G: 0.683 loss_D_real: 0.508 loss_D_fake: 1.441 loss_D: 2.347 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.016 loss_AUX: 0.323 loss_D_gr_fake: 0.074 acc_grfake: 0.960 
(epoch: 27, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.520 loss_G_anti_sc: 0.160 loss_G: 0.696 loss_D_real: 0.518 loss_D_fake: 1.505 loss_D: 2.370 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.016 loss_AUX: 0.321 loss_D_gr_fake: 0.025 acc_grfake: 0.960 
(epoch: 27, batches: 180, time: 0.007, data: 0.005) loss_G_comp: 0.530 loss_G_anti_sc: 0.110 loss_G: 0.656 loss_D_real: 0.516 loss_D_fake: 1.247 loss_D: 2.158 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.016 loss_AUX: 0.343 loss_D_gr_fake: 0.052 acc_grfake: 0.960 
(epoch: 27, batches: 200, time: 0.008, data: 0.004) loss_G_comp: 0.522 loss_G_anti_sc: 0.136 loss_G: 0.674 loss_D_real: 0.520 loss_D_fake: 1.548 loss_D: 2.524 acc_real: 0.981 acc_fake: 0.502 loss_G_conf: 0.015 loss_AUX: 0.383 loss_D_gr_fake: 0.073 acc_grfake: 0.960 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.06

ran validation set (B:6301) in                         46.3 s.
(epoch: 27, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.560 loss_D_fake: 1.058 loss_D: 1.964 acc_real: 0.983 acc_fake: 0.061 loss_G_conf: 0.016 loss_AUX: 0.321 loss_D_gr_fake: 0.025 acc_grfake: 0.964 
learning rate 0.0000800 -> 0.0000800
End of epoch 27 / 30 	 Time Taken: 251 sec
(epoch: 28, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.505 loss_D_fake: 1.290 loss_D: 2.201 acc_real: 0.983 acc_fake: 0.061 loss_G_conf: 0.016 loss_AUX: 0.364 loss_D_gr_fake: 0.042 acc_grfake: 0.964 
(epoch: 28, batches: 40, time: 0.007, data: 0.011) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.516 loss_D_fake: 1.198 loss_D: 2.115 acc_real: 0.983 acc_fake: 0.061 loss_G_conf: 0.016 loss_AUX: 0.326 loss_D_gr_fake: 0.076 acc_grfake: 0.964 
(epoch: 28, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.508 loss_D_fake: 1.344 loss_D: 2.355 acc_real: 0.983 acc_fake: 0.061 loss_G_conf: 0.016 loss_AUX: 0.333 loss_D_gr_fake: 0.169 acc_grfake: 0.964 
(epoch: 28, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.507 loss_D_fake: 1.217 loss_D: 2.120 acc_real: 0.983 acc_fake: 0.061 loss_G_conf: 0.016 loss_AUX: 0.320 loss_D_gr_fake: 0.076 acc_grfake: 0.964 
validation accuracies:
                gf: 0.97
                real: 0.97
                fake: 0.40

ran validation set (B:6401) in                         46.2 s.
(epoch: 28, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.515 loss_D_fake: 1.194 loss_D: 2.126 acc_real: 0.975 acc_fake: 0.403 loss_G_conf: 0.016 loss_AUX: 0.346 loss_D_gr_fake: 0.072 acc_grfake: 0.968 
(epoch: 28, batches: 120, time: 0.007, data: 0.006) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.516 loss_D_fake: 1.190 loss_D: 2.068 acc_real: 0.975 acc_fake: 0.403 loss_G_conf: 0.016 loss_AUX: 0.330 loss_D_gr_fake: 0.032 acc_grfake: 0.968 
(epoch: 28, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.509 loss_D_fake: 1.116 loss_D: 1.991 acc_real: 0.975 acc_fake: 0.403 loss_G_conf: 0.016 loss_AUX: 0.329 loss_D_gr_fake: 0.038 acc_grfake: 0.968 
(epoch: 28, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.511 loss_D_fake: 1.118 loss_D: 2.048 acc_real: 0.975 acc_fake: 0.403 loss_G_conf: 0.016 loss_AUX: 0.358 loss_D_gr_fake: 0.060 acc_grfake: 0.968 
(epoch: 28, batches: 180, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.525 loss_D_fake: 1.040 loss_D: 1.992 acc_real: 0.975 acc_fake: 0.403 loss_G_conf: 0.016 loss_AUX: 0.355 loss_D_gr_fake: 0.071 acc_grfake: 0.968 
validation accuracies:
                gf: 0.95
                real: 1.00
                fake: 0.27

ran validation set (B:6501) in                         46.0 s.
(epoch: 28, batches: 200, time: 0.007, data: 0.005) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.516 loss_D_fake: 1.130 loss_D: 2.134 acc_real: 0.995 acc_fake: 0.269 loss_G_conf: 0.016 loss_AUX: 0.347 loss_D_gr_fake: 0.142 acc_grfake: 0.953 
(epoch: 28, batches: 220, time: 0.008, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.525 loss_D_fake: 1.071 loss_D: 2.052 acc_real: 0.995 acc_fake: 0.269 loss_G_conf: 0.016 loss_AUX: 0.386 loss_D_gr_fake: 0.071 acc_grfake: 0.953 
learning rate 0.0000800 -> 0.0000800
End of epoch 28 / 30 	 Time Taken: 205 sec
(epoch: 29, batches: 20, time: 0.008, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.520 loss_D_fake: 0.987 loss_D: 1.890 acc_real: 0.995 acc_fake: 0.269 loss_G_conf: 0.016 loss_AUX: 0.362 loss_D_gr_fake: 0.021 acc_grfake: 0.953 
(epoch: 29, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.509 loss_D_fake: 1.044 loss_D: 2.107 acc_real: 0.995 acc_fake: 0.269 loss_G_conf: 0.016 loss_AUX: 0.469 loss_D_gr_fake: 0.085 acc_grfake: 0.953 
validation accuracies:
                gf: 0.97
                real: 0.99
                fake: 0.41

ran validation set (B:6601) in                         45.9 s.
(epoch: 29, batches: 60, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.506 loss_D_fake: 1.049 loss_D: 1.903 acc_real: 0.986 acc_fake: 0.413 loss_G_conf: 0.016 loss_AUX: 0.325 loss_D_gr_fake: 0.023 acc_grfake: 0.966 
(epoch: 29, batches: 80, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.514 loss_D_fake: 0.765 loss_D: 1.678 acc_real: 0.986 acc_fake: 0.413 loss_G_conf: 0.016 loss_AUX: 0.360 loss_D_gr_fake: 0.039 acc_grfake: 0.966 
(epoch: 29, batches: 100, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.511 loss_D_fake: 1.049 loss_D: 1.975 acc_real: 0.986 acc_fake: 0.413 loss_G_conf: 0.016 loss_AUX: 0.348 loss_D_gr_fake: 0.066 acc_grfake: 0.966 
(epoch: 29, batches: 120, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.527 loss_D_fake: 0.929 loss_D: 1.869 acc_real: 0.986 acc_fake: 0.413 loss_G_conf: 0.016 loss_AUX: 0.357 loss_D_gr_fake: 0.055 acc_grfake: 0.966 
(epoch: 29, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.512 loss_G_anti_sc: 0.230 loss_G: 0.758 loss_D_real: 0.525 loss_D_fake: 0.963 loss_D: 1.916 acc_real: 0.986 acc_fake: 0.413 loss_G_conf: 0.016 loss_AUX: 0.396 loss_D_gr_fake: 0.031 acc_grfake: 0.966 
validation accuracies:
                gf: 0.98
                real: 0.93
                fake: 0.63

ran validation set (B:6701) in                         46.0 s.
(epoch: 29, batches: 160, time: 0.007, data: 0.004) loss_G_comp: 0.740 loss_G_anti_sc: 0.066 loss_G: 0.821 loss_D_real: 0.511 loss_D_fake: 1.510 loss_D: 2.614 acc_real: 0.932 acc_fake: 0.629 loss_G_conf: 0.015 loss_AUX: 0.310 loss_D_gr_fake: 0.282 acc_grfake: 0.976 
(epoch: 29, batches: 180, time: 0.007, data: 0.003) loss_G_comp: 0.573 loss_G_anti_sc: 0.062 loss_G: 0.650 loss_D_real: 0.518 loss_D_fake: 1.268 loss_D: 2.386 acc_real: 0.932 acc_fake: 0.629 loss_G_conf: 0.015 loss_AUX: 0.519 loss_D_gr_fake: 0.081 acc_grfake: 0.976 
(epoch: 29, batches: 200, time: 0.008, data: 0.001) loss_G_comp: 0.526 loss_G_anti_sc: 0.150 loss_G: 0.690 loss_D_real: 0.513 loss_D_fake: 1.462 loss_D: 2.459 acc_real: 0.932 acc_fake: 0.629 loss_G_conf: 0.015 loss_AUX: 0.383 loss_D_gr_fake: 0.101 acc_grfake: 0.976 
(epoch: 29, batches: 220, time: 0.007, data: 0.017) loss_G_comp: 0.521 loss_G_anti_sc: 0.143 loss_G: 0.679 loss_D_real: 0.532 loss_D_fake: 1.482 loss_D: 2.508 acc_real: 0.932 acc_fake: 0.629 loss_G_conf: 0.014 loss_AUX: 0.437 loss_D_gr_fake: 0.058 acc_grfake: 0.976 
learning rate 0.0000800 -> 0.0000800
End of epoch 29 / 30 	 Time Taken: 204 sec
validation accuracies:
                gf: 0.97
                real: 0.97
                fake: 0.15

ran validation set (B:6801) in                         46.2 s.
(epoch: 30, batches: 20, time: 0.007, data: 0.001) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.524 loss_D_fake: 1.502 loss_D: 2.486 acc_real: 0.966 acc_fake: 0.154 loss_G_conf: 0.016 loss_AUX: 0.370 loss_D_gr_fake: 0.090 acc_grfake: 0.966 
(epoch: 30, batches: 40, time: 0.007, data: 0.001) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.516 loss_D_fake: 1.399 loss_D: 2.302 acc_real: 0.966 acc_fake: 0.154 loss_G_conf: 0.016 loss_AUX: 0.350 loss_D_gr_fake: 0.037 acc_grfake: 0.966 
(epoch: 30, batches: 60, time: 0.008, data: 0.006) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.524 loss_D_fake: 1.376 loss_D: 2.340 acc_real: 0.966 acc_fake: 0.154 loss_G_conf: 0.016 loss_AUX: 0.345 loss_D_gr_fake: 0.096 acc_grfake: 0.966 
(epoch: 30, batches: 80, time: 0.007, data: 0.002) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.524 loss_D_fake: 1.400 loss_D: 2.414 acc_real: 0.966 acc_fake: 0.154 loss_G_conf: 0.016 loss_AUX: 0.365 loss_D_gr_fake: 0.126 acc_grfake: 0.966 
(epoch: 30, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.516 loss_D_fake: 1.417 loss_D: 2.372 acc_real: 0.966 acc_fake: 0.154 loss_G_conf: 0.016 loss_AUX: 0.334 loss_D_gr_fake: 0.105 acc_grfake: 0.966 
validation accuracies:
                gf: 0.96
                real: 0.98
                fake: 0.14

ran validation set (B:6901) in                         45.8 s.
(epoch: 30, batches: 120, time: 0.008, data: 0.003) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.511 loss_D_fake: 1.424 loss_D: 2.307 acc_real: 0.980 acc_fake: 0.137 loss_G_conf: 0.016 loss_AUX: 0.306 loss_D_gr_fake: 0.066 acc_grfake: 0.964 
(epoch: 30, batches: 140, time: 0.008, data: 0.004) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.516 loss_D_fake: 1.397 loss_D: 2.400 acc_real: 0.980 acc_fake: 0.137 loss_G_conf: 0.016 loss_AUX: 0.355 loss_D_gr_fake: 0.132 acc_grfake: 0.964 
(epoch: 30, batches: 160, time: 0.007, data: 0.003) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.509 loss_D_fake: 1.392 loss_D: 2.275 acc_real: 0.980 acc_fake: 0.137 loss_G_conf: 0.016 loss_AUX: 0.309 loss_D_gr_fake: 0.065 acc_grfake: 0.964 
(epoch: 30, batches: 180, time: 0.007, data: 0.001) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.519 loss_D_fake: 1.335 loss_D: 2.196 acc_real: 0.980 acc_fake: 0.137 loss_G_conf: 0.016 loss_AUX: 0.307 loss_D_gr_fake: 0.035 acc_grfake: 0.964 
(epoch: 30, batches: 200, time: 0.007, data: 0.005) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.514 loss_D_fake: 1.386 loss_D: 2.304 acc_real: 0.980 acc_fake: 0.137 loss_G_conf: 0.016 loss_AUX: 0.340 loss_D_gr_fake: 0.063 acc_grfake: 0.964 
validation accuracies:
                gf: 0.97
                real: 0.95
                fake: 0.32

ran validation set (B:7001) in                         46.2 s.
(epoch: 30, batches: 220, time: 0.007, data: 0.004) loss_G_comp: 0.539 loss_G_anti_sc: 0.109 loss_G: 0.664 loss_D_real: 0.522 loss_D_fake: 1.299 loss_D: 2.297 acc_real: 0.953 acc_fake: 0.323 loss_G_conf: 0.016 loss_AUX: 0.392 loss_D_gr_fake: 0.084 acc_grfake: 0.973 
saving the model at the end of epoch 30, iters 449280
learning rate 0.0000800 -> 0.0000800
End of epoch 30 / 30 	 Time Taken: 251 sec
Finished training, model is saved
Batches trained - G: 1300, D: 5720 
