starting training run 36
----------------- Options ---------------
              D_headstart: 0                             	[default: 80000]
              D_threshold: 0.6                           
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 128                           	[default: 64]
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 130                           	[default: 70]
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: True                          
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: False                         
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 1.0                           
               rotate_img: False                         
             save_by_iter: False                         
          save_epoch_freq: 15                            	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
----------------- Options ---------------
              D_headstart: 0                             	[default: 80000]
              D_threshold: 0.6                           
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 128                           	[default: 64]
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 130                           	[default: 70]
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: True                          
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: False                         
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 1.0                           
               rotate_img: False                         
             save_by_iter: False                         
          save_epoch_freq: 15                            	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [DoubleDataset] was created
dataset [DoubleDataset] was created
The number of training images = 15000
The number of epochs to run = 30
initialize network with normal
initialize network with normal
model [CopyPasteGANModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.469 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False, padding_mode=replicate)
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (sigmoid): Sigmoid()
    (avg): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=2, padding=0)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=256, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=256, out_features=1, bias=True)
      (5): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 3.600 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 0.00
                real: 1.00
                fake: 0.00

ran validation set (B:1) in                         52.7 s.
(epoch: 1, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.658 loss_D_fake: 0.715 loss_D: 2.299 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.272 loss_D_gr_fake: 0.655 acc_grfake: 0.000 
(epoch: 1, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.570 loss_D_fake: 0.767 loss_D: 2.111 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.271 loss_D_gr_fake: 0.503 acc_grfake: 0.000 
(epoch: 1, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.401 loss_D_fake: 0.962 loss_D: 2.118 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.270 loss_D_gr_fake: 0.484 acc_grfake: 0.000 
(epoch: 1, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.349 loss_D_fake: 0.825 loss_D: 1.792 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.269 loss_D_gr_fake: 0.349 acc_grfake: 0.000 
(epoch: 1, batches: 100, time: 0.012, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.401 loss_D_fake: 0.846 loss_D: 1.787 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.269 loss_D_gr_fake: 0.272 acc_grfake: 0.000 
validation accuracies:
                gf: 0.79
                real: 0.99
                fake: 0.08

ran validation set (B:101) in                         51.1 s.
(epoch: 1, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.286 loss_D_fake: 1.058 loss_D: 1.932 acc_real: 0.991 acc_fake: 0.084 loss_G_conf: 0.000 loss_AUX: 0.268 loss_D_gr_fake: 0.320 acc_grfake: 0.788 
(epoch: 1, batches: 140, time: 0.010, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.204 loss_D_fake: 1.051 loss_D: 1.806 acc_real: 0.991 acc_fake: 0.084 loss_G_conf: 0.000 loss_AUX: 0.267 loss_D_gr_fake: 0.284 acc_grfake: 0.788 
(epoch: 1, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.171 loss_D_fake: 1.326 loss_D: 2.139 acc_real: 0.991 acc_fake: 0.084 loss_G_conf: 0.000 loss_AUX: 0.267 loss_D_gr_fake: 0.376 acc_grfake: 0.788 
(epoch: 1, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.180 loss_D_fake: 0.980 loss_D: 1.710 acc_real: 0.991 acc_fake: 0.084 loss_G_conf: 0.000 loss_AUX: 0.266 loss_D_gr_fake: 0.283 acc_grfake: 0.788 
(epoch: 1, batches: 200, time: 0.011, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.110 loss_D_fake: 1.246 loss_D: 1.973 acc_real: 0.991 acc_fake: 0.084 loss_G_conf: 0.000 loss_AUX: 0.266 loss_D_gr_fake: 0.351 acc_grfake: 0.788 
validation accuracies:
                gf: 0.92
                real: 0.94
                fake: 0.49

ran validation set (B:201) in                         51.0 s.
(epoch: 1, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.148 loss_D_fake: 1.384 loss_D: 2.090 acc_real: 0.936 acc_fake: 0.486 loss_G_conf: 0.000 loss_AUX: 0.265 loss_D_gr_fake: 0.293 acc_grfake: 0.917 
learning rate 0.0001000 -> 0.0001000
End of epoch 1 / 30 	 Time Taken: 296 sec
/home/tlotze/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
(epoch: 2, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.186 loss_D_fake: 1.050 loss_D: 1.743 acc_real: 0.936 acc_fake: 0.486 loss_G_conf: 0.000 loss_AUX: 0.264 loss_D_gr_fake: 0.244 acc_grfake: 0.917 
(epoch: 2, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.101 loss_D_fake: 1.372 loss_D: 1.913 acc_real: 0.936 acc_fake: 0.486 loss_G_conf: 0.000 loss_AUX: 0.263 loss_D_gr_fake: 0.177 acc_grfake: 0.917 
(epoch: 2, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.092 loss_D_fake: 1.315 loss_D: 1.909 acc_real: 0.936 acc_fake: 0.486 loss_G_conf: 0.000 loss_AUX: 0.262 loss_D_gr_fake: 0.239 acc_grfake: 0.917 
validation accuracies:
                gf: 0.94
                real: 0.88
                fake: 0.68

ran validation set (B:301) in                         51.4 s.
(epoch: 2, batches: 80, time: 0.008, data: 0.006) loss_G_comp: 0.617 loss_G_anti_sc: 0.829 loss_G: 1.929 loss_D_real: 0.336 loss_D_fake: 0.819 loss_D: 1.693 acc_real: 0.880 acc_fake: 0.685 loss_G_conf: 0.483 loss_AUX: 0.262 loss_D_gr_fake: 0.276 acc_grfake: 0.943 
(epoch: 2, batches: 100, time: 0.008, data: 0.007) loss_G_comp: 0.668 loss_G_anti_sc: 0.776 loss_G: 1.926 loss_D_real: 0.323 loss_D_fake: 0.752 loss_D: 1.570 acc_real: 0.880 acc_fake: 0.685 loss_G_conf: 0.482 loss_AUX: 0.262 loss_D_gr_fake: 0.233 acc_grfake: 0.943 
(epoch: 2, batches: 120, time: 0.008, data: 0.006) loss_G_comp: 0.552 loss_G_anti_sc: 0.904 loss_G: 1.938 loss_D_real: 0.304 loss_D_fake: 0.742 loss_D: 1.571 acc_real: 0.880 acc_fake: 0.685 loss_G_conf: 0.481 loss_AUX: 0.262 loss_D_gr_fake: 0.263 acc_grfake: 0.943 
(epoch: 2, batches: 140, time: 0.008, data: 0.006) loss_G_comp: 0.597 loss_G_anti_sc: 0.883 loss_G: 1.960 loss_D_real: 0.217 loss_D_fake: 0.900 loss_D: 1.578 acc_real: 0.880 acc_fake: 0.685 loss_G_conf: 0.480 loss_AUX: 0.261 loss_D_gr_fake: 0.200 acc_grfake: 0.943 
(epoch: 2, batches: 160, time: 0.008, data: 0.007) loss_G_comp: 0.623 loss_G_anti_sc: 0.660 loss_G: 1.762 loss_D_real: 0.317 loss_D_fake: 0.707 loss_D: 1.442 acc_real: 0.880 acc_fake: 0.685 loss_G_conf: 0.479 loss_AUX: 0.261 loss_D_gr_fake: 0.157 acc_grfake: 0.943 
validation accuracies:
                gf: 0.91
                real: 0.83
                fake: 0.71

ran validation set (B:401) in                         51.3 s.
(epoch: 2, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.446 loss_G_anti_sc: 0.963 loss_G: 1.887 loss_D_real: 0.365 loss_D_fake: 0.659 loss_D: 1.503 acc_real: 0.827 acc_fake: 0.714 loss_G_conf: 0.478 loss_AUX: 0.261 loss_D_gr_fake: 0.218 acc_grfake: 0.906 
(epoch: 2, batches: 200, time: 0.008, data: 0.007) loss_G_comp: 0.516 loss_G_anti_sc: 0.777 loss_G: 1.770 loss_D_real: 0.225 loss_D_fake: 0.881 loss_D: 1.551 acc_real: 0.827 acc_fake: 0.714 loss_G_conf: 0.477 loss_AUX: 0.260 loss_D_gr_fake: 0.185 acc_grfake: 0.906 
(epoch: 2, batches: 220, time: 0.008, data: 0.007) loss_G_comp: 0.894 loss_G_anti_sc: 0.520 loss_G: 1.889 loss_D_real: 0.151 loss_D_fake: 1.084 loss_D: 1.728 acc_real: 0.827 acc_fake: 0.714 loss_G_conf: 0.475 loss_AUX: 0.260 loss_D_gr_fake: 0.232 acc_grfake: 0.906 
learning rate 0.0001000 -> 0.0001000
End of epoch 2 / 30 	 Time Taken: 237 sec
(epoch: 3, batches: 20, time: 0.008, data: 0.006) loss_G_comp: 0.962 loss_G_anti_sc: 0.331 loss_G: 1.767 loss_D_real: 0.149 loss_D_fake: 0.973 loss_D: 1.637 acc_real: 0.827 acc_fake: 0.714 loss_G_conf: 0.474 loss_AUX: 0.260 loss_D_gr_fake: 0.254 acc_grfake: 0.906 
validation accuracies:
                gf: 0.92
                real: 0.95
                fake: 0.40

ran validation set (B:501) in                         51.3 s.
(epoch: 3, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.147 loss_D_fake: 1.102 loss_D: 1.701 acc_real: 0.953 acc_fake: 0.395 loss_G_conf: 0.474 loss_AUX: 0.259 loss_D_gr_fake: 0.193 acc_grfake: 0.922 
(epoch: 3, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.085 loss_D_fake: 1.529 loss_D: 2.179 acc_real: 0.953 acc_fake: 0.395 loss_G_conf: 0.474 loss_AUX: 0.259 loss_D_gr_fake: 0.306 acc_grfake: 0.922 
(epoch: 3, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.198 loss_D_fake: 0.993 loss_D: 1.581 acc_real: 0.953 acc_fake: 0.395 loss_G_conf: 0.474 loss_AUX: 0.258 loss_D_gr_fake: 0.131 acc_grfake: 0.922 
(epoch: 3, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.123 loss_D_fake: 1.401 loss_D: 2.042 acc_real: 0.953 acc_fake: 0.395 loss_G_conf: 0.474 loss_AUX: 0.258 loss_D_gr_fake: 0.260 acc_grfake: 0.922 
(epoch: 3, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.156 loss_D_fake: 1.046 loss_D: 1.632 acc_real: 0.953 acc_fake: 0.395 loss_G_conf: 0.474 loss_AUX: 0.258 loss_D_gr_fake: 0.172 acc_grfake: 0.922 
validation accuracies:
                gf: 0.91
                real: 0.98
                fake: 0.27

ran validation set (B:601) in                         51.2 s.
(epoch: 3, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.110 loss_D_fake: 1.124 loss_D: 1.830 acc_real: 0.981 acc_fake: 0.268 loss_G_conf: 0.474 loss_AUX: 0.257 loss_D_gr_fake: 0.339 acc_grfake: 0.912 
(epoch: 3, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.085 loss_D_fake: 1.564 loss_D: 2.198 acc_real: 0.981 acc_fake: 0.268 loss_G_conf: 0.474 loss_AUX: 0.257 loss_D_gr_fake: 0.292 acc_grfake: 0.912 
(epoch: 3, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.095 loss_D_fake: 1.209 loss_D: 1.925 acc_real: 0.981 acc_fake: 0.268 loss_G_conf: 0.474 loss_AUX: 0.257 loss_D_gr_fake: 0.365 acc_grfake: 0.912 
(epoch: 3, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.102 loss_D_fake: 1.015 loss_D: 1.487 acc_real: 0.981 acc_fake: 0.268 loss_G_conf: 0.474 loss_AUX: 0.256 loss_D_gr_fake: 0.113 acc_grfake: 0.912 
(epoch: 3, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.108 loss_D_fake: 1.331 loss_D: 1.794 acc_real: 0.981 acc_fake: 0.268 loss_G_conf: 0.474 loss_AUX: 0.255 loss_D_gr_fake: 0.099 acc_grfake: 0.912 
validation accuracies:
                gf: 0.91
                real: 1.00
                fake: 0.19

ran validation set (B:701) in                         50.3 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 3 / 30 	 Time Taken: 293 sec
(epoch: 4, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.077 loss_D_fake: 1.353 loss_D: 1.876 acc_real: 0.996 acc_fake: 0.192 loss_G_conf: 0.474 loss_AUX: 0.255 loss_D_gr_fake: 0.191 acc_grfake: 0.907 
(epoch: 4, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.128 loss_D_fake: 1.080 loss_D: 1.840 acc_real: 0.996 acc_fake: 0.192 loss_G_conf: 0.474 loss_AUX: 0.255 loss_D_gr_fake: 0.377 acc_grfake: 0.907 
(epoch: 4, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.095 loss_D_fake: 1.058 loss_D: 1.600 acc_real: 0.996 acc_fake: 0.192 loss_G_conf: 0.474 loss_AUX: 0.255 loss_D_gr_fake: 0.192 acc_grfake: 0.907 
(epoch: 4, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.164 loss_D_fake: 1.155 loss_D: 1.744 acc_real: 0.996 acc_fake: 0.192 loss_G_conf: 0.474 loss_AUX: 0.254 loss_D_gr_fake: 0.171 acc_grfake: 0.907 
validation accuracies:
                gf: 0.93
                real: 0.98
                fake: 0.33

ran validation set (B:801) in                         51.2 s.
(epoch: 4, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.113 loss_D_fake: 0.961 loss_D: 1.634 acc_real: 0.984 acc_fake: 0.328 loss_G_conf: 0.474 loss_AUX: 0.253 loss_D_gr_fake: 0.306 acc_grfake: 0.928 
(epoch: 4, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.104 loss_D_fake: 1.079 loss_D: 1.836 acc_real: 0.984 acc_fake: 0.328 loss_G_conf: 0.474 loss_AUX: 0.253 loss_D_gr_fake: 0.400 acc_grfake: 0.928 
(epoch: 4, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.109 loss_D_fake: 1.217 loss_D: 1.722 acc_real: 0.984 acc_fake: 0.328 loss_G_conf: 0.474 loss_AUX: 0.253 loss_D_gr_fake: 0.143 acc_grfake: 0.928 
(epoch: 4, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.063 loss_D_fake: 1.404 loss_D: 1.917 acc_real: 0.984 acc_fake: 0.328 loss_G_conf: 0.474 loss_AUX: 0.253 loss_D_gr_fake: 0.197 acc_grfake: 0.928 
(epoch: 4, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.073 loss_D_fake: 1.666 loss_D: 2.139 acc_real: 0.984 acc_fake: 0.328 loss_G_conf: 0.474 loss_AUX: 0.252 loss_D_gr_fake: 0.149 acc_grfake: 0.928 
validation accuracies:
                gf: 0.91
                real: 1.00
                fake: 0.29

ran validation set (B:901) in                         51.3 s.
(epoch: 4, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.082 loss_D_fake: 1.065 loss_D: 1.578 acc_real: 0.998 acc_fake: 0.285 loss_G_conf: 0.474 loss_AUX: 0.252 loss_D_gr_fake: 0.180 acc_grfake: 0.915 
(epoch: 4, batches: 220, time: 0.010, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.081 loss_D_fake: 1.318 loss_D: 1.905 acc_real: 0.998 acc_fake: 0.285 loss_G_conf: 0.474 loss_AUX: 0.252 loss_D_gr_fake: 0.254 acc_grfake: 0.915 
learning rate 0.0001000 -> 0.0001000
End of epoch 4 / 30 	 Time Taken: 244 sec
(epoch: 5, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.139 loss_D_fake: 0.873 loss_D: 1.395 acc_real: 0.998 acc_fake: 0.285 loss_G_conf: 0.474 loss_AUX: 0.251 loss_D_gr_fake: 0.132 acc_grfake: 0.915 
(epoch: 5, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.056 loss_D_fake: 1.446 loss_D: 1.947 acc_real: 0.998 acc_fake: 0.285 loss_G_conf: 0.474 loss_AUX: 0.251 loss_D_gr_fake: 0.193 acc_grfake: 0.915 
(epoch: 5, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.112 loss_D_fake: 0.893 loss_D: 1.384 acc_real: 0.998 acc_fake: 0.285 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.129 acc_grfake: 0.915 
validation accuracies:
                gf: 0.93
                real: 0.97
                fake: 0.48

ran validation set (B:1001) in                         51.4 s.
(epoch: 5, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.164 loss_D_fake: 0.847 loss_D: 1.361 acc_real: 0.967 acc_fake: 0.483 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.100 acc_grfake: 0.930 
(epoch: 5, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.131 loss_D_fake: 0.921 loss_D: 1.518 acc_real: 0.967 acc_fake: 0.483 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.215 acc_grfake: 0.930 
(epoch: 5, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.072 loss_D_fake: 1.344 loss_D: 1.857 acc_real: 0.967 acc_fake: 0.483 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.191 acc_grfake: 0.930 
(epoch: 5, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.103 loss_D_fake: 1.193 loss_D: 1.704 acc_real: 0.967 acc_fake: 0.483 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.158 acc_grfake: 0.930 
(epoch: 5, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.166 loss_D_fake: 1.114 loss_D: 1.858 acc_real: 0.967 acc_fake: 0.483 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.328 acc_grfake: 0.930 
validation accuracies:
                gf: 0.92
                real: 0.98
                fake: 0.32

ran validation set (B:1101) in                         51.2 s.
(epoch: 5, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.154 loss_D_fake: 0.951 loss_D: 1.535 acc_real: 0.984 acc_fake: 0.319 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.181 acc_grfake: 0.915 
(epoch: 5, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.086 loss_D_fake: 1.185 loss_D: 1.673 acc_real: 0.984 acc_fake: 0.319 loss_G_conf: 0.474 loss_AUX: 0.249 loss_D_gr_fake: 0.153 acc_grfake: 0.915 
(epoch: 5, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.048 loss_D_fake: 1.682 loss_D: 2.432 acc_real: 0.984 acc_fake: 0.319 loss_G_conf: 0.474 loss_AUX: 0.250 loss_D_gr_fake: 0.452 acc_grfake: 0.915 
learning rate 0.0001000 -> 0.0001000
End of epoch 5 / 30 	 Time Taken: 241 sec
(epoch: 6, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.065 loss_D_fake: 1.657 loss_D: 2.205 acc_real: 0.984 acc_fake: 0.319 loss_G_conf: 0.474 loss_AUX: 0.249 loss_D_gr_fake: 0.234 acc_grfake: 0.915 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.21

ran validation set (B:1201) in                         51.1 s.
(epoch: 6, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.105 loss_D_fake: 1.064 loss_D: 1.539 acc_real: 0.999 acc_fake: 0.208 loss_G_conf: 0.474 loss_AUX: 0.249 loss_D_gr_fake: 0.121 acc_grfake: 0.925 
(epoch: 6, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.096 loss_D_fake: 1.118 loss_D: 1.586 acc_real: 0.999 acc_fake: 0.208 loss_G_conf: 0.474 loss_AUX: 0.248 loss_D_gr_fake: 0.124 acc_grfake: 0.925 
(epoch: 6, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.077 loss_D_fake: 0.901 loss_D: 1.422 acc_real: 0.999 acc_fake: 0.208 loss_G_conf: 0.474 loss_AUX: 0.248 loss_D_gr_fake: 0.196 acc_grfake: 0.925 
(epoch: 6, batches: 100, time: 0.010, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.067 loss_D_fake: 1.317 loss_D: 1.853 acc_real: 0.999 acc_fake: 0.208 loss_G_conf: 0.474 loss_AUX: 0.248 loss_D_gr_fake: 0.221 acc_grfake: 0.925 
(epoch: 6, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.050 loss_D_fake: 1.288 loss_D: 1.711 acc_real: 0.999 acc_fake: 0.208 loss_G_conf: 0.474 loss_AUX: 0.248 loss_D_gr_fake: 0.124 acc_grfake: 0.925 
validation accuracies:
                gf: 0.92
                real: 1.00
                fake: 0.22

ran validation set (B:1301) in                         51.2 s.
(epoch: 6, batches: 140, time: 0.009, data: 0.011) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.103 loss_D_fake: 0.942 loss_D: 1.427 acc_real: 0.999 acc_fake: 0.218 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.135 acc_grfake: 0.920 
(epoch: 6, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.052 loss_D_fake: 1.298 loss_D: 1.699 acc_real: 0.999 acc_fake: 0.218 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.102 acc_grfake: 0.920 
(epoch: 6, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.120 loss_D_fake: 1.318 loss_D: 1.835 acc_real: 0.999 acc_fake: 0.218 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.150 acc_grfake: 0.920 
(epoch: 6, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.043 loss_D_fake: 1.502 loss_D: 1.904 acc_real: 0.999 acc_fake: 0.218 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.112 acc_grfake: 0.920 
(epoch: 6, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.068 loss_D_fake: 1.026 loss_D: 1.455 acc_real: 0.999 acc_fake: 0.218 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.114 acc_grfake: 0.920 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.32

ran validation set (B:1401) in                         50.2 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 6 / 30 	 Time Taken: 290 sec
(epoch: 7, batches: 20, time: 0.009, data: 0.008) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.216 loss_D_fake: 0.761 loss_D: 1.466 acc_real: 0.995 acc_fake: 0.317 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.243 acc_grfake: 0.926 
(epoch: 7, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.098 loss_D_fake: 1.000 loss_D: 1.510 acc_real: 0.995 acc_fake: 0.317 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.165 acc_grfake: 0.926 
(epoch: 7, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.123 loss_D_fake: 0.913 loss_D: 1.377 acc_real: 0.995 acc_fake: 0.317 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.095 acc_grfake: 0.926 
(epoch: 7, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.216 loss_D_fake: 0.460 loss_D: 1.032 acc_real: 0.995 acc_fake: 0.317 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.110 acc_grfake: 0.926 
validation accuracies:
                gf: 0.92
                real: 0.99
                fake: 0.37

ran validation set (B:1501) in                         51.0 s.
(epoch: 7, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.220 loss_D_fake: 0.640 loss_D: 1.206 acc_real: 0.993 acc_fake: 0.365 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.098 acc_grfake: 0.924 
(epoch: 7, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.105 loss_D_fake: 1.102 loss_D: 1.673 acc_real: 0.993 acc_fake: 0.365 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.219 acc_grfake: 0.924 
(epoch: 7, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.101 loss_D_fake: 1.110 loss_D: 1.594 acc_real: 0.993 acc_fake: 0.365 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.136 acc_grfake: 0.924 
(epoch: 7, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.168 loss_D_fake: 0.666 loss_D: 1.195 acc_real: 0.993 acc_fake: 0.365 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.114 acc_grfake: 0.924 
(epoch: 7, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.075 loss_D_fake: 0.825 loss_D: 1.332 acc_real: 0.993 acc_fake: 0.365 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.186 acc_grfake: 0.924 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.36

ran validation set (B:1601) in                         50.9 s.
(epoch: 7, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.292 loss_D_fake: 0.484 loss_D: 1.156 acc_real: 0.997 acc_fake: 0.357 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.134 acc_grfake: 0.929 
(epoch: 7, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.051 loss_D_fake: 1.454 loss_D: 2.263 acc_real: 0.997 acc_fake: 0.357 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.511 acc_grfake: 0.929 
learning rate 0.0001000 -> 0.0001000
End of epoch 7 / 30 	 Time Taken: 238 sec
(epoch: 8, batches: 20, time: 0.009, data: 0.011) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.083 loss_D_fake: 1.004 loss_D: 1.383 acc_real: 0.997 acc_fake: 0.357 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.051 acc_grfake: 0.929 
(epoch: 8, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.188 loss_D_fake: 0.649 loss_D: 1.304 acc_real: 0.997 acc_fake: 0.357 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.220 acc_grfake: 0.929 
(epoch: 8, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.052 loss_D_fake: 1.328 loss_D: 1.871 acc_real: 0.997 acc_fake: 0.357 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.245 acc_grfake: 0.929 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.55

ran validation set (B:1701) in                         51.3 s.
(epoch: 8, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.083 loss_D_fake: 0.979 loss_D: 1.565 acc_real: 0.992 acc_fake: 0.546 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.258 acc_grfake: 0.926 
(epoch: 8, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.079 loss_D_fake: 0.936 loss_D: 1.482 acc_real: 0.992 acc_fake: 0.546 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.221 acc_grfake: 0.926 
(epoch: 8, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.107 loss_D_fake: 0.841 loss_D: 1.281 acc_real: 0.992 acc_fake: 0.546 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.088 acc_grfake: 0.926 
(epoch: 8, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.051 loss_D_fake: 1.242 loss_D: 1.751 acc_real: 0.992 acc_fake: 0.546 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.211 acc_grfake: 0.926 
(epoch: 8, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.096 loss_D_fake: 0.850 loss_D: 1.309 acc_real: 0.992 acc_fake: 0.546 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.119 acc_grfake: 0.926 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.36

ran validation set (B:1801) in                         51.0 s.
(epoch: 8, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.051 loss_D_fake: 1.140 loss_D: 1.625 acc_real: 0.999 acc_fake: 0.362 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.189 acc_grfake: 0.929 
(epoch: 8, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.038 loss_D_fake: 1.356 loss_D: 1.902 acc_real: 0.999 acc_fake: 0.362 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.263 acc_grfake: 0.929 
(epoch: 8, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.079 loss_D_fake: 1.183 loss_D: 1.766 acc_real: 0.999 acc_fake: 0.362 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.258 acc_grfake: 0.929 
learning rate 0.0001000 -> 0.0001000
End of epoch 8 / 30 	 Time Taken: 241 sec
(epoch: 9, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.066 loss_D_fake: 1.030 loss_D: 1.447 acc_real: 0.999 acc_fake: 0.362 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.106 acc_grfake: 0.929 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.50

ran validation set (B:1901) in                         51.0 s.
(epoch: 9, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.068 loss_D_fake: 1.346 loss_D: 1.951 acc_real: 0.997 acc_fake: 0.496 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.292 acc_grfake: 0.941 
(epoch: 9, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.060 loss_D_fake: 1.180 loss_D: 1.820 acc_real: 0.997 acc_fake: 0.496 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.336 acc_grfake: 0.941 
(epoch: 9, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.042 loss_D_fake: 1.588 loss_D: 1.996 acc_real: 0.997 acc_fake: 0.496 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.121 acc_grfake: 0.941 
(epoch: 9, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.048 loss_D_fake: 1.278 loss_D: 1.776 acc_real: 0.997 acc_fake: 0.496 loss_G_conf: 0.474 loss_AUX: 0.247 loss_D_gr_fake: 0.203 acc_grfake: 0.941 
(epoch: 9, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.046 loss_D_fake: 1.315 loss_D: 1.765 acc_real: 0.997 acc_fake: 0.496 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.160 acc_grfake: 0.941 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.29

ran validation set (B:2001) in                         51.1 s.
(epoch: 9, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.054 loss_D_fake: 1.213 loss_D: 1.650 acc_real: 0.997 acc_fake: 0.287 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.139 acc_grfake: 0.928 
(epoch: 9, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.052 loss_D_fake: 1.230 loss_D: 1.638 acc_real: 0.997 acc_fake: 0.287 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.110 acc_grfake: 0.928 
(epoch: 9, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.110 loss_D_fake: 0.933 loss_D: 1.616 acc_real: 0.997 acc_fake: 0.287 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.327 acc_grfake: 0.928 
(epoch: 9, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.077 loss_D_fake: 0.886 loss_D: 1.325 acc_real: 0.997 acc_fake: 0.287 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.118 acc_grfake: 0.928 
(epoch: 9, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.091 loss_D_fake: 0.767 loss_D: 1.220 acc_real: 0.997 acc_fake: 0.287 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.118 acc_grfake: 0.928 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.49

ran validation set (B:2101) in                         50.1 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 9 / 30 	 Time Taken: 292 sec
(epoch: 10, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.237 loss_D_fake: 0.489 loss_D: 1.003 acc_real: 0.996 acc_fake: 0.490 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.033 acc_grfake: 0.934 
(epoch: 10, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.129 loss_D_fake: 0.674 loss_D: 1.206 acc_real: 0.996 acc_fake: 0.490 loss_G_conf: 0.474 loss_AUX: 0.243 loss_D_gr_fake: 0.160 acc_grfake: 0.934 
(epoch: 10, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.043 loss_D_fake: 1.110 loss_D: 1.593 acc_real: 0.996 acc_fake: 0.490 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.195 acc_grfake: 0.934 
(epoch: 10, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.034 loss_D_fake: 1.362 loss_D: 1.916 acc_real: 0.996 acc_fake: 0.490 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.275 acc_grfake: 0.934 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.50

ran validation set (B:2201) in                         51.1 s.
(epoch: 10, batches: 100, time: 0.009, data: 0.008) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.045 loss_D_fake: 1.168 loss_D: 1.551 acc_real: 0.993 acc_fake: 0.501 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.094 acc_grfake: 0.930 
(epoch: 10, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.144 loss_D_fake: 0.424 loss_D: 0.942 acc_real: 0.993 acc_fake: 0.501 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.130 acc_grfake: 0.930 
(epoch: 10, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.092 loss_D_fake: 0.843 loss_D: 1.266 acc_real: 0.993 acc_fake: 0.501 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.086 acc_grfake: 0.930 
(epoch: 10, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.104 loss_D_fake: 0.672 loss_D: 1.229 acc_real: 0.993 acc_fake: 0.501 loss_G_conf: 0.474 loss_AUX: 0.246 loss_D_gr_fake: 0.208 acc_grfake: 0.930 
(epoch: 10, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.043 loss_D_fake: 1.319 loss_D: 1.663 acc_real: 0.993 acc_fake: 0.501 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.056 acc_grfake: 0.930 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.47

ran validation set (B:2301) in                         50.9 s.
(epoch: 10, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.089 loss_D_fake: 0.690 loss_D: 1.195 acc_real: 0.994 acc_fake: 0.470 loss_G_conf: 0.474 loss_AUX: 0.243 loss_D_gr_fake: 0.173 acc_grfake: 0.929 
(epoch: 10, batches: 220, time: 0.010, data: 0.006) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.062 loss_D_fake: 0.900 loss_D: 1.298 acc_real: 0.994 acc_fake: 0.470 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.092 acc_grfake: 0.929 
learning rate 0.0001000 -> 0.0001000
End of epoch 10 / 30 	 Time Taken: 242 sec
(epoch: 11, batches: 20, time: 0.009, data: 0.004) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.097 loss_D_fake: 0.797 loss_D: 1.210 acc_real: 0.994 acc_fake: 0.470 loss_G_conf: 0.474 loss_AUX: 0.245 loss_D_gr_fake: 0.071 acc_grfake: 0.929 
(epoch: 11, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.038 loss_D_fake: 1.207 loss_D: 1.683 acc_real: 0.994 acc_fake: 0.470 loss_G_conf: 0.474 loss_AUX: 0.244 loss_D_gr_fake: 0.194 acc_grfake: 0.929 
(epoch: 11, batches: 60, time: 0.014, data: 0.007) loss_G_comp: 0.566 loss_G_anti_sc: 0.606 loss_G: 1.645 loss_D_real: 0.061 loss_D_fake: 1.087 loss_D: 1.655 acc_real: 0.994 acc_fake: 0.470 loss_G_conf: 0.474 loss_AUX: 0.243 loss_D_gr_fake: 0.264 acc_grfake: 0.929 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.68

ran validation set (B:2401) in                         51.2 s.
(epoch: 11, batches: 80, time: 0.008, data: 0.006) loss_G_comp: 0.512 loss_G_anti_sc: 0.830 loss_G: 1.814 loss_D_real: 0.297 loss_D_fake: 0.940 loss_D: 1.827 acc_real: 0.990 acc_fake: 0.679 loss_G_conf: 0.473 loss_AUX: 0.247 loss_D_gr_fake: 0.343 acc_grfake: 0.938 
(epoch: 11, batches: 100, time: 0.008, data: 0.007) loss_G_comp: 0.446 loss_G_anti_sc: 0.677 loss_G: 1.594 loss_D_real: 0.148 loss_D_fake: 1.100 loss_D: 1.678 acc_real: 0.990 acc_fake: 0.679 loss_G_conf: 0.472 loss_AUX: 0.247 loss_D_gr_fake: 0.183 acc_grfake: 0.938 
(epoch: 11, batches: 120, time: 0.008, data: 0.009) loss_G_comp: 0.404 loss_G_anti_sc: 0.794 loss_G: 1.668 loss_D_real: 0.193 loss_D_fake: 1.046 loss_D: 1.699 acc_real: 0.990 acc_fake: 0.679 loss_G_conf: 0.471 loss_AUX: 0.245 loss_D_gr_fake: 0.214 acc_grfake: 0.938 
(epoch: 11, batches: 140, time: 0.008, data: 0.006) loss_G_comp: 0.561 loss_G_anti_sc: 0.480 loss_G: 1.511 loss_D_real: 0.045 loss_D_fake: 1.952 loss_D: 2.455 acc_real: 0.990 acc_fake: 0.679 loss_G_conf: 0.470 loss_AUX: 0.245 loss_D_gr_fake: 0.214 acc_grfake: 0.938 
(epoch: 11, batches: 160, time: 0.013, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.238 loss_D_fake: 1.035 loss_D: 1.692 acc_real: 0.990 acc_fake: 0.679 loss_G_conf: 0.468 loss_AUX: 0.246 loss_D_gr_fake: 0.173 acc_grfake: 0.938 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.09

ran validation set (B:2501) in                         51.0 s.
(epoch: 11, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.055 loss_D_fake: 1.596 loss_D: 2.281 acc_real: 0.997 acc_fake: 0.085 loss_G_conf: 0.468 loss_AUX: 0.245 loss_D_gr_fake: 0.385 acc_grfake: 0.926 
(epoch: 11, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.095 loss_D_fake: 1.031 loss_D: 1.535 acc_real: 0.997 acc_fake: 0.085 loss_G_conf: 0.468 loss_AUX: 0.243 loss_D_gr_fake: 0.165 acc_grfake: 0.926 
(epoch: 11, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.189 loss_D_fake: 0.978 loss_D: 1.529 acc_real: 0.997 acc_fake: 0.085 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.118 acc_grfake: 0.926 
learning rate 0.0001000 -> 0.0001000
End of epoch 11 / 30 	 Time Taken: 239 sec
(epoch: 12, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.061 loss_D_fake: 1.151 loss_D: 1.545 acc_real: 0.997 acc_fake: 0.085 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.090 acc_grfake: 0.926 
validation accuracies:
                gf: 0.92
                real: 1.00
                fake: 0.22

ran validation set (B:2601) in                         51.3 s.
(epoch: 12, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.086 loss_D_fake: 1.032 loss_D: 1.528 acc_real: 0.998 acc_fake: 0.222 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.166 acc_grfake: 0.917 
(epoch: 12, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.075 loss_D_fake: 1.209 loss_D: 1.614 acc_real: 0.998 acc_fake: 0.222 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.085 acc_grfake: 0.917 
(epoch: 12, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.125 loss_D_fake: 0.681 loss_D: 1.171 acc_real: 0.998 acc_fake: 0.222 loss_G_conf: 0.468 loss_AUX: 0.246 loss_D_gr_fake: 0.118 acc_grfake: 0.917 
(epoch: 12, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.097 loss_D_fake: 1.038 loss_D: 1.483 acc_real: 0.998 acc_fake: 0.222 loss_G_conf: 0.468 loss_AUX: 0.243 loss_D_gr_fake: 0.105 acc_grfake: 0.917 
(epoch: 12, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.059 loss_D_fake: 1.215 loss_D: 1.633 acc_real: 0.998 acc_fake: 0.222 loss_G_conf: 0.468 loss_AUX: 0.243 loss_D_gr_fake: 0.116 acc_grfake: 0.917 
validation accuracies:
                gf: 0.92
                real: 1.00
                fake: 0.14

ran validation set (B:2701) in                         50.8 s.
(epoch: 12, batches: 140, time: 0.009, data: 0.011) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.043 loss_D_fake: 1.366 loss_D: 1.890 acc_real: 0.996 acc_fake: 0.144 loss_G_conf: 0.468 loss_AUX: 0.242 loss_D_gr_fake: 0.239 acc_grfake: 0.918 
(epoch: 12, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.047 loss_D_fake: 1.374 loss_D: 1.719 acc_real: 0.996 acc_fake: 0.144 loss_G_conf: 0.468 loss_AUX: 0.242 loss_D_gr_fake: 0.056 acc_grfake: 0.918 
(epoch: 12, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.074 loss_D_fake: 0.922 loss_D: 1.353 acc_real: 0.996 acc_fake: 0.144 loss_G_conf: 0.468 loss_AUX: 0.242 loss_D_gr_fake: 0.116 acc_grfake: 0.918 
(epoch: 12, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.078 loss_D_fake: 1.088 loss_D: 1.521 acc_real: 0.996 acc_fake: 0.144 loss_G_conf: 0.468 loss_AUX: 0.246 loss_D_gr_fake: 0.110 acc_grfake: 0.918 
(epoch: 12, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.081 loss_D_fake: 0.895 loss_D: 1.333 acc_real: 0.996 acc_fake: 0.144 loss_G_conf: 0.468 loss_AUX: 0.242 loss_D_gr_fake: 0.115 acc_grfake: 0.918 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.50

ran validation set (B:2801) in                         50.3 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 12 / 30 	 Time Taken: 292 sec
(epoch: 13, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.056 loss_D_fake: 1.225 loss_D: 2.013 acc_real: 0.995 acc_fake: 0.497 loss_G_conf: 0.468 loss_AUX: 0.245 loss_D_gr_fake: 0.487 acc_grfake: 0.941 
(epoch: 13, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.046 loss_D_fake: 1.135 loss_D: 1.713 acc_real: 0.995 acc_fake: 0.497 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.287 acc_grfake: 0.941 
(epoch: 13, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.079 loss_D_fake: 1.246 loss_D: 1.810 acc_real: 0.995 acc_fake: 0.497 loss_G_conf: 0.468 loss_AUX: 0.242 loss_D_gr_fake: 0.243 acc_grfake: 0.941 
(epoch: 13, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.064 loss_D_fake: 1.149 loss_D: 1.634 acc_real: 0.995 acc_fake: 0.497 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.176 acc_grfake: 0.941 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.46

ran validation set (B:2901) in                         51.0 s.
(epoch: 13, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.050 loss_D_fake: 0.977 loss_D: 1.444 acc_real: 0.995 acc_fake: 0.458 loss_G_conf: 0.468 loss_AUX: 0.243 loss_D_gr_fake: 0.174 acc_grfake: 0.929 
(epoch: 13, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.050 loss_D_fake: 1.214 loss_D: 1.614 acc_real: 0.995 acc_fake: 0.458 loss_G_conf: 0.468 loss_AUX: 0.242 loss_D_gr_fake: 0.108 acc_grfake: 0.929 
(epoch: 13, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.106 loss_D_fake: 0.810 loss_D: 1.308 acc_real: 0.995 acc_fake: 0.458 loss_G_conf: 0.468 loss_AUX: 0.245 loss_D_gr_fake: 0.147 acc_grfake: 0.929 
(epoch: 13, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.050 loss_D_fake: 1.144 loss_D: 1.562 acc_real: 0.995 acc_fake: 0.458 loss_G_conf: 0.468 loss_AUX: 0.244 loss_D_gr_fake: 0.124 acc_grfake: 0.929 
(epoch: 13, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.305 loss_G_anti_sc: 0.831 loss_G: 1.604 loss_D_real: 0.053 loss_D_fake: 1.029 loss_D: 1.459 acc_real: 0.995 acc_fake: 0.458 loss_G_conf: 0.468 loss_AUX: 0.243 loss_D_gr_fake: 0.133 acc_grfake: 0.929 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.61

ran validation set (B:3001) in                         51.3 s.
(epoch: 13, batches: 200, time: 0.008, data: 0.006) loss_G_comp: 0.269 loss_G_anti_sc: 1.253 loss_G: 1.991 loss_D_real: 0.551 loss_D_fake: 0.355 loss_D: 1.194 acc_real: 0.995 acc_fake: 0.607 loss_G_conf: 0.469 loss_AUX: 0.243 loss_D_gr_fake: 0.044 acc_grfake: 0.940 
(epoch: 13, batches: 220, time: 0.008, data: 0.006) loss_G_comp: 0.604 loss_G_anti_sc: 0.573 loss_G: 1.645 loss_D_real: 0.218 loss_D_fake: 1.153 loss_D: 1.947 acc_real: 0.995 acc_fake: 0.607 loss_G_conf: 0.467 loss_AUX: 0.250 loss_D_gr_fake: 0.326 acc_grfake: 0.940 
learning rate 0.0001000 -> 0.0001000
End of epoch 13 / 30 	 Time Taken: 241 sec
(epoch: 14, batches: 20, time: 0.008, data: 0.007) loss_G_comp: 0.522 loss_G_anti_sc: 0.451 loss_G: 1.439 loss_D_real: 0.180 loss_D_fake: 1.066 loss_D: 1.687 acc_real: 0.995 acc_fake: 0.607 loss_G_conf: 0.467 loss_AUX: 0.247 loss_D_gr_fake: 0.194 acc_grfake: 0.940 
(epoch: 14, batches: 40, time: 0.008, data: 0.006) loss_G_comp: 0.369 loss_G_anti_sc: 0.639 loss_G: 1.474 loss_D_real: 0.139 loss_D_fake: 1.049 loss_D: 1.462 acc_real: 0.995 acc_fake: 0.607 loss_G_conf: 0.465 loss_AUX: 0.242 loss_D_gr_fake: 0.032 acc_grfake: 0.940 
validation accuracies:
                gf: 0.91
                real: 1.00
                fake: 0.04

ran validation set (B:3101) in                         51.1 s.
(epoch: 14, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.095 loss_D_fake: 1.279 loss_D: 1.748 acc_real: 0.999 acc_fake: 0.039 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.130 acc_grfake: 0.914 
(epoch: 14, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.155 loss_D_fake: 0.966 loss_D: 1.528 acc_real: 0.999 acc_fake: 0.039 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.164 acc_grfake: 0.914 
(epoch: 14, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.088 loss_D_fake: 1.363 loss_D: 1.917 acc_real: 0.999 acc_fake: 0.039 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.223 acc_grfake: 0.914 
(epoch: 14, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.058 loss_D_fake: 1.442 loss_D: 1.950 acc_real: 0.999 acc_fake: 0.039 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.207 acc_grfake: 0.914 
(epoch: 14, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.104 loss_D_fake: 1.223 loss_D: 1.734 acc_real: 0.999 acc_fake: 0.039 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.163 acc_grfake: 0.914 
validation accuracies:
                gf: 0.92
                real: 1.00
                fake: 0.22

ran validation set (B:3201) in                         50.9 s.
(epoch: 14, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.057 loss_D_fake: 1.289 loss_D: 1.848 acc_real: 0.997 acc_fake: 0.219 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.259 acc_grfake: 0.923 
(epoch: 14, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.077 loss_D_fake: 1.160 loss_D: 1.563 acc_real: 0.997 acc_fake: 0.219 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.083 acc_grfake: 0.923 
(epoch: 14, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.065 loss_D_fake: 0.955 loss_D: 1.324 acc_real: 0.997 acc_fake: 0.219 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.062 acc_grfake: 0.923 
(epoch: 14, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.055 loss_D_fake: 1.564 loss_D: 2.081 acc_real: 0.997 acc_fake: 0.219 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.219 acc_grfake: 0.923 
learning rate 0.0001000 -> 0.0001000
End of epoch 14 / 30 	 Time Taken: 241 sec
(epoch: 15, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.095 loss_D_fake: 1.062 loss_D: 1.475 acc_real: 0.997 acc_fake: 0.219 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.076 acc_grfake: 0.923 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.21

ran validation set (B:3301) in                         51.0 s.
(epoch: 15, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.055 loss_D_fake: 1.301 loss_D: 1.734 acc_real: 0.997 acc_fake: 0.211 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.136 acc_grfake: 0.929 
(epoch: 15, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.101 loss_D_fake: 0.938 loss_D: 1.357 acc_real: 0.997 acc_fake: 0.211 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.075 acc_grfake: 0.929 
(epoch: 15, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.062 loss_D_fake: 0.916 loss_D: 1.342 acc_real: 0.997 acc_fake: 0.211 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.122 acc_grfake: 0.929 
(epoch: 15, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.069 loss_D_fake: 1.143 loss_D: 1.814 acc_real: 0.997 acc_fake: 0.211 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.358 acc_grfake: 0.929 
(epoch: 15, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.063 loss_D_fake: 1.032 loss_D: 1.501 acc_real: 0.997 acc_fake: 0.211 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.163 acc_grfake: 0.929 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.26

ran validation set (B:3401) in                         51.2 s.
(epoch: 15, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.098 loss_D_fake: 0.877 loss_D: 1.369 acc_real: 0.999 acc_fake: 0.256 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.150 acc_grfake: 0.928 
(epoch: 15, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.065 loss_D_fake: 1.143 loss_D: 1.555 acc_real: 0.999 acc_fake: 0.256 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.104 acc_grfake: 0.928 
(epoch: 15, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.073 loss_D_fake: 0.973 loss_D: 1.505 acc_real: 0.999 acc_fake: 0.256 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.216 acc_grfake: 0.928 
(epoch: 15, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.040 loss_D_fake: 1.138 loss_D: 1.594 acc_real: 0.999 acc_fake: 0.256 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.174 acc_grfake: 0.928 
(epoch: 15, batches: 220, time: 0.009, data: 0.011) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.088 loss_D_fake: 0.829 loss_D: 1.379 acc_real: 0.999 acc_fake: 0.256 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.217 acc_grfake: 0.928 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.51

ran validation set (B:3501) in                         51.0 s.
saving the model at the end of epoch 15, iters 224640
learning rate 0.0001000 -> 0.0001000
End of epoch 15 / 30 	 Time Taken: 293 sec
(epoch: 16, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.046 loss_D_fake: 1.252 loss_D: 1.816 acc_real: 0.994 acc_fake: 0.513 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.275 acc_grfake: 0.935 
(epoch: 16, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.077 loss_D_fake: 0.986 loss_D: 1.384 acc_real: 0.994 acc_fake: 0.513 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.078 acc_grfake: 0.935 
(epoch: 16, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.049 loss_D_fake: 1.160 loss_D: 1.539 acc_real: 0.994 acc_fake: 0.513 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.087 acc_grfake: 0.935 
(epoch: 16, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.064 loss_D_fake: 0.927 loss_D: 1.443 acc_real: 0.994 acc_fake: 0.513 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.208 acc_grfake: 0.935 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.60

ran validation set (B:3601) in                         51.0 s.
(epoch: 16, batches: 100, time: 0.010, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.063 loss_D_fake: 0.963 loss_D: 1.634 acc_real: 0.995 acc_fake: 0.596 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.366 acc_grfake: 0.936 
(epoch: 16, batches: 120, time: 0.010, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.157 loss_D_fake: 0.620 loss_D: 1.141 acc_real: 0.995 acc_fake: 0.596 loss_G_conf: 0.464 loss_AUX: 0.242 loss_D_gr_fake: 0.122 acc_grfake: 0.936 
(epoch: 16, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.089 loss_D_fake: 0.837 loss_D: 1.304 acc_real: 0.995 acc_fake: 0.596 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.133 acc_grfake: 0.936 
(epoch: 16, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.093 loss_D_fake: 0.687 loss_D: 1.121 acc_real: 0.995 acc_fake: 0.596 loss_G_conf: 0.464 loss_AUX: 0.241 loss_D_gr_fake: 0.101 acc_grfake: 0.936 
(epoch: 16, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.049 loss_D_fake: 0.906 loss_D: 1.362 acc_real: 0.995 acc_fake: 0.596 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.163 acc_grfake: 0.936 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.51

ran validation set (B:3701) in                         50.7 s.
(epoch: 16, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.087 loss_D_fake: 0.720 loss_D: 1.182 acc_real: 0.997 acc_fake: 0.515 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.132 acc_grfake: 0.941 
(epoch: 16, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.057 loss_D_fake: 1.140 loss_D: 1.744 acc_real: 0.997 acc_fake: 0.515 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.304 acc_grfake: 0.941 
learning rate 0.0001000 -> 0.0001000
End of epoch 16 / 30 	 Time Taken: 243 sec
(epoch: 17, batches: 20, time: 0.009, data: 0.005) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.104 loss_D_fake: 0.605 loss_D: 1.074 acc_real: 0.997 acc_fake: 0.515 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.121 acc_grfake: 0.941 
(epoch: 17, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.080 loss_D_fake: 0.875 loss_D: 1.334 acc_real: 0.997 acc_fake: 0.515 loss_G_conf: 0.464 loss_AUX: 0.241 loss_D_gr_fake: 0.137 acc_grfake: 0.941 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.34

ran validation set (B:3801) in                         51.1 s.
(epoch: 17, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.061 loss_D_fake: 1.075 loss_D: 1.571 acc_real: 1.000 acc_fake: 0.341 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.192 acc_grfake: 0.942 
(epoch: 17, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.062 loss_D_fake: 0.978 loss_D: 1.509 acc_real: 1.000 acc_fake: 0.341 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.226 acc_grfake: 0.942 
(epoch: 17, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.044 loss_D_fake: 1.334 loss_D: 1.917 acc_real: 1.000 acc_fake: 0.341 loss_G_conf: 0.464 loss_AUX: 0.245 loss_D_gr_fake: 0.293 acc_grfake: 0.942 
(epoch: 17, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.048 loss_D_fake: 1.060 loss_D: 1.423 acc_real: 1.000 acc_fake: 0.341 loss_G_conf: 0.464 loss_AUX: 0.243 loss_D_gr_fake: 0.072 acc_grfake: 0.942 
(epoch: 17, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.307 loss_G_anti_sc: 0.628 loss_G: 1.399 loss_D_real: 0.034 loss_D_fake: 1.281 loss_D: 1.844 acc_real: 1.000 acc_fake: 0.341 loss_G_conf: 0.464 loss_AUX: 0.245 loss_D_gr_fake: 0.284 acc_grfake: 0.942 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.79

ran validation set (B:3901) in                         50.9 s.
(epoch: 17, batches: 160, time: 0.008, data: 0.006) loss_G_comp: 0.335 loss_G_anti_sc: 0.685 loss_G: 1.484 loss_D_real: 0.057 loss_D_fake: 0.931 loss_D: 1.544 acc_real: 0.967 acc_fake: 0.785 loss_G_conf: 0.464 loss_AUX: 0.244 loss_D_gr_fake: 0.311 acc_grfake: 0.947 
(epoch: 17, batches: 180, time: 0.008, data: 0.007) loss_G_comp: 1.021 loss_G_anti_sc: 0.285 loss_G: 1.770 loss_D_real: 0.268 loss_D_fake: 1.054 loss_D: 2.076 acc_real: 0.967 acc_fake: 0.785 loss_G_conf: 0.464 loss_AUX: 0.266 loss_D_gr_fake: 0.488 acc_grfake: 0.947 
(epoch: 17, batches: 200, time: 0.008, data: 0.007) loss_G_comp: 0.359 loss_G_anti_sc: 0.803 loss_G: 1.626 loss_D_real: 0.151 loss_D_fake: 1.329 loss_D: 2.085 acc_real: 0.967 acc_fake: 0.785 loss_G_conf: 0.464 loss_AUX: 0.246 loss_D_gr_fake: 0.359 acc_grfake: 0.947 
(epoch: 17, batches: 220, time: 0.008, data: 0.006) loss_G_comp: 0.686 loss_G_anti_sc: 0.213 loss_G: 1.362 loss_D_real: 0.102 loss_D_fake: 1.519 loss_D: 2.178 acc_real: 0.967 acc_fake: 0.785 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.313 acc_grfake: 0.947 
learning rate 0.0001000 -> 0.0001000
End of epoch 17 / 30 	 Time Taken: 240 sec
(epoch: 18, batches: 20, time: 0.008, data: 0.012) loss_G_comp: 0.366 loss_G_anti_sc: 0.441 loss_G: 1.269 loss_D_real: 0.122 loss_D_fake: 1.501 loss_D: 2.075 acc_real: 0.967 acc_fake: 0.785 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.208 acc_grfake: 0.947 
validation accuracies:
                gf: 0.93
                real: 0.97
                fake: 0.28

ran validation set (B:4001) in                         51.6 s.
(epoch: 18, batches: 40, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.103 loss_D_fake: 1.473 loss_D: 1.965 acc_real: 0.974 acc_fake: 0.284 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.148 acc_grfake: 0.932 
(epoch: 18, batches: 60, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.082 loss_D_fake: 1.408 loss_D: 1.859 acc_real: 0.974 acc_fake: 0.284 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.127 acc_grfake: 0.932 
(epoch: 18, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.053 loss_D_fake: 1.800 loss_D: 2.305 acc_real: 0.974 acc_fake: 0.284 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.210 acc_grfake: 0.932 
(epoch: 18, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.115 loss_D_fake: 0.962 loss_D: 1.437 acc_real: 0.974 acc_fake: 0.284 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.117 acc_grfake: 0.932 
(epoch: 18, batches: 120, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.062 loss_D_fake: 1.456 loss_D: 1.919 acc_real: 0.974 acc_fake: 0.284 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.159 acc_grfake: 0.932 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.24

ran validation set (B:4101) in                         50.9 s.
(epoch: 18, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.086 loss_D_fake: 1.288 loss_D: 1.760 acc_real: 0.997 acc_fake: 0.243 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.144 acc_grfake: 0.936 
(epoch: 18, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.054 loss_D_fake: 1.234 loss_D: 1.741 acc_real: 0.997 acc_fake: 0.243 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.209 acc_grfake: 0.936 
(epoch: 18, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.057 loss_D_fake: 1.258 loss_D: 1.828 acc_real: 0.997 acc_fake: 0.243 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.267 acc_grfake: 0.936 
(epoch: 18, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.046 loss_D_fake: 1.473 loss_D: 1.899 acc_real: 0.997 acc_fake: 0.243 loss_G_conf: 0.463 loss_AUX: 0.241 loss_D_gr_fake: 0.139 acc_grfake: 0.936 
(epoch: 18, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.059 loss_D_fake: 1.680 loss_D: 2.185 acc_real: 0.997 acc_fake: 0.243 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.204 acc_grfake: 0.936 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.30

ran validation set (B:4201) in                         51.1 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 18 / 30 	 Time Taken: 296 sec
(epoch: 19, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.075 loss_D_fake: 1.278 loss_D: 1.619 acc_real: 0.998 acc_fake: 0.296 loss_G_conf: 0.463 loss_AUX: 0.241 loss_D_gr_fake: 0.024 acc_grfake: 0.926 
(epoch: 19, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.047 loss_D_fake: 1.496 loss_D: 2.073 acc_real: 0.998 acc_fake: 0.296 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.285 acc_grfake: 0.926 
(epoch: 19, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.104 loss_D_fake: 1.028 loss_D: 1.469 acc_real: 0.998 acc_fake: 0.296 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.092 acc_grfake: 0.926 
(epoch: 19, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.160 loss_D_fake: 0.605 loss_D: 1.119 acc_real: 0.998 acc_fake: 0.296 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.112 acc_grfake: 0.926 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.34

ran validation set (B:4301) in                         51.4 s.
(epoch: 19, batches: 100, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.025 loss_D_fake: 1.548 loss_D: 1.986 acc_real: 0.996 acc_fake: 0.344 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.168 acc_grfake: 0.940 
(epoch: 19, batches: 120, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.068 loss_D_fake: 0.959 loss_D: 1.402 acc_real: 0.996 acc_fake: 0.344 loss_G_conf: 0.463 loss_AUX: 0.245 loss_D_gr_fake: 0.130 acc_grfake: 0.940 
(epoch: 19, batches: 140, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.046 loss_D_fake: 1.168 loss_D: 1.729 acc_real: 0.996 acc_fake: 0.344 loss_G_conf: 0.463 loss_AUX: 0.245 loss_D_gr_fake: 0.271 acc_grfake: 0.940 
(epoch: 19, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.104 loss_D_fake: 0.944 loss_D: 1.358 acc_real: 0.996 acc_fake: 0.344 loss_G_conf: 0.463 loss_AUX: 0.245 loss_D_gr_fake: 0.065 acc_grfake: 0.940 
(epoch: 19, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.066 loss_D_fake: 1.280 loss_D: 1.783 acc_real: 0.996 acc_fake: 0.344 loss_G_conf: 0.463 loss_AUX: 0.247 loss_D_gr_fake: 0.189 acc_grfake: 0.940 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.28

ran validation set (B:4401) in                         51.0 s.
(epoch: 19, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.091 loss_D_fake: 0.966 loss_D: 1.411 acc_real: 0.998 acc_fake: 0.281 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.110 acc_grfake: 0.935 
(epoch: 19, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.065 loss_D_fake: 1.384 loss_D: 1.982 acc_real: 0.998 acc_fake: 0.281 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.286 acc_grfake: 0.935 
learning rate 0.0001000 -> 0.0001000
End of epoch 19 / 30 	 Time Taken: 247 sec
(epoch: 20, batches: 20, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.066 loss_D_fake: 1.007 loss_D: 1.588 acc_real: 0.998 acc_fake: 0.281 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.271 acc_grfake: 0.935 
(epoch: 20, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.073 loss_D_fake: 0.911 loss_D: 1.380 acc_real: 0.998 acc_fake: 0.281 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.153 acc_grfake: 0.935 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.38

ran validation set (B:4501) in                         50.9 s.
(epoch: 20, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.092 loss_D_fake: 1.016 loss_D: 1.576 acc_real: 0.998 acc_fake: 0.379 loss_G_conf: 0.463 loss_AUX: 0.245 loss_D_gr_fake: 0.222 acc_grfake: 0.940 
(epoch: 20, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.051 loss_D_fake: 0.961 loss_D: 1.365 acc_real: 0.998 acc_fake: 0.379 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.110 acc_grfake: 0.940 
(epoch: 20, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.079 loss_D_fake: 0.969 loss_D: 1.381 acc_real: 0.998 acc_fake: 0.379 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.091 acc_grfake: 0.940 
(epoch: 20, batches: 120, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.069 loss_D_fake: 0.904 loss_D: 1.281 acc_real: 0.998 acc_fake: 0.379 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.064 acc_grfake: 0.940 
(epoch: 20, batches: 140, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.110 loss_D_fake: 0.698 loss_D: 1.094 acc_real: 0.998 acc_fake: 0.379 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.043 acc_grfake: 0.940 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.30

ran validation set (B:4601) in                         51.6 s.
(epoch: 20, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.078 loss_D_fake: 0.834 loss_D: 1.265 acc_real: 1.000 acc_fake: 0.300 loss_G_conf: 0.463 loss_AUX: 0.249 loss_D_gr_fake: 0.103 acc_grfake: 0.936 
(epoch: 20, batches: 180, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.045 loss_D_fake: 1.051 loss_D: 1.449 acc_real: 1.000 acc_fake: 0.300 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.107 acc_grfake: 0.936 
(epoch: 20, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.063 loss_D_fake: 1.093 loss_D: 1.550 acc_real: 1.000 acc_fake: 0.300 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.149 acc_grfake: 0.936 
(epoch: 20, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.061 loss_D_fake: 0.721 loss_D: 1.226 acc_real: 1.000 acc_fake: 0.300 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.199 acc_grfake: 0.936 
learning rate 0.0001000 -> 0.0000800
End of epoch 20 / 30 	 Time Taken: 248 sec
(epoch: 21, batches: 20, time: 0.017, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.045 loss_D_fake: 1.068 loss_D: 1.477 acc_real: 1.000 acc_fake: 0.300 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.120 acc_grfake: 0.936 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.44

ran validation set (B:4701) in                         51.3 s.
(epoch: 21, batches: 40, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.053 loss_D_fake: 0.970 loss_D: 1.357 acc_real: 0.996 acc_fake: 0.435 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.092 acc_grfake: 0.941 
(epoch: 21, batches: 60, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.054 loss_D_fake: 1.135 loss_D: 1.573 acc_real: 0.996 acc_fake: 0.435 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.139 acc_grfake: 0.941 
(epoch: 21, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.080 loss_D_fake: 0.877 loss_D: 1.222 acc_real: 0.996 acc_fake: 0.435 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.023 acc_grfake: 0.941 
(epoch: 21, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.043 loss_D_fake: 1.178 loss_D: 1.734 acc_real: 0.996 acc_fake: 0.435 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.268 acc_grfake: 0.941 
(epoch: 21, batches: 120, time: 0.015, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.063 loss_D_fake: 1.037 loss_D: 1.599 acc_real: 0.996 acc_fake: 0.435 loss_G_conf: 0.463 loss_AUX: 0.245 loss_D_gr_fake: 0.254 acc_grfake: 0.941 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.48

ran validation set (B:4801) in                         51.0 s.
(epoch: 21, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.051 loss_D_fake: 1.026 loss_D: 1.440 acc_real: 0.996 acc_fake: 0.476 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.120 acc_grfake: 0.933 
(epoch: 21, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.050 loss_D_fake: 0.992 loss_D: 1.576 acc_real: 0.996 acc_fake: 0.476 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.288 acc_grfake: 0.933 
(epoch: 21, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.061 loss_D_fake: 0.940 loss_D: 1.302 acc_real: 0.996 acc_fake: 0.476 loss_G_conf: 0.463 loss_AUX: 0.242 loss_D_gr_fake: 0.059 acc_grfake: 0.933 
(epoch: 21, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.032 loss_D_fake: 1.308 loss_D: 1.805 acc_real: 0.996 acc_fake: 0.476 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.222 acc_grfake: 0.933 
(epoch: 21, batches: 220, time: 0.015, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.093 loss_D_fake: 0.962 loss_D: 1.414 acc_real: 0.996 acc_fake: 0.476 loss_G_conf: 0.463 loss_AUX: 0.247 loss_D_gr_fake: 0.111 acc_grfake: 0.933 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.44

ran validation set (B:4901) in                         50.9 s.
learning rate 0.0000800 -> 0.0000800
End of epoch 21 / 30 	 Time Taken: 295 sec
(epoch: 22, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.055 loss_D_fake: 0.807 loss_D: 1.114 acc_real: 0.997 acc_fake: 0.438 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.007 acc_grfake: 0.941 
(epoch: 22, batches: 40, time: 0.009, data: 0.008) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.045 loss_D_fake: 1.236 loss_D: 1.933 acc_real: 0.997 acc_fake: 0.438 loss_G_conf: 0.463 loss_AUX: 0.245 loss_D_gr_fake: 0.407 acc_grfake: 0.941 
(epoch: 22, batches: 60, time: 0.010, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.062 loss_D_fake: 0.881 loss_D: 1.329 acc_real: 0.997 acc_fake: 0.438 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.142 acc_grfake: 0.941 
(epoch: 22, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.059 loss_D_fake: 0.958 loss_D: 1.330 acc_real: 0.997 acc_fake: 0.438 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.070 acc_grfake: 0.941 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.37

ran validation set (B:5001) in                         51.3 s.
(epoch: 22, batches: 100, time: 0.009, data: 0.008) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.072 loss_D_fake: 0.781 loss_D: 1.299 acc_real: 0.998 acc_fake: 0.369 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.199 acc_grfake: 0.938 
(epoch: 22, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.153 loss_D_fake: 0.387 loss_D: 0.848 acc_real: 0.998 acc_fake: 0.369 loss_G_conf: 0.463 loss_AUX: 0.248 loss_D_gr_fake: 0.060 acc_grfake: 0.938 
(epoch: 22, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.052 loss_D_fake: 0.999 loss_D: 1.394 acc_real: 0.998 acc_fake: 0.369 loss_G_conf: 0.463 loss_AUX: 0.243 loss_D_gr_fake: 0.099 acc_grfake: 0.938 
(epoch: 22, batches: 160, time: 0.009, data: 0.008) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.038 loss_D_fake: 1.081 loss_D: 1.516 acc_real: 0.998 acc_fake: 0.369 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.152 acc_grfake: 0.938 
(epoch: 22, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.559 loss_G_anti_sc: 0.241 loss_G: 1.262 loss_D_real: 0.051 loss_D_fake: 1.035 loss_D: 1.530 acc_real: 0.998 acc_fake: 0.369 loss_G_conf: 0.463 loss_AUX: 0.244 loss_D_gr_fake: 0.200 acc_grfake: 0.938 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.61

ran validation set (B:5101) in                         51.2 s.
(epoch: 22, batches: 200, time: 0.008, data: 0.007) loss_G_comp: 0.729 loss_G_anti_sc: 0.351 loss_G: 1.542 loss_D_real: 0.039 loss_D_fake: 2.365 loss_D: 2.949 acc_real: 0.994 acc_fake: 0.606 loss_G_conf: 0.462 loss_AUX: 0.256 loss_D_gr_fake: 0.290 acc_grfake: 0.934 
(epoch: 22, batches: 220, time: 0.008, data: 0.007) loss_G_comp: 0.519 loss_G_anti_sc: 0.271 loss_G: 1.252 loss_D_real: 0.051 loss_D_fake: 2.317 loss_D: 3.149 acc_real: 0.994 acc_fake: 0.606 loss_G_conf: 0.461 loss_AUX: 0.246 loss_D_gr_fake: 0.535 acc_grfake: 0.934 
learning rate 0.0000800 -> 0.0000800
End of epoch 22 / 30 	 Time Taken: 241 sec
(epoch: 23, batches: 20, time: 0.008, data: 0.005) loss_G_comp: 0.330 loss_G_anti_sc: 0.392 loss_G: 1.183 loss_D_real: 0.080 loss_D_fake: 1.763 loss_D: 2.118 acc_real: 0.994 acc_fake: 0.606 loss_G_conf: 0.460 loss_AUX: 0.246 loss_D_gr_fake: 0.029 acc_grfake: 0.934 
(epoch: 23, batches: 40, time: 0.008, data: 0.006) loss_G_comp: 0.394 loss_G_anti_sc: 0.331 loss_G: 1.185 loss_D_real: 0.038 loss_D_fake: 2.265 loss_D: 2.746 acc_real: 0.994 acc_fake: 0.606 loss_G_conf: 0.460 loss_AUX: 0.246 loss_D_gr_fake: 0.197 acc_grfake: 0.934 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.03

ran validation set (B:5201) in                         51.1 s.
(epoch: 23, batches: 60, time: 0.010, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.059 loss_D_fake: 1.746 loss_D: 2.189 acc_real: 1.000 acc_fake: 0.031 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.138 acc_grfake: 0.928 
(epoch: 23, batches: 80, time: 0.010, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.046 loss_D_fake: 2.086 loss_D: 2.604 acc_real: 1.000 acc_fake: 0.031 loss_G_conf: 0.459 loss_AUX: 0.244 loss_D_gr_fake: 0.229 acc_grfake: 0.928 
(epoch: 23, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.081 loss_D_fake: 1.447 loss_D: 1.838 acc_real: 1.000 acc_fake: 0.031 loss_G_conf: 0.459 loss_AUX: 0.245 loss_D_gr_fake: 0.064 acc_grfake: 0.928 
(epoch: 23, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.079 loss_D_fake: 1.222 loss_D: 1.671 acc_real: 1.000 acc_fake: 0.031 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.124 acc_grfake: 0.928 
(epoch: 23, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.028 loss_D_fake: 1.962 loss_D: 2.475 acc_real: 1.000 acc_fake: 0.031 loss_G_conf: 0.459 loss_AUX: 0.245 loss_D_gr_fake: 0.239 acc_grfake: 0.928 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.17

ran validation set (B:5301) in                         51.1 s.
(epoch: 23, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.054 loss_D_fake: 1.565 loss_D: 1.950 acc_real: 0.999 acc_fake: 0.168 loss_G_conf: 0.459 loss_AUX: 0.245 loss_D_gr_fake: 0.086 acc_grfake: 0.932 
(epoch: 23, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.056 loss_D_fake: 1.161 loss_D: 1.532 acc_real: 0.999 acc_fake: 0.168 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.068 acc_grfake: 0.932 
(epoch: 23, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.049 loss_D_fake: 1.266 loss_D: 1.642 acc_real: 0.999 acc_fake: 0.168 loss_G_conf: 0.459 loss_AUX: 0.244 loss_D_gr_fake: 0.083 acc_grfake: 0.932 
(epoch: 23, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.055 loss_D_fake: 1.023 loss_D: 1.392 acc_real: 0.999 acc_fake: 0.168 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.066 acc_grfake: 0.932 
learning rate 0.0000800 -> 0.0000800
End of epoch 23 / 30 	 Time Taken: 240 sec
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.25

ran validation set (B:5401) in                         51.5 s.
(epoch: 24, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.072 loss_D_fake: 1.063 loss_D: 1.410 acc_real: 1.000 acc_fake: 0.247 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.029 acc_grfake: 0.944 
(epoch: 24, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.030 loss_D_fake: 1.667 loss_D: 2.118 acc_real: 1.000 acc_fake: 0.247 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.175 acc_grfake: 0.944 
(epoch: 24, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.049 loss_D_fake: 1.344 loss_D: 1.720 acc_real: 1.000 acc_fake: 0.247 loss_G_conf: 0.459 loss_AUX: 0.245 loss_D_gr_fake: 0.083 acc_grfake: 0.944 
(epoch: 24, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.075 loss_D_fake: 0.994 loss_D: 1.457 acc_real: 1.000 acc_fake: 0.247 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.140 acc_grfake: 0.944 
(epoch: 24, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.072 loss_D_fake: 0.945 loss_D: 1.417 acc_real: 1.000 acc_fake: 0.247 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.151 acc_grfake: 0.944 
validation accuracies:
                gf: 0.95
                real: 1.00
                fake: 0.30

ran validation set (B:5501) in                         51.2 s.
(epoch: 24, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.050 loss_D_fake: 1.300 loss_D: 1.747 acc_real: 0.998 acc_fake: 0.303 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.150 acc_grfake: 0.946 
(epoch: 24, batches: 140, time: 0.010, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.086 loss_D_fake: 0.986 loss_D: 1.402 acc_real: 0.998 acc_fake: 0.303 loss_G_conf: 0.459 loss_AUX: 0.245 loss_D_gr_fake: 0.084 acc_grfake: 0.946 
(epoch: 24, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.061 loss_D_fake: 1.015 loss_D: 1.512 acc_real: 0.998 acc_fake: 0.303 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.190 acc_grfake: 0.946 
(epoch: 24, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.032 loss_D_fake: 1.253 loss_D: 1.790 acc_real: 0.998 acc_fake: 0.303 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.258 acc_grfake: 0.946 
(epoch: 24, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.069 loss_D_fake: 1.058 loss_D: 1.501 acc_real: 0.998 acc_fake: 0.303 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.129 acc_grfake: 0.946 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.55

ran validation set (B:5601) in                         51.1 s.
(epoch: 24, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.068 loss_D_fake: 0.757 loss_D: 1.258 acc_real: 0.993 acc_fake: 0.547 loss_G_conf: 0.459 loss_AUX: 0.249 loss_D_gr_fake: 0.184 acc_grfake: 0.948 
learning rate 0.0000800 -> 0.0000800
End of epoch 24 / 30 	 Time Taken: 293 sec
(epoch: 25, batches: 20, time: 0.009, data: 0.008) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.055 loss_D_fake: 1.160 loss_D: 1.555 acc_real: 0.993 acc_fake: 0.547 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.093 acc_grfake: 0.948 
(epoch: 25, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.040 loss_D_fake: 1.348 loss_D: 1.814 acc_real: 0.993 acc_fake: 0.547 loss_G_conf: 0.459 loss_AUX: 0.246 loss_D_gr_fake: 0.180 acc_grfake: 0.948 
(epoch: 25, batches: 60, time: 0.009, data: 0.011) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.061 loss_D_fake: 1.006 loss_D: 1.369 acc_real: 0.993 acc_fake: 0.547 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.054 acc_grfake: 0.948 
(epoch: 25, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.063 loss_D_fake: 0.974 loss_D: 1.450 acc_real: 0.993 acc_fake: 0.547 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.165 acc_grfake: 0.948 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.32

ran validation set (B:5701) in                         51.3 s.
(epoch: 25, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.060 loss_D_fake: 1.099 loss_D: 1.527 acc_real: 0.999 acc_fake: 0.319 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.119 acc_grfake: 0.941 
(epoch: 25, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.041 loss_D_fake: 1.296 loss_D: 1.721 acc_real: 0.999 acc_fake: 0.319 loss_G_conf: 0.459 loss_AUX: 0.244 loss_D_gr_fake: 0.140 acc_grfake: 0.941 
(epoch: 25, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.080 loss_D_fake: 0.881 loss_D: 1.366 acc_real: 0.999 acc_fake: 0.319 loss_G_conf: 0.459 loss_AUX: 0.251 loss_D_gr_fake: 0.155 acc_grfake: 0.941 
(epoch: 25, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.039 loss_D_fake: 1.222 loss_D: 1.684 acc_real: 0.999 acc_fake: 0.319 loss_G_conf: 0.459 loss_AUX: 0.245 loss_D_gr_fake: 0.178 acc_grfake: 0.941 
(epoch: 25, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.073 loss_D_fake: 1.151 loss_D: 1.689 acc_real: 0.999 acc_fake: 0.319 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.219 acc_grfake: 0.941 
validation accuracies:
                gf: 0.96
                real: 1.00
                fake: 0.39

ran validation set (B:5801) in                         51.2 s.
(epoch: 25, batches: 200, time: 0.009, data: 0.008) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.059 loss_D_fake: 1.247 loss_D: 1.690 acc_real: 0.996 acc_fake: 0.393 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.135 acc_grfake: 0.956 
(epoch: 25, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.045 loss_D_fake: 1.065 loss_D: 1.492 acc_real: 0.996 acc_fake: 0.393 loss_G_conf: 0.459 loss_AUX: 0.250 loss_D_gr_fake: 0.132 acc_grfake: 0.956 
learning rate 0.0000800 -> 0.0000800
End of epoch 25 / 30 	 Time Taken: 239 sec
(epoch: 26, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.068 loss_D_fake: 1.311 loss_D: 1.687 acc_real: 0.996 acc_fake: 0.393 loss_G_conf: 0.459 loss_AUX: 0.250 loss_D_gr_fake: 0.059 acc_grfake: 0.956 
(epoch: 26, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.049 loss_D_fake: 1.222 loss_D: 1.646 acc_real: 0.996 acc_fake: 0.393 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.128 acc_grfake: 0.956 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.58

ran validation set (B:5901) in                         51.1 s.
(epoch: 26, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.050 loss_D_fake: 1.101 loss_D: 1.457 acc_real: 0.966 acc_fake: 0.576 loss_G_conf: 0.459 loss_AUX: 0.247 loss_D_gr_fake: 0.059 acc_grfake: 0.952 
(epoch: 26, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.091 loss_D_fake: 0.819 loss_D: 1.410 acc_real: 0.966 acc_fake: 0.576 loss_G_conf: 0.459 loss_AUX: 0.250 loss_D_gr_fake: 0.250 acc_grfake: 0.952 
(epoch: 26, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.041 loss_D_fake: 1.204 loss_D: 1.721 acc_real: 0.966 acc_fake: 0.576 loss_G_conf: 0.459 loss_AUX: 0.249 loss_D_gr_fake: 0.227 acc_grfake: 0.952 
(epoch: 26, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.038 loss_D_fake: 1.038 loss_D: 1.448 acc_real: 0.966 acc_fake: 0.576 loss_G_conf: 0.459 loss_AUX: 0.248 loss_D_gr_fake: 0.124 acc_grfake: 0.952 
(epoch: 26, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.208 loss_G_anti_sc: 0.577 loss_G: 1.245 loss_D_real: 0.081 loss_D_fake: 0.892 loss_D: 1.370 acc_real: 0.966 acc_fake: 0.576 loss_G_conf: 0.459 loss_AUX: 0.249 loss_D_gr_fake: 0.149 acc_grfake: 0.952 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.68

ran validation set (B:6001) in                         51.2 s.
(epoch: 26, batches: 160, time: 0.008, data: 0.007) loss_G_comp: 2.203 loss_G_anti_sc: 0.074 loss_G: 2.738 loss_D_real: 0.018 loss_D_fake: 2.528 loss_D: 3.361 acc_real: 0.989 acc_fake: 0.675 loss_G_conf: 0.461 loss_AUX: 0.259 loss_D_gr_fake: 0.556 acc_grfake: 0.947 
(epoch: 26, batches: 180, time: 0.008, data: 0.007) loss_G_comp: 0.438 loss_G_anti_sc: 0.396 loss_G: 1.292 loss_D_real: 0.147 loss_D_fake: 1.325 loss_D: 1.928 acc_real: 0.989 acc_fake: 0.675 loss_G_conf: 0.459 loss_AUX: 0.257 loss_D_gr_fake: 0.200 acc_grfake: 0.947 
(epoch: 26, batches: 200, time: 0.008, data: 0.007) loss_G_comp: 0.345 loss_G_anti_sc: 0.488 loss_G: 1.292 loss_D_real: 0.123 loss_D_fake: 1.443 loss_D: 2.084 acc_real: 0.989 acc_fake: 0.675 loss_G_conf: 0.459 loss_AUX: 0.253 loss_D_gr_fake: 0.265 acc_grfake: 0.947 
(epoch: 26, batches: 220, time: 0.008, data: 0.007) loss_G_comp: 0.300 loss_G_anti_sc: 0.484 loss_G: 1.242 loss_D_real: 0.137 loss_D_fake: 1.278 loss_D: 1.748 acc_real: 0.989 acc_fake: 0.675 loss_G_conf: 0.458 loss_AUX: 0.251 loss_D_gr_fake: 0.082 acc_grfake: 0.947 
learning rate 0.0000800 -> 0.0000800
End of epoch 26 / 30 	 Time Taken: 237 sec
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.17

ran validation set (B:6101) in                         50.8 s.
(epoch: 27, batches: 20, time: 0.008, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.021 loss_D_fake: 3.065 loss_D: 3.532 acc_real: 0.986 acc_fake: 0.174 loss_G_conf: 0.457 loss_AUX: 0.248 loss_D_gr_fake: 0.198 acc_grfake: 0.935 
(epoch: 27, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.061 loss_D_fake: 2.034 loss_D: 2.448 acc_real: 0.986 acc_fake: 0.174 loss_G_conf: 0.457 loss_AUX: 0.249 loss_D_gr_fake: 0.103 acc_grfake: 0.935 
(epoch: 27, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.046 loss_D_fake: 2.061 loss_D: 2.560 acc_real: 0.986 acc_fake: 0.174 loss_G_conf: 0.457 loss_AUX: 0.250 loss_D_gr_fake: 0.204 acc_grfake: 0.935 
(epoch: 27, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.057 loss_D_fake: 2.023 loss_D: 2.441 acc_real: 0.986 acc_fake: 0.174 loss_G_conf: 0.457 loss_AUX: 0.249 loss_D_gr_fake: 0.111 acc_grfake: 0.935 
(epoch: 27, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.087 loss_D_fake: 1.364 loss_D: 1.774 acc_real: 0.986 acc_fake: 0.174 loss_G_conf: 0.457 loss_AUX: 0.251 loss_D_gr_fake: 0.072 acc_grfake: 0.935 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.16

ran validation set (B:6201) in                         51.0 s.
(epoch: 27, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.120 loss_D_fake: 1.093 loss_D: 1.523 acc_real: 0.998 acc_fake: 0.164 loss_G_conf: 0.457 loss_AUX: 0.251 loss_D_gr_fake: 0.059 acc_grfake: 0.942 
(epoch: 27, batches: 140, time: 0.009, data: 0.008) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.093 loss_D_fake: 1.320 loss_D: 1.811 acc_real: 0.998 acc_fake: 0.164 loss_G_conf: 0.457 loss_AUX: 0.254 loss_D_gr_fake: 0.145 acc_grfake: 0.942 
(epoch: 27, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.034 loss_D_fake: 2.029 loss_D: 2.438 acc_real: 0.998 acc_fake: 0.164 loss_G_conf: 0.457 loss_AUX: 0.250 loss_D_gr_fake: 0.126 acc_grfake: 0.942 
(epoch: 27, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.076 loss_D_fake: 1.240 loss_D: 1.653 acc_real: 0.998 acc_fake: 0.164 loss_G_conf: 0.457 loss_AUX: 0.253 loss_D_gr_fake: 0.083 acc_grfake: 0.942 
(epoch: 27, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.049 loss_D_fake: 1.625 loss_D: 2.107 acc_real: 0.998 acc_fake: 0.164 loss_G_conf: 0.457 loss_AUX: 0.249 loss_D_gr_fake: 0.183 acc_grfake: 0.942 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.30

ran validation set (B:6301) in                         50.9 s.
(epoch: 27, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.075 loss_D_fake: 1.169 loss_D: 1.551 acc_real: 0.996 acc_fake: 0.299 loss_G_conf: 0.457 loss_AUX: 0.252 loss_D_gr_fake: 0.055 acc_grfake: 0.938 
learning rate 0.0000800 -> 0.0000800
End of epoch 27 / 30 	 Time Taken: 294 sec
(epoch: 28, batches: 20, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.075 loss_D_fake: 1.195 loss_D: 1.611 acc_real: 0.996 acc_fake: 0.299 loss_G_conf: 0.457 loss_AUX: 0.253 loss_D_gr_fake: 0.088 acc_grfake: 0.938 
(epoch: 28, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.077 loss_D_fake: 1.200 loss_D: 1.608 acc_real: 0.996 acc_fake: 0.299 loss_G_conf: 0.457 loss_AUX: 0.253 loss_D_gr_fake: 0.078 acc_grfake: 0.938 
(epoch: 28, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.070 loss_D_fake: 1.258 loss_D: 1.614 acc_real: 0.996 acc_fake: 0.299 loss_G_conf: 0.457 loss_AUX: 0.252 loss_D_gr_fake: 0.034 acc_grfake: 0.938 
(epoch: 28, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.052 loss_D_fake: 1.410 loss_D: 1.899 acc_real: 0.996 acc_fake: 0.299 loss_G_conf: 0.457 loss_AUX: 0.253 loss_D_gr_fake: 0.184 acc_grfake: 0.938 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.23

ran validation set (B:6401) in                         50.9 s.
(epoch: 28, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.047 loss_D_fake: 1.412 loss_D: 1.999 acc_real: 1.000 acc_fake: 0.227 loss_G_conf: 0.457 loss_AUX: 0.255 loss_D_gr_fake: 0.286 acc_grfake: 0.936 
(epoch: 28, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.037 loss_D_fake: 1.512 loss_D: 1.912 acc_real: 1.000 acc_fake: 0.227 loss_G_conf: 0.457 loss_AUX: 0.251 loss_D_gr_fake: 0.111 acc_grfake: 0.936 
(epoch: 28, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.093 loss_D_fake: 0.935 loss_D: 1.484 acc_real: 1.000 acc_fake: 0.227 loss_G_conf: 0.457 loss_AUX: 0.257 loss_D_gr_fake: 0.199 acc_grfake: 0.936 
(epoch: 28, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.063 loss_D_fake: 1.192 loss_D: 1.742 acc_real: 1.000 acc_fake: 0.227 loss_G_conf: 0.457 loss_AUX: 0.256 loss_D_gr_fake: 0.231 acc_grfake: 0.936 
(epoch: 28, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.060 loss_D_fake: 0.904 loss_D: 1.374 acc_real: 1.000 acc_fake: 0.227 loss_G_conf: 0.457 loss_AUX: 0.256 loss_D_gr_fake: 0.154 acc_grfake: 0.936 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.38

ran validation set (B:6501) in                         50.9 s.
(epoch: 28, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.050 loss_D_fake: 1.513 loss_D: 2.002 acc_real: 0.994 acc_fake: 0.380 loss_G_conf: 0.457 loss_AUX: 0.255 loss_D_gr_fake: 0.184 acc_grfake: 0.948 
(epoch: 28, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.072 loss_D_fake: 0.987 loss_D: 1.551 acc_real: 0.994 acc_fake: 0.380 loss_G_conf: 0.457 loss_AUX: 0.256 loss_D_gr_fake: 0.236 acc_grfake: 0.948 
learning rate 0.0000800 -> 0.0000800
End of epoch 28 / 30 	 Time Taken: 240 sec
(epoch: 29, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.096 loss_D_fake: 0.866 loss_D: 1.252 acc_real: 0.994 acc_fake: 0.380 loss_G_conf: 0.457 loss_AUX: 0.256 loss_D_gr_fake: 0.033 acc_grfake: 0.948 
(epoch: 29, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.066 loss_D_fake: 1.288 loss_D: 1.864 acc_real: 0.994 acc_fake: 0.380 loss_G_conf: 0.457 loss_AUX: 0.256 loss_D_gr_fake: 0.253 acc_grfake: 0.948 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.46

ran validation set (B:6601) in                         51.1 s.
(epoch: 29, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.056 loss_D_fake: 1.049 loss_D: 1.578 acc_real: 0.996 acc_fake: 0.456 loss_G_conf: 0.457 loss_AUX: 0.258 loss_D_gr_fake: 0.216 acc_grfake: 0.943 
(epoch: 29, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.042 loss_D_fake: 1.398 loss_D: 1.766 acc_real: 0.996 acc_fake: 0.456 loss_G_conf: 0.457 loss_AUX: 0.257 loss_D_gr_fake: 0.070 acc_grfake: 0.943 
(epoch: 29, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.050 loss_D_fake: 1.117 loss_D: 1.559 acc_real: 0.996 acc_fake: 0.456 loss_G_conf: 0.457 loss_AUX: 0.259 loss_D_gr_fake: 0.132 acc_grfake: 0.943 
(epoch: 29, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.048 loss_D_fake: 1.298 loss_D: 1.832 acc_real: 0.996 acc_fake: 0.456 loss_G_conf: 0.457 loss_AUX: 0.259 loss_D_gr_fake: 0.226 acc_grfake: 0.943 
(epoch: 29, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.042 loss_D_fake: 1.012 loss_D: 1.353 acc_real: 0.996 acc_fake: 0.456 loss_G_conf: 0.457 loss_AUX: 0.256 loss_D_gr_fake: 0.043 acc_grfake: 0.943 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.40

ran validation set (B:6701) in                         51.1 s.
(epoch: 29, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.061 loss_D_fake: 1.138 loss_D: 1.610 acc_real: 0.996 acc_fake: 0.399 loss_G_conf: 0.457 loss_AUX: 0.259 loss_D_gr_fake: 0.152 acc_grfake: 0.936 
(epoch: 29, batches: 180, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.038 loss_D_fake: 1.331 loss_D: 1.896 acc_real: 0.996 acc_fake: 0.399 loss_G_conf: 0.457 loss_AUX: 0.258 loss_D_gr_fake: 0.270 acc_grfake: 0.936 
(epoch: 29, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.048 loss_D_fake: 1.090 loss_D: 1.729 acc_real: 0.996 acc_fake: 0.399 loss_G_conf: 0.457 loss_AUX: 0.258 loss_D_gr_fake: 0.334 acc_grfake: 0.936 
(epoch: 29, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.060 loss_D_fake: 1.124 loss_D: 1.542 acc_real: 0.996 acc_fake: 0.399 loss_G_conf: 0.457 loss_AUX: 0.257 loss_D_gr_fake: 0.102 acc_grfake: 0.936 
learning rate 0.0000800 -> 0.0000800
End of epoch 29 / 30 	 Time Taken: 243 sec
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.48

ran validation set (B:6801) in                         51.1 s.
(epoch: 30, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.091 loss_D_fake: 0.917 loss_D: 1.394 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.457 loss_AUX: 0.260 loss_D_gr_fake: 0.125 acc_grfake: 0.946 
(epoch: 30, batches: 40, time: 0.010, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.036 loss_D_fake: 1.099 loss_D: 1.566 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.457 loss_AUX: 0.264 loss_D_gr_fake: 0.167 acc_grfake: 0.946 
(epoch: 30, batches: 60, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.082 loss_D_fake: 1.015 loss_D: 1.530 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.457 loss_AUX: 0.259 loss_D_gr_fake: 0.174 acc_grfake: 0.946 
(epoch: 30, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.069 loss_D_fake: 1.032 loss_D: 1.453 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.457 loss_AUX: 0.261 loss_D_gr_fake: 0.091 acc_grfake: 0.946 
(epoch: 30, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.036 loss_D_fake: 1.376 loss_D: 1.912 acc_real: 0.993 acc_fake: 0.477 loss_G_conf: 0.457 loss_AUX: 0.260 loss_D_gr_fake: 0.239 acc_grfake: 0.946 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.36

ran validation set (B:6901) in                         51.3 s.
(epoch: 30, batches: 120, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.057 loss_D_fake: 0.883 loss_D: 1.331 acc_real: 0.998 acc_fake: 0.360 loss_G_conf: 0.457 loss_AUX: 0.260 loss_D_gr_fake: 0.130 acc_grfake: 0.943 
(epoch: 30, batches: 140, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.039 loss_D_fake: 1.236 loss_D: 1.873 acc_real: 0.998 acc_fake: 0.360 loss_G_conf: 0.457 loss_AUX: 0.263 loss_D_gr_fake: 0.334 acc_grfake: 0.943 
(epoch: 30, batches: 160, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.108 loss_D_fake: 0.793 loss_D: 1.194 acc_real: 0.998 acc_fake: 0.360 loss_G_conf: 0.457 loss_AUX: 0.261 loss_D_gr_fake: 0.032 acc_grfake: 0.943 
(epoch: 30, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.046 loss_D_fake: 1.014 loss_D: 1.386 acc_real: 0.998 acc_fake: 0.360 loss_G_conf: 0.457 loss_AUX: 0.261 loss_D_gr_fake: 0.065 acc_grfake: 0.943 
(epoch: 30, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.063 loss_D_fake: 0.652 loss_D: 1.120 acc_real: 0.998 acc_fake: 0.360 loss_G_conf: 0.457 loss_AUX: 0.263 loss_D_gr_fake: 0.142 acc_grfake: 0.943 
validation accuracies:
                gf: 0.95
                real: 1.00
                fake: 0.37

ran validation set (B:7001) in                         51.4 s.
(epoch: 30, batches: 220, time: 0.009, data: 0.006) loss_G_comp: 0.410 loss_G_anti_sc: 0.165 loss_G: 1.033 loss_D_real: 0.029 loss_D_fake: 1.360 loss_D: 1.872 acc_real: 0.997 acc_fake: 0.367 loss_G_conf: 0.457 loss_AUX: 0.260 loss_D_gr_fake: 0.223 acc_grfake: 0.949 
saving the model at the end of epoch 30, iters 449280
learning rate 0.0000800 -> 0.0000800
End of epoch 30 / 30 	 Time Taken: 293 sec
Finished training, model is saved
