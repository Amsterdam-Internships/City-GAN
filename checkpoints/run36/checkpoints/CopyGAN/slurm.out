starting training run 36
----------------- Options ---------------
              D_headstart: 0                             	[default: 80000]
              D_threshold: 0.6                           
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 128                           	[default: 64]
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 130                           	[default: 70]
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: True                          
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: False                         
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 1.0                           
               rotate_img: False                         
             save_by_iter: False                         
          save_epoch_freq: 15                            	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
----------------- Options ---------------
              D_headstart: 0                             	[default: 80000]
              D_threshold: 0.6                           
       accumulation_steps: 1                             	[default: 4]
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 128                           	[default: 64]
                 dataroot: /scratch/datasets/CLEVR_colorized/images	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 130                           	[default: 70]
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 20                            	[default: 1]
           n_epochs_decay: 10                            	[default: 3]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: True                          
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
           nr_obj_classes: 1                             
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: False                         
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 1.0                           
               rotate_img: False                         
             save_by_iter: False                         
          save_epoch_freq: 15                            	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [DoubleDataset] was created
dataset [DoubleDataset] was created
The number of training images = 15000
The number of epochs to run = 30
initialize network with normal
initialize network with normal
model [CopyPasteGANModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.505 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False, padding_mode=replicate)
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (sigmoid): Sigmoid()
    (avg): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=2, padding=0)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=256, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=256, out_features=1, bias=True)
      (5): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 3.637 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 0.00
                real: 1.00
                fake: 0.00

ran validation set (B:1) in                         54.7 s.
(epoch: 1, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.656 loss_D_fake: 0.712 loss_D: 2.290 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.272 loss_D_gr_fake: 0.650 acc_grfake: 0.000 
(epoch: 1, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.496 loss_D_fake: 0.874 loss_D: 2.248 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.271 loss_D_gr_fake: 0.608 acc_grfake: 0.000 
(epoch: 1, batches: 60, time: 0.010, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.377 loss_D_fake: 1.037 loss_D: 2.282 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.270 loss_D_gr_fake: 0.598 acc_grfake: 0.000 
(epoch: 1, batches: 80, time: 0.010, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.533 loss_D_fake: 0.565 loss_D: 1.608 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.269 loss_D_gr_fake: 0.241 acc_grfake: 0.000 
(epoch: 1, batches: 100, time: 0.012, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.294 loss_D_fake: 0.799 loss_D: 1.724 acc_real: 1.000 acc_fake: 0.000 loss_G_conf: 0.000 loss_AUX: 0.269 loss_D_gr_fake: 0.363 acc_grfake: 0.000 
validation accuracies:
                gf: 0.87
                real: 0.97
                fake: 0.30

ran validation set (B:101) in                         51.6 s.
(epoch: 1, batches: 120, time: 0.010, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.396 loss_D_fake: 0.655 loss_D: 1.602 acc_real: 0.969 acc_fake: 0.303 loss_G_conf: 0.000 loss_AUX: 0.268 loss_D_gr_fake: 0.284 acc_grfake: 0.870 
(epoch: 1, batches: 140, time: 0.010, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.148 loss_D_fake: 0.985 loss_D: 1.601 acc_real: 0.969 acc_fake: 0.303 loss_G_conf: 0.000 loss_AUX: 0.267 loss_D_gr_fake: 0.202 acc_grfake: 0.870 
(epoch: 1, batches: 160, time: 0.010, data: 0.006) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.247 loss_D_fake: 0.643 loss_D: 1.345 acc_real: 0.969 acc_fake: 0.303 loss_G_conf: 0.000 loss_AUX: 0.266 loss_D_gr_fake: 0.189 acc_grfake: 0.870 
(epoch: 1, batches: 180, time: 0.010, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.447 loss_D_fake: 0.688 loss_D: 1.715 acc_real: 0.969 acc_fake: 0.303 loss_G_conf: 0.000 loss_AUX: 0.266 loss_D_gr_fake: 0.313 acc_grfake: 0.870 
(epoch: 1, batches: 200, time: 0.012, data: 0.007) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.109 loss_D_fake: 1.119 loss_D: 1.863 acc_real: 0.969 acc_fake: 0.303 loss_G_conf: 0.000 loss_AUX: 0.265 loss_D_gr_fake: 0.370 acc_grfake: 0.870 
validation accuracies:
                gf: 0.92
                real: 0.94
                fake: 0.70

ran validation set (B:201) in                         51.7 s.
(epoch: 1, batches: 220, time: 0.010, data: 0.006) loss_G_comp: 0.728 loss_G_anti_sc: 0.663 loss_G: 1.874 loss_D_real: 0.348 loss_D_fake: 0.831 loss_D: 1.809 acc_real: 0.941 acc_fake: 0.702 loss_G_conf: 0.483 loss_AUX: 0.265 loss_D_gr_fake: 0.365 acc_grfake: 0.917 
learning rate 0.0001000 -> 0.0001000
End of epoch 1 / 30 	 Time Taken: 306 sec
(epoch: 2, batches: 20, time: 0.008, data: 0.007) loss_G_comp: 0.685 loss_G_anti_sc: 0.833 loss_G: 2.000 loss_D_real: 0.202 loss_D_fake: 1.030 loss_D: 1.825 acc_real: 0.941 acc_fake: 0.702 loss_G_conf: 0.482 loss_AUX: 0.264 loss_D_gr_fake: 0.329 acc_grfake: 0.917 
(epoch: 2, batches: 40, time: 0.008, data: 0.006) loss_G_comp: 0.759 loss_G_anti_sc: 0.674 loss_G: 1.913 loss_D_real: 0.177 loss_D_fake: 0.822 loss_D: 1.549 acc_real: 0.941 acc_fake: 0.702 loss_G_conf: 0.480 loss_AUX: 0.264 loss_D_gr_fake: 0.287 acc_grfake: 0.917 
(epoch: 2, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.768 loss_G_anti_sc: 0.634 loss_G: 1.881 loss_D_real: 0.154 loss_D_fake: 1.130 loss_D: 1.874 acc_real: 0.941 acc_fake: 0.702 loss_G_conf: 0.478 loss_AUX: 0.264 loss_D_gr_fake: 0.326 acc_grfake: 0.917 
validation accuracies:
                gf: 0.93
                real: 0.90
                fake: 0.81

ran validation set (B:301) in                         51.9 s.
(epoch: 2, batches: 80, time: 0.008, data: 0.006) loss_G_comp: 0.730 loss_G_anti_sc: 0.641 loss_G: 1.848 loss_D_real: 0.194 loss_D_fake: 0.906 loss_D: 1.620 acc_real: 0.896 acc_fake: 0.806 loss_G_conf: 0.477 loss_AUX: 0.264 loss_D_gr_fake: 0.256 acc_grfake: 0.934 
(epoch: 2, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.724 loss_G_anti_sc: 0.574 loss_G: 1.775 loss_D_real: 0.146 loss_D_fake: 1.021 loss_D: 1.659 acc_real: 0.896 acc_fake: 0.806 loss_G_conf: 0.477 loss_AUX: 0.263 loss_D_gr_fake: 0.229 acc_grfake: 0.934 
(epoch: 2, batches: 120, time: 0.008, data: 0.007) loss_G_comp: 0.536 loss_G_anti_sc: 0.740 loss_G: 1.753 loss_D_real: 0.129 loss_D_fake: 1.325 loss_D: 2.035 acc_real: 0.896 acc_fake: 0.806 loss_G_conf: 0.476 loss_AUX: 0.263 loss_D_gr_fake: 0.319 acc_grfake: 0.934 
(epoch: 2, batches: 140, time: 0.008, data: 0.006) loss_G_comp: 0.648 loss_G_anti_sc: 0.513 loss_G: 1.635 loss_D_real: 0.253 loss_D_fake: 0.803 loss_D: 1.588 acc_real: 0.896 acc_fake: 0.806 loss_G_conf: 0.474 loss_AUX: 0.262 loss_D_gr_fake: 0.270 acc_grfake: 0.934 
(epoch: 2, batches: 160, time: 0.008, data: 0.006) loss_G_comp: 0.711 loss_G_anti_sc: 0.416 loss_G: 1.600 loss_D_real: 0.243 loss_D_fake: 0.848 loss_D: 1.606 acc_real: 0.896 acc_fake: 0.806 loss_G_conf: 0.473 loss_AUX: 0.262 loss_D_gr_fake: 0.253 acc_grfake: 0.934 
validation accuracies:
                gf: 0.93
                real: 0.96
                fake: 0.49

ran validation set (B:401) in                         51.9 s.
(epoch: 2, batches: 180, time: 0.011, data: 0.006) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.102 loss_D_fake: 0.930 loss_D: 1.561 acc_real: 0.963 acc_fake: 0.489 loss_G_conf: 0.473 loss_AUX: 0.262 loss_D_gr_fake: 0.268 acc_grfake: 0.929 
(epoch: 2, batches: 200, time: 0.010, data: 0.007) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.118 loss_D_fake: 1.039 loss_D: 1.696 acc_real: 0.963 acc_fake: 0.489 loss_G_conf: 0.473 loss_AUX: 0.261 loss_D_gr_fake: 0.278 acc_grfake: 0.929 
(epoch: 2, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.097 loss_D_fake: 1.045 loss_D: 1.574 acc_real: 0.963 acc_fake: 0.489 loss_G_conf: 0.473 loss_AUX: 0.260 loss_D_gr_fake: 0.171 acc_grfake: 0.929 
learning rate 0.0001000 -> 0.0001000
End of epoch 2 / 30 	 Time Taken: 243 sec
(epoch: 3, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.103 loss_D_fake: 1.017 loss_D: 1.698 acc_real: 0.963 acc_fake: 0.489 loss_G_conf: 0.473 loss_AUX: 0.260 loss_D_gr_fake: 0.318 acc_grfake: 0.929 
validation accuracies:
                gf: 0.92
                real: 0.98
                fake: 0.41

ran validation set (B:501) in                         51.7 s.
(epoch: 3, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.110 loss_D_fake: 0.819 loss_D: 1.389 acc_real: 0.983 acc_fake: 0.413 loss_G_conf: 0.473 loss_AUX: 0.259 loss_D_gr_fake: 0.201 acc_grfake: 0.921 
(epoch: 3, batches: 60, time: 0.010, data: 0.007) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.099 loss_D_fake: 0.937 loss_D: 1.716 acc_real: 0.983 acc_fake: 0.413 loss_G_conf: 0.473 loss_AUX: 0.259 loss_D_gr_fake: 0.420 acc_grfake: 0.921 
(epoch: 3, batches: 80, time: 0.010, data: 0.006) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.126 loss_D_fake: 0.794 loss_D: 1.271 acc_real: 0.983 acc_fake: 0.413 loss_G_conf: 0.473 loss_AUX: 0.258 loss_D_gr_fake: 0.094 acc_grfake: 0.921 
(epoch: 3, batches: 100, time: 0.010, data: 0.007) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.084 loss_D_fake: 0.898 loss_D: 1.474 acc_real: 0.983 acc_fake: 0.413 loss_G_conf: 0.473 loss_AUX: 0.257 loss_D_gr_fake: 0.235 acc_grfake: 0.921 
(epoch: 3, batches: 120, time: 0.010, data: 0.007) loss_G_comp: 0.714 loss_G_anti_sc: 0.456 loss_G: 1.643 loss_D_real: 0.176 loss_D_fake: 0.490 loss_D: 1.056 acc_real: 0.983 acc_fake: 0.413 loss_G_conf: 0.473 loss_AUX: 0.257 loss_D_gr_fake: 0.133 acc_grfake: 0.921 
validation accuracies:
                gf: 0.92
                real: 0.98
                fake: 0.69

ran validation set (B:601) in                         51.7 s.
(epoch: 3, batches: 140, time: 0.008, data: 0.006) loss_G_comp: 0.736 loss_G_anti_sc: 0.589 loss_G: 1.799 loss_D_real: 0.797 loss_D_fake: 0.303 loss_D: 1.513 acc_real: 0.980 acc_fake: 0.691 loss_G_conf: 0.474 loss_AUX: 0.258 loss_D_gr_fake: 0.155 acc_grfake: 0.923 
(epoch: 3, batches: 160, time: 0.008, data: 0.006) loss_G_comp: 0.552 loss_G_anti_sc: 0.649 loss_G: 1.673 loss_D_real: 0.275 loss_D_fake: 0.856 loss_D: 1.685 acc_real: 0.980 acc_fake: 0.691 loss_G_conf: 0.472 loss_AUX: 0.257 loss_D_gr_fake: 0.297 acc_grfake: 0.923 
(epoch: 3, batches: 180, time: 0.009, data: 0.007) loss_G_comp: 0.316 loss_G_anti_sc: 0.970 loss_G: 1.757 loss_D_real: 0.272 loss_D_fake: 0.773 loss_D: 1.519 acc_real: 0.980 acc_fake: 0.691 loss_G_conf: 0.472 loss_AUX: 0.257 loss_D_gr_fake: 0.217 acc_grfake: 0.923 
(epoch: 3, batches: 200, time: 0.009, data: 0.007) loss_G_comp: 0.522 loss_G_anti_sc: 0.638 loss_G: 1.630 loss_D_real: 0.278 loss_D_fake: 0.734 loss_D: 1.435 acc_real: 0.980 acc_fake: 0.691 loss_G_conf: 0.470 loss_AUX: 0.257 loss_D_gr_fake: 0.167 acc_grfake: 0.923 
(epoch: 3, batches: 220, time: 0.009, data: 0.007) loss_G_comp: 0.677 loss_G_anti_sc: 0.504 loss_G: 1.651 loss_D_real: 0.148 loss_D_fake: 1.002 loss_D: 1.682 acc_real: 0.980 acc_fake: 0.691 loss_G_conf: 0.470 loss_AUX: 0.256 loss_D_gr_fake: 0.276 acc_grfake: 0.923 
validation accuracies:
                gf: 0.93
                real: 0.89
                fake: 0.69

ran validation set (B:701) in                         51.0 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 3 / 30 	 Time Taken: 298 sec
(epoch: 4, batches: 20, time: 0.009, data: 0.006) loss_G_comp: 0.596 loss_G_anti_sc: 0.458 loss_G: 1.521 loss_D_real: 0.084 loss_D_fake: 1.539 loss_D: 2.126 acc_real: 0.892 acc_fake: 0.685 loss_G_conf: 0.468 loss_AUX: 0.256 loss_D_gr_fake: 0.248 acc_grfake: 0.934 
(epoch: 4, batches: 40, time: 0.009, data: 0.007) loss_G_comp: 0.279 loss_G_anti_sc: 0.766 loss_G: 1.513 loss_D_real: 0.211 loss_D_fake: 0.979 loss_D: 1.586 acc_real: 0.892 acc_fake: 0.685 loss_G_conf: 0.468 loss_AUX: 0.255 loss_D_gr_fake: 0.141 acc_grfake: 0.934 
(epoch: 4, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.467 loss_G_anti_sc: 0.600 loss_G: 1.534 loss_D_real: 0.084 loss_D_fake: 1.506 loss_D: 2.032 acc_real: 0.892 acc_fake: 0.685 loss_G_conf: 0.467 loss_AUX: 0.255 loss_D_gr_fake: 0.187 acc_grfake: 0.934 
(epoch: 4, batches: 80, time: 0.009, data: 0.007) loss_G_comp: 0.375 loss_G_anti_sc: 0.446 loss_G: 1.287 loss_D_real: 0.136 loss_D_fake: 1.084 loss_D: 1.683 acc_real: 0.892 acc_fake: 0.685 loss_G_conf: 0.466 loss_AUX: 0.255 loss_D_gr_fake: 0.209 acc_grfake: 0.934 
validation accuracies:
                gf: 0.92
                real: 0.99
                fake: 0.13

ran validation set (B:801) in                         52.0 s.
(epoch: 4, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.095 loss_D_fake: 1.376 loss_D: 1.908 acc_real: 0.992 acc_fake: 0.131 loss_G_conf: 0.465 loss_AUX: 0.254 loss_D_gr_fake: 0.182 acc_grfake: 0.923 
(epoch: 4, batches: 120, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.069 loss_D_fake: 1.462 loss_D: 2.049 acc_real: 0.992 acc_fake: 0.131 loss_G_conf: 0.465 loss_AUX: 0.254 loss_D_gr_fake: 0.264 acc_grfake: 0.923 
(epoch: 4, batches: 140, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.106 loss_D_fake: 1.304 loss_D: 1.869 acc_real: 0.992 acc_fake: 0.131 loss_G_conf: 0.465 loss_AUX: 0.254 loss_D_gr_fake: 0.205 acc_grfake: 0.923 
(epoch: 4, batches: 160, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.074 loss_D_fake: 1.511 loss_D: 2.037 acc_real: 0.992 acc_fake: 0.131 loss_G_conf: 0.465 loss_AUX: 0.254 loss_D_gr_fake: 0.198 acc_grfake: 0.923 
(epoch: 4, batches: 180, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.110 loss_D_fake: 1.153 loss_D: 1.746 acc_real: 0.992 acc_fake: 0.131 loss_G_conf: 0.465 loss_AUX: 0.253 loss_D_gr_fake: 0.230 acc_grfake: 0.923 
validation accuracies:
                gf: 0.92
                real: 0.99
                fake: 0.31

ran validation set (B:901) in                         51.8 s.
(epoch: 4, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.148 loss_D_fake: 1.014 loss_D: 1.563 acc_real: 0.990 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.253 loss_D_gr_fake: 0.148 acc_grfake: 0.920 
(epoch: 4, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.069 loss_D_fake: 1.400 loss_D: 1.975 acc_real: 0.990 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.252 loss_D_gr_fake: 0.254 acc_grfake: 0.920 
learning rate 0.0001000 -> 0.0001000
End of epoch 4 / 30 	 Time Taken: 248 sec
(epoch: 5, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.119 loss_D_fake: 1.080 loss_D: 1.732 acc_real: 0.990 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.252 loss_D_gr_fake: 0.281 acc_grfake: 0.920 
(epoch: 5, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.089 loss_D_fake: 1.173 loss_D: 1.687 acc_real: 0.990 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.251 loss_D_gr_fake: 0.173 acc_grfake: 0.920 
(epoch: 5, batches: 60, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.077 loss_D_fake: 1.232 loss_D: 1.789 acc_real: 0.990 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.251 loss_D_gr_fake: 0.229 acc_grfake: 0.920 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.44

ran validation set (B:1001) in                         51.8 s.
(epoch: 5, batches: 80, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.077 loss_D_fake: 1.103 loss_D: 1.562 acc_real: 0.991 acc_fake: 0.439 loss_G_conf: 0.465 loss_AUX: 0.250 loss_D_gr_fake: 0.132 acc_grfake: 0.938 
(epoch: 5, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.071 loss_D_fake: 1.407 loss_D: 2.005 acc_real: 0.991 acc_fake: 0.439 loss_G_conf: 0.465 loss_AUX: 0.251 loss_D_gr_fake: 0.275 acc_grfake: 0.938 
(epoch: 5, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.074 loss_D_fake: 1.046 loss_D: 1.531 acc_real: 0.991 acc_fake: 0.439 loss_G_conf: 0.465 loss_AUX: 0.250 loss_D_gr_fake: 0.161 acc_grfake: 0.938 
(epoch: 5, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.086 loss_D_fake: 0.997 loss_D: 1.532 acc_real: 0.991 acc_fake: 0.439 loss_G_conf: 0.465 loss_AUX: 0.250 loss_D_gr_fake: 0.199 acc_grfake: 0.938 
(epoch: 5, batches: 160, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.053 loss_D_fake: 1.233 loss_D: 1.727 acc_real: 0.991 acc_fake: 0.439 loss_G_conf: 0.465 loss_AUX: 0.249 loss_D_gr_fake: 0.191 acc_grfake: 0.938 
validation accuracies:
                gf: 0.92
                real: 0.99
                fake: 0.31

ran validation set (B:1101) in                         51.7 s.
(epoch: 5, batches: 180, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.128 loss_D_fake: 0.803 loss_D: 1.261 acc_real: 0.995 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.250 loss_D_gr_fake: 0.079 acc_grfake: 0.920 
(epoch: 5, batches: 200, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.172 loss_D_fake: 0.711 loss_D: 1.181 acc_real: 0.995 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.249 loss_D_gr_fake: 0.049 acc_grfake: 0.920 
(epoch: 5, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.084 loss_D_fake: 0.966 loss_D: 1.367 acc_real: 0.995 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.249 loss_D_gr_fake: 0.068 acc_grfake: 0.920 
learning rate 0.0001000 -> 0.0001000
End of epoch 5 / 30 	 Time Taken: 249 sec
(epoch: 6, batches: 20, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.077 loss_D_fake: 1.081 loss_D: 1.481 acc_real: 0.995 acc_fake: 0.305 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.075 acc_grfake: 0.920 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.32

ran validation set (B:1201) in                         51.7 s.
(epoch: 6, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.082 loss_D_fake: 0.898 loss_D: 1.513 acc_real: 0.998 acc_fake: 0.324 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.284 acc_grfake: 0.934 
(epoch: 6, batches: 60, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.089 loss_D_fake: 1.017 loss_D: 1.515 acc_real: 0.998 acc_fake: 0.324 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.160 acc_grfake: 0.934 
(epoch: 6, batches: 80, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.037 loss_D_fake: 1.410 loss_D: 2.133 acc_real: 0.998 acc_fake: 0.324 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.439 acc_grfake: 0.934 
(epoch: 6, batches: 100, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.081 loss_D_fake: 1.041 loss_D: 1.574 acc_real: 0.998 acc_fake: 0.324 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.204 acc_grfake: 0.934 
(epoch: 6, batches: 120, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.057 loss_D_fake: 1.084 loss_D: 1.774 acc_real: 0.998 acc_fake: 0.324 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.385 acc_grfake: 0.934 
validation accuracies:
                gf: 0.94
                real: 0.99
                fake: 0.48

ran validation set (B:1301) in                         51.7 s.
(epoch: 6, batches: 140, time: 0.009, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.048 loss_D_fake: 1.155 loss_D: 1.644 acc_real: 0.988 acc_fake: 0.479 loss_G_conf: 0.465 loss_AUX: 0.248 loss_D_gr_fake: 0.193 acc_grfake: 0.938 
(epoch: 6, batches: 160, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.185 loss_D_fake: 0.615 loss_D: 1.199 acc_real: 0.988 acc_fake: 0.479 loss_G_conf: 0.465 loss_AUX: 0.247 loss_D_gr_fake: 0.152 acc_grfake: 0.938 
(epoch: 6, batches: 180, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.051 loss_D_fake: 1.176 loss_D: 1.677 acc_real: 0.988 acc_fake: 0.479 loss_G_conf: 0.465 loss_AUX: 0.246 loss_D_gr_fake: 0.203 acc_grfake: 0.938 
(epoch: 6, batches: 200, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.130 loss_D_fake: 0.689 loss_D: 1.259 acc_real: 0.988 acc_fake: 0.479 loss_G_conf: 0.465 loss_AUX: 0.246 loss_D_gr_fake: 0.194 acc_grfake: 0.938 
(epoch: 6, batches: 220, time: 0.010, data: 0.008) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.038 loss_D_fake: 1.003 loss_D: 1.490 acc_real: 0.988 acc_fake: 0.479 loss_G_conf: 0.465 loss_AUX: 0.246 loss_D_gr_fake: 0.204 acc_grfake: 0.938 
validation accuracies:
                gf: 0.93
                real: 1.00
                fake: 0.31

ran validation set (B:1401) in                         50.8 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 6 / 30 	 Time Taken: 298 sec
(epoch: 7, batches: 20, time: 0.010, data: 0.009) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.108 loss_D_fake: 0.657 loss_D: 1.272 acc_real: 0.998 acc_fake: 0.306 loss_G_conf: 0.465 loss_AUX: 0.245 loss_D_gr_fake: 0.261 acc_grfake: 0.930 
(epoch: 7, batches: 40, time: 0.010, data: 0.006) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.046 loss_D_fake: 1.130 loss_D: 1.576 acc_real: 0.998 acc_fake: 0.306 loss_G_conf: 0.465 loss_AUX: 0.246 loss_D_gr_fake: 0.154 acc_grfake: 0.930 
(epoch: 7, batches: 60, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.339 loss_D_fake: 0.393 loss_D: 1.080 acc_real: 0.998 acc_fake: 0.306 loss_G_conf: 0.465 loss_AUX: 0.244 loss_D_gr_fake: 0.103 acc_grfake: 0.930 
(epoch: 7, batches: 80, time: 0.010, data: 0.007) loss_G_comp: 0.423 loss_G_anti_sc: 0.561 loss_G: 1.449 loss_D_real: 0.102 loss_D_fake: 1.027 loss_D: 1.532 acc_real: 0.998 acc_fake: 0.306 loss_G_conf: 0.465 loss_AUX: 0.246 loss_D_gr_fake: 0.158 acc_grfake: 0.930 
validation accuracies:
                gf: 0.95
                real: 0.97
                fake: 0.72

ran validation set (B:1501) in                         51.6 s.
(epoch: 7, batches: 100, time: 0.008, data: 0.006) loss_G_comp: 0.266 loss_G_anti_sc: 1.235 loss_G: 1.968 loss_D_real: 0.103 loss_D_fake: 0.801 loss_D: 1.264 acc_real: 0.973 acc_fake: 0.721 loss_G_conf: 0.466 loss_AUX: 0.244 loss_D_gr_fake: 0.116 acc_grfake: 0.948 
(epoch: 7, batches: 120, time: 0.008, data: 0.006) loss_G_comp: 0.882 loss_G_anti_sc: 0.360 loss_G: 1.706 loss_D_real: 0.239 loss_D_fake: 0.880 loss_D: 1.915 acc_real: 0.973 acc_fake: 0.721 loss_G_conf: 0.464 loss_AUX: 0.248 loss_D_gr_fake: 0.549 acc_grfake: 0.948 
(epoch: 7, batches: 140, time: 0.008, data: 0.007) loss_G_comp: 0.536 loss_G_anti_sc: 0.400 loss_G: 1.400 loss_D_real: 0.085 loss_D_fake: 1.599 loss_D: 2.390 acc_real: 0.973 acc_fake: 0.721 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.460 acc_grfake: 0.948 
(epoch: 7, batches: 160, time: 0.008, data: 0.007) loss_G_comp: 0.233 loss_G_anti_sc: 0.678 loss_G: 1.374 loss_D_real: 0.182 loss_D_fake: 0.982 loss_D: 1.591 acc_real: 0.973 acc_fake: 0.721 loss_G_conf: 0.463 loss_AUX: 0.246 loss_D_gr_fake: 0.181 acc_grfake: 0.948 
(epoch: 7, batches: 180, time: 0.008, data: 0.006) loss_G_comp: 0.332 loss_G_anti_sc: 0.584 loss_G: 1.379 loss_D_real: 0.158 loss_D_fake: 0.990 loss_D: 1.556 acc_real: 0.973 acc_fake: 0.721 loss_G_conf: 0.462 loss_AUX: 0.245 loss_D_gr_fake: 0.163 acc_grfake: 0.948 
validation accuracies:
                gf: 0.91
                real: 0.99
                fake: 0.16

ran validation set (B:1601) in                         52.1 s.
(epoch: 7, batches: 200, time: 0.009, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.068 loss_D_fake: 2.029 loss_D: 2.772 acc_real: 0.990 acc_fake: 0.156 loss_G_conf: 0.462 loss_AUX: 0.246 loss_D_gr_fake: 0.429 acc_grfake: 0.915 
(epoch: 7, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.139 loss_D_fake: 1.398 loss_D: 1.954 acc_real: 0.990 acc_fake: 0.156 loss_G_conf: 0.462 loss_AUX: 0.245 loss_D_gr_fake: 0.172 acc_grfake: 0.915 
learning rate 0.0001000 -> 0.0001000
End of epoch 7 / 30 	 Time Taken: 244 sec
(epoch: 8, batches: 20, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.080 loss_D_fake: 1.419 loss_D: 2.010 acc_real: 0.990 acc_fake: 0.156 loss_G_conf: 0.462 loss_AUX: 0.245 loss_D_gr_fake: 0.266 acc_grfake: 0.915 
(epoch: 8, batches: 40, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.053 loss_D_fake: 1.385 loss_D: 1.867 acc_real: 0.990 acc_fake: 0.156 loss_G_conf: 0.462 loss_AUX: 0.245 loss_D_gr_fake: 0.184 acc_grfake: 0.915 
(epoch: 8, batches: 60, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.057 loss_D_fake: 1.334 loss_D: 1.957 acc_real: 0.990 acc_fake: 0.156 loss_G_conf: 0.462 loss_AUX: 0.245 loss_D_gr_fake: 0.322 acc_grfake: 0.915 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.31

ran validation set (B:1701) in                         51.6 s.
(epoch: 8, batches: 80, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.117 loss_D_fake: 1.065 loss_D: 1.575 acc_real: 0.993 acc_fake: 0.309 loss_G_conf: 0.462 loss_AUX: 0.244 loss_D_gr_fake: 0.150 acc_grfake: 0.931 
(epoch: 8, batches: 100, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.066 loss_D_fake: 1.241 loss_D: 1.786 acc_real: 0.993 acc_fake: 0.309 loss_G_conf: 0.462 loss_AUX: 0.245 loss_D_gr_fake: 0.233 acc_grfake: 0.931 
(epoch: 8, batches: 120, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.090 loss_D_fake: 1.006 loss_D: 1.681 acc_real: 0.993 acc_fake: 0.309 loss_G_conf: 0.462 loss_AUX: 0.244 loss_D_gr_fake: 0.341 acc_grfake: 0.931 
(epoch: 8, batches: 140, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.066 loss_D_fake: 1.102 loss_D: 1.586 acc_real: 0.993 acc_fake: 0.309 loss_G_conf: 0.462 loss_AUX: 0.244 loss_D_gr_fake: 0.174 acc_grfake: 0.931 
(epoch: 8, batches: 160, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.077 loss_D_fake: 0.874 loss_D: 1.419 acc_real: 0.993 acc_fake: 0.309 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.225 acc_grfake: 0.931 
validation accuracies:
                gf: 0.94
                real: 0.98
                fake: 0.59

ran validation set (B:1801) in                         51.8 s.
(epoch: 8, batches: 180, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.080 loss_D_fake: 0.905 loss_D: 1.304 acc_real: 0.978 acc_fake: 0.586 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.075 acc_grfake: 0.940 
(epoch: 8, batches: 200, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.042 loss_D_fake: 1.312 loss_D: 1.858 acc_real: 0.978 acc_fake: 0.586 loss_G_conf: 0.462 loss_AUX: 0.244 loss_D_gr_fake: 0.261 acc_grfake: 0.940 
(epoch: 8, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.069 loss_D_fake: 1.091 loss_D: 1.646 acc_real: 0.978 acc_fake: 0.586 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.243 acc_grfake: 0.940 
learning rate 0.0001000 -> 0.0001000
End of epoch 8 / 30 	 Time Taken: 250 sec
(epoch: 9, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.110 loss_D_fake: 1.090 loss_D: 1.565 acc_real: 0.978 acc_fake: 0.586 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.122 acc_grfake: 0.940 
validation accuracies:
                gf: 0.94
                real: 1.00
                fake: 0.34

ran validation set (B:1901) in                         51.5 s.
(epoch: 9, batches: 40, time: 0.009, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.085 loss_D_fake: 1.100 loss_D: 1.584 acc_real: 0.995 acc_fake: 0.345 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.156 acc_grfake: 0.936 
(epoch: 9, batches: 60, time: 0.011, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.070 loss_D_fake: 0.863 loss_D: 1.384 acc_real: 0.995 acc_fake: 0.345 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.208 acc_grfake: 0.936 
(epoch: 9, batches: 80, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.067 loss_D_fake: 0.861 loss_D: 1.345 acc_real: 0.995 acc_fake: 0.345 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.175 acc_grfake: 0.936 
(epoch: 9, batches: 100, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.071 loss_D_fake: 1.017 loss_D: 1.646 acc_real: 0.995 acc_fake: 0.345 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.314 acc_grfake: 0.936 
(epoch: 9, batches: 120, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.092 loss_D_fake: 0.757 loss_D: 1.229 acc_real: 0.995 acc_fake: 0.345 loss_G_conf: 0.462 loss_AUX: 0.244 loss_D_gr_fake: 0.136 acc_grfake: 0.936 
validation accuracies:
                gf: 0.95
                real: 0.99
                fake: 0.50

ran validation set (B:2001) in                         51.8 s.
(epoch: 9, batches: 140, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.091 loss_D_fake: 0.882 loss_D: 1.378 acc_real: 0.994 acc_fake: 0.497 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.163 acc_grfake: 0.946 
(epoch: 9, batches: 160, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.046 loss_D_fake: 0.772 loss_D: 1.171 acc_real: 0.994 acc_fake: 0.497 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.111 acc_grfake: 0.946 
(epoch: 9, batches: 180, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.061 loss_D_fake: 0.870 loss_D: 1.416 acc_real: 0.994 acc_fake: 0.497 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.242 acc_grfake: 0.946 
(epoch: 9, batches: 200, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.043 loss_D_fake: 1.222 loss_D: 1.575 acc_real: 0.994 acc_fake: 0.497 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.067 acc_grfake: 0.946 
(epoch: 9, batches: 220, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.039 loss_D_fake: 1.374 loss_D: 1.927 acc_real: 0.994 acc_fake: 0.497 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.271 acc_grfake: 0.946 
validation accuracies:
                gf: 0.92
                real: 0.99
                fake: 0.39

ran validation set (B:2101) in                         50.8 s.
learning rate 0.0001000 -> 0.0001000
End of epoch 9 / 30 	 Time Taken: 302 sec
(epoch: 10, batches: 20, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.044 loss_D_fake: 0.929 loss_D: 1.283 acc_real: 0.990 acc_fake: 0.392 loss_G_conf: 0.462 loss_AUX: 0.241 loss_D_gr_fake: 0.068 acc_grfake: 0.919 
(epoch: 10, batches: 40, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.107 loss_D_fake: 0.535 loss_D: 1.074 acc_real: 0.990 acc_fake: 0.392 loss_G_conf: 0.462 loss_AUX: 0.242 loss_D_gr_fake: 0.190 acc_grfake: 0.919 
(epoch: 10, batches: 60, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.100 loss_D_fake: 0.713 loss_D: 1.286 acc_real: 0.990 acc_fake: 0.392 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.230 acc_grfake: 0.919 
(epoch: 10, batches: 80, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.124 loss_D_fake: 0.742 loss_D: 1.160 acc_real: 0.990 acc_fake: 0.392 loss_G_conf: 0.462 loss_AUX: 0.244 loss_D_gr_fake: 0.051 acc_grfake: 0.919 
validation accuracies:
                gf: 0.93
                real: 0.99
                fake: 0.48

ran validation set (B:2201) in                         51.8 s.
(epoch: 10, batches: 100, time: 0.009, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.032 loss_D_fake: 1.063 loss_D: 1.702 acc_real: 0.989 acc_fake: 0.485 loss_G_conf: 0.462 loss_AUX: 0.243 loss_D_gr_fake: 0.365 acc_grfake: 0.935 
(epoch: 10, batches: 120, time: 0.010, data: 0.007) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.037 loss_D_fake: 1.151 loss_D: 1.677 acc_real: 0.989 acc_fake: 0.485 loss_G_conf: 0.462 loss_AUX: 0.242 loss_D_gr_fake: 0.247 acc_grfake: 0.935 
(epoch: 10, batches: 140, time: 0.010, data: 0.006) loss_G_comp: 0.478 loss_G_anti_sc: 0.371 loss_G: 1.311 loss_D_real: 0.035 loss_D_fake: 1.273 loss_D: 1.741 acc_real: 0.989 acc_fake: 0.485 loss_G_conf: 0.462 loss_AUX: 0.242 loss_D_gr_fake: 0.192 acc_grfake: 0.935 
Traceback (most recent call last):
  File "/home/tlotze/City-GAN/train.py", line 97, in <module>
    model.run_batch(data, total_iters)
  File "/home/tlotze/City-GAN/models/copypasteGAN_model.py", line 419, in run_batch
    self.optimize_parameters()
  File "/home/tlotze/City-GAN/models/copypasteGAN_model.py", line 361, in optimize_parameters
    self.forward()
  File "/home/tlotze/City-GAN/models/copypasteGAN_model.py", line 268, in forward
    self.pred_fake, self.D_mask_fake = self.netD(self.composite)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 159, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/tlotze/City-GAN/models/networks.py", line 674, in forward
    dec1 = self.dec1(torch.cat([enc1, dec2], 1))
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/tlotze/City-GAN/models/networks.py", line 766, in forward
    return self.model(input)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/modules/upsampling.py", line 141, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
  File "/home/tlotze/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 3151, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 10.92 GiB total capacity; 9.07 GiB already allocated; 273.44 MiB free; 9.96 GiB reserved in total by PyTorch)
