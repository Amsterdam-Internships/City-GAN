starting training and testing run 1
replace /scratch/datasets/Cityscapes/README? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL
(EOF or read error, treating as "[N]one" ...)
gtFine
leftImg8bit
license.txt
README
src_imgs
Seed: 1
----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 32                            	[default: 64]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints/         	[default: ./checkpoints]
        confidence_weight: 0.0                           
           continue_train: False                         
                crop_size: 256                           	[default: 64]
                 dataroot: /scratch/datasets/Cityscapes  	[default: datasets]
             dataset_mode: cityscapes                    	[default: double]
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
              fake_target: 0.1                           
            flip_vertical: False                         
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.0                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
          min_obj_surface: 100                           
                    model: copy                          
    n_alternating_batches: 20                            	[default: 1]
                 n_epochs: 5                             	[default: 20]
           n_epochs_decay: 0                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
             noisy_labels: True                          	[default: False]
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
              pred_type_D: baseline                      	[default: pool]
               preprocess: resize_and_crop               
               print_freq: 100                           	[default: 20]
              real_target: 0.9                           
                      run: -1                            
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
                     seed: 1                             	[default: 0]
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
                  use_amp: True                          
           val_batch_size: 64                            	[default: 512]
                 val_freq: 20                            	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [CityscapesDataset] and dataloder are created
dataset [CityscapesDataset] and dataloder are created
The number of validation images = 500
Starting training of copy-model
The number of training images = 2975
The number of epochs to run = 5
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [CopyModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.634 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): GaussianSmoothing()
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential()
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (sigmoid): Sigmoid()
    (pred_layers): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=1, bias=True)
      (3): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 1.606 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 1.00,0.49
                real: 0.00, 0.49
                fake: 1.00, 0.49

ran validation set (B:1) in                         72.0 s.
validation accuracies:
                gf: 1.00,0.49
                real: 0.00, 0.49
                fake: 0.50, 0.50

ran validation set (B:21) in                         77.1 s.
validation accuracies:
                gf: 0.19,0.52
                real: 0.97, 0.54
                fake: 0.80, 0.48

ran validation set (B:41) in                         75.6 s.
validation accuracies:
                gf: 1.00,0.48
                real: 0.00, 0.48
                fake: 1.00, 0.48

ran validation set (B:61) in                         72.8 s.
validation accuracies:
                gf: 0.48,0.51
                real: 0.72, 0.52
                fake: 0.84, 0.48

ran validation set (B:81) in                         70.8 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 5 	 Time Taken: 622 sec
validation accuracies:
                gf: 0.94,0.47
                real: 0.09, 0.47
                fake: 1.00, 0.47

ran validation set (B:101) in                         53.0 s.
validation accuracies:
                gf: 1.00,0.37
                real: 0.00, 0.38
                fake: 1.00, 0.37

ran validation set (B:121) in                         76.0 s.
validation accuracies:
                gf: 1.00,0.43
                real: 0.00, 0.44
                fake: 1.00, 0.44

ran validation set (B:141) in                         68.5 s.
validation accuracies:
                gf: 0.75,0.48
                real: 0.36, 0.49
                fake: 0.91, 0.46

ran validation set (B:161) in                         62.8 s.
validation accuracies:
                gf: 0.84,0.48
                real: 0.27, 0.49
                fake: 0.91, 0.48

ran validation set (B:181) in                         54.3 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 5 	 Time Taken: 591 sec
validation accuracies:
                gf: 1.00,0.40
                real: 0.00, 0.40
                fake: 1.00, 0.40

ran validation set (B:201) in                         59.9 s.
validation accuracies:
                gf: 1.00,0.45
                real: 0.03, 0.46
                fake: 1.00, 0.46

ran validation set (B:221) in                         68.5 s.
validation accuracies:
                gf: 0.30,0.51
                real: 0.73, 0.52
                fake: 0.44, 0.50

ran validation set (B:241) in                         70.5 s.
validation accuracies:
                gf: 1.00,0.40
                real: 0.00, 0.40
                fake: 1.00, 0.38

ran validation set (B:261) in                         67.7 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 5 	 Time Taken: 544 sec
validation accuracies:
                gf: 0.69,0.48
                real: 0.55, 0.50
                fake: 0.88, 0.44

ran validation set (B:281) in                         58.4 s.
validation accuracies:
                gf: 1.00,0.44
                real: 0.00, 0.44
                fake: 1.00, 0.45

ran validation set (B:301) in                         72.7 s.
validation accuracies:
                gf: 0.56,0.49
                real: 0.55, 0.50
                fake: 0.86, 0.47

ran validation set (B:321) in                         74.4 s.
validation accuracies:
                gf: 0.94,0.47
                real: 0.19, 0.48
                fake: 0.86, 0.48

ran validation set (B:341) in                         69.4 s.
validation accuracies:
                gf: 1.00,0.40
                real: 0.00, 0.41
                fake: 1.00, 0.40

ran validation set (B:361) in                         71.4 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 5 	 Time Taken: 609 sec
validation accuracies:
                gf: 1.00,0.43
                real: 0.00, 0.43
                fake: 1.00, 0.44

ran validation set (B:381) in                         61.3 s.
validation accuracies:
                gf: 0.58,0.50
                real: 0.47, 0.50
                fake: 0.80, 0.48

ran validation set (B:401) in                         78.5 s.
validation accuracies:
                gf: 1.00,0.48
                real: 0.03, 0.48
                fake: 0.98, 0.48

ran validation set (B:421) in                         67.7 s.
validation accuracies:
                gf: 0.72,0.49
                real: 0.28, 0.50
                fake: 0.95, 0.49

ran validation set (B:441) in                         79.7 s.
learning rate 0.0002000 -> 0.0001600
End of epoch 5 / 5 	 Time Taken: 567 sec
Finished training, model is saved (5 epochs in 2943.823529481888s)
Batches trained - G: 219, D: 241 
Seed: 10
----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 32                            	[default: 64]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints/         	[default: ./checkpoints]
        confidence_weight: 0.0                           
           continue_train: False                         
                crop_size: 256                           	[default: 64]
                 dataroot: /scratch/datasets/Cityscapes  	[default: datasets]
             dataset_mode: cityscapes                    	[default: double]
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
              fake_target: 0.1                           
            flip_vertical: False                         
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.0                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
          min_obj_surface: 100                           
                    model: copy                          
    n_alternating_batches: 20                            	[default: 1]
                 n_epochs: 5                             	[default: 20]
           n_epochs_decay: 0                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
             noisy_labels: True                          	[default: False]
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
              pred_type_D: baseline                      	[default: pool]
               preprocess: resize_and_crop               
               print_freq: 100                           	[default: 20]
              real_target: 0.9                           
                      run: -1                            
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
                     seed: 10                            	[default: 0]
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
                  use_amp: True                          
           val_batch_size: 64                            	[default: 512]
                 val_freq: 20                            	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [CityscapesDataset] and dataloder are created
dataset [CityscapesDataset] and dataloder are created
The number of validation images = 500
Starting training of copy-model
The number of training images = 2975
The number of epochs to run = 5
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [CopyModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.634 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): GaussianSmoothing()
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential()
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (sigmoid): Sigmoid()
    (pred_layers): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=1, bias=True)
      (3): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 1.606 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 1.00,0.46
                real: 0.00, 0.46
                fake: 1.00, 0.46

ran validation set (B:1) in                         62.5 s.
validation accuracies:
                gf: 1.00,0.46
                real: 0.00, 0.46
                fake: 1.00, 0.47

ran validation set (B:21) in                         74.5 s.
validation accuracies:
                gf: 0.12,0.53
                real: 0.97, 0.55
                fake: 0.75, 0.49

ran validation set (B:41) in                         77.3 s.
validation accuracies:
                gf: 1.00,0.47
                real: 0.00, 0.47
                fake: 1.00, 0.47

ran validation set (B:61) in                         68.7 s.
validation accuracies:
                gf: 0.56,0.50
                real: 0.61, 0.51
                fake: 0.78, 0.49

ran validation set (B:81) in                         64.0 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 5 	 Time Taken: 596 sec
validation accuracies:
                gf: 0.94,0.48
                real: 0.22, 0.49
                fake: 0.97, 0.48

ran validation set (B:101) in                         54.0 s.
validation accuracies:
                gf: 1.00,0.38
                real: 0.00, 0.39
                fake: 1.00, 0.38

ran validation set (B:121) in                         64.5 s.
validation accuracies:
                gf: 1.00,0.43
                real: 0.00, 0.44
                fake: 1.00, 0.44

ran validation set (B:141) in                         75.1 s.
validation accuracies:
                gf: 0.44,0.50
                real: 0.66, 0.51
                fake: 0.89, 0.47

ran validation set (B:161) in                         78.5 s.
validation accuracies:
                gf: 1.00,0.44
                real: 0.00, 0.43
                fake: 1.00, 0.45

ran validation set (B:181) in                         58.8 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 5 	 Time Taken: 603 sec
validation accuracies:
                gf: 0.50,0.50
                real: 0.55, 0.51
                fake: 0.91, 0.46

ran validation set (B:201) in                         63.0 s.
validation accuracies:
                gf: 1.00,0.43
                real: 0.00, 0.43
                fake: 1.00, 0.45

ran validation set (B:221) in                         70.4 s.
validation accuracies:
                gf: 0.80,0.49
                real: 0.36, 0.50
                fake: 1.00, 0.48

ran validation set (B:241) in                         60.0 s.
validation accuracies:
                gf: 0.97,0.49
                real: 0.03, 0.49
                fake: 0.84, 0.49

ran validation set (B:261) in                         73.7 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 5 	 Time Taken: 564 sec
validation accuracies:
                gf: 1.00,0.40
                real: 0.00, 0.39
                fake: 1.00, 0.40

ran validation set (B:281) in                         66.7 s.
validation accuracies:
                gf: 1.00,0.43
                real: 0.00, 0.43
                fake: 1.00, 0.45

ran validation set (B:301) in                         77.1 s.
validation accuracies:
                gf: 0.23,0.52
                real: 0.83, 0.53
                fake: 0.44, 0.50

ran validation set (B:321) in                         67.0 s.
validation accuracies:
                gf: 0.98,0.41
                real: 0.11, 0.43
                fake: 1.00, 0.37

ran validation set (B:341) in                         64.5 s.
validation accuracies:
                gf: 1.00,0.36
                real: 0.03, 0.41
                fake: 1.00, 0.35

ran validation set (B:361) in                         64.0 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 5 	 Time Taken: 616 sec
validation accuracies:
                gf: 1.00,0.39
                real: 0.00, 0.39
                fake: 1.00, 0.40

ran validation set (B:381) in                         68.4 s.
validation accuracies:
                gf: 0.64,0.49
                real: 0.55, 0.50
                fake: 0.94, 0.47

ran validation set (B:401) in                         58.5 s.
validation accuracies:
                gf: 0.86,0.48
                real: 0.09, 0.48
                fake: 0.88, 0.47

ran validation set (B:421) in                         55.6 s.
validation accuracies:
                gf: 1.00,0.41
                real: 0.05, 0.44
                fake: 1.00, 0.41

ran validation set (B:441) in                         67.1 s.
learning rate 0.0002000 -> 0.0001600
End of epoch 5 / 5 	 Time Taken: 541 sec
Finished training, model is saved (5 epochs in 2929.3156237602234s)
Batches trained - G: 220, D: 240 
Seed: 20
----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 32                            	[default: 64]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints/         	[default: ./checkpoints]
        confidence_weight: 0.0                           
           continue_train: False                         
                crop_size: 256                           	[default: 64]
                 dataroot: /scratch/datasets/Cityscapes  	[default: datasets]
             dataset_mode: cityscapes                    	[default: double]
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
              fake_target: 0.1                           
            flip_vertical: False                         
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.0                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
          min_obj_surface: 100                           
                    model: copy                          
    n_alternating_batches: 20                            	[default: 1]
                 n_epochs: 5                             	[default: 20]
           n_epochs_decay: 0                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
             noisy_labels: True                          	[default: False]
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
              pred_type_D: baseline                      	[default: pool]
               preprocess: resize_and_crop               
               print_freq: 100                           	[default: 20]
              real_target: 0.9                           
                      run: -1                            
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
                     seed: 20                            	[default: 0]
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
                  use_amp: True                          
           val_batch_size: 64                            	[default: 512]
                 val_freq: 20                            	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [CityscapesDataset] and dataloder are created
dataset [CityscapesDataset] and dataloder are created
The number of validation images = 500
Starting training of copy-model
The number of training images = 2975
The number of epochs to run = 5
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [CopyModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.634 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): GaussianSmoothing()
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential()
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (sigmoid): Sigmoid()
    (pred_layers): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=1, bias=True)
      (3): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 1.606 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 1.00,0.47
                real: 0.00, 0.47
                fake: 1.00, 0.47

ran validation set (B:1) in                         73.2 s.
validation accuracies:
                gf: 1.00,0.47
                real: 0.00, 0.47
                fake: 1.00, 0.48

ran validation set (B:21) in                         77.0 s.
validation accuracies:
                gf: 0.11,0.53
                real: 0.97, 0.55
                fake: 0.52, 0.50

ran validation set (B:41) in                         72.2 s.
validation accuracies:
                gf: 0.69,0.49
                real: 0.48, 0.50
                fake: 0.56, 0.50

ran validation set (B:61) in                         65.8 s.
validation accuracies:
                gf: 1.00,0.39
                real: 0.00, 0.41
                fake: 1.00, 0.39

ran validation set (B:81) in                         69.2 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 5 	 Time Taken: 626 sec
validation accuracies:
                gf: 1.00,0.42
                real: 0.00, 0.43
                fake: 1.00, 0.42

ran validation set (B:101) in                         65.2 s.
validation accuracies:
                gf: 0.47,0.50
                real: 0.67, 0.52
                fake: 0.84, 0.47

ran validation set (B:121) in                         75.1 s.
validation accuracies:
                gf: 0.88,0.48
                real: 0.17, 0.48
                fake: 0.86, 0.48

ran validation set (B:141) in                         69.7 s.
validation accuracies:
                gf: 1.00,0.39
                real: 0.00, 0.39
                fake: 1.00, 0.39

ran validation set (B:161) in                         75.9 s.
validation accuracies:
                gf: 1.00,0.43
                real: 0.00, 0.44
                fake: 1.00, 0.44

ran validation set (B:181) in                         44.9 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 5 	 Time Taken: 614 sec
validation accuracies:
                gf: 0.56,0.50
                real: 0.62, 0.51
                fake: 0.50, 0.50

ran validation set (B:201) in                         70.5 s.
validation accuracies:
                gf: 1.00,0.41
                real: 0.00, 0.41
                fake: 1.00, 0.39

ran validation set (B:221) in                         73.0 s.
validation accuracies:
                gf: 0.61,0.49
                real: 0.59, 0.50
                fake: 0.97, 0.44

ran validation set (B:241) in                         78.2 s.
validation accuracies:
                gf: 0.95,0.47
                real: 0.06, 0.47
                fake: 0.61, 0.50

ran validation set (B:261) in                         63.8 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 5 	 Time Taken: 576 sec
validation accuracies:
                gf: 1.00,0.37
                real: 0.03, 0.41
                fake: 1.00, 0.37

ran validation set (B:281) in                         77.4 s.
validation accuracies:
                gf: 0.97,0.42
                real: 0.16, 0.45
                fake: 0.92, 0.45

ran validation set (B:301) in                         67.8 s.
validation accuracies:
                gf: 0.98,0.39
                real: 0.02, 0.42
                fake: 0.98, 0.39

ran validation set (B:321) in                         58.2 s.
validation accuracies:
                gf: 0.97,0.42
                real: 0.02, 0.40
                fake: 0.91, 0.44

ran validation set (B:341) in                         56.3 s.
validation accuracies:
                gf: 1.00,0.40
                real: 0.05, 0.43
                fake: 1.00, 0.38

ran validation set (B:361) in                         49.1 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 5 	 Time Taken: 589 sec
validation accuracies:
                gf: 1.00,0.41
                real: 0.00, 0.41
                fake: 1.00, 0.42

ran validation set (B:381) in                         69.5 s.
validation accuracies:
                gf: 0.67,0.49
                real: 0.39, 0.50
                fake: 0.91, 0.46

ran validation set (B:401) in                         70.5 s.
validation accuracies:
                gf: 0.95,0.46
                real: 0.00, 0.44
                fake: 0.88, 0.47

ran validation set (B:421) in                         75.6 s.
validation accuracies:
                gf: 1.00,0.39
                real: 0.00, 0.41
                fake: 1.00, 0.36

ran validation set (B:441) in                         70.6 s.
learning rate 0.0002000 -> 0.0001600
End of epoch 5 / 5 	 Time Taken: 567 sec
Finished training, model is saved (5 epochs in 2980.530135154724s)
Batches trained - G: 220, D: 240 
Seed: 30
----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 32                            	[default: 64]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints/         	[default: ./checkpoints]
        confidence_weight: 0.0                           
           continue_train: False                         
                crop_size: 256                           	[default: 64]
                 dataroot: /scratch/datasets/Cityscapes  	[default: datasets]
             dataset_mode: cityscapes                    	[default: double]
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
              fake_target: 0.1                           
            flip_vertical: False                         
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.0                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
          min_obj_surface: 100                           
                    model: copy                          
    n_alternating_batches: 20                            	[default: 1]
                 n_epochs: 5                             	[default: 20]
           n_epochs_decay: 0                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
             noisy_labels: True                          	[default: False]
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
              pred_type_D: baseline                      	[default: pool]
               preprocess: resize_and_crop               
               print_freq: 100                           	[default: 20]
              real_target: 0.9                           
                      run: -1                            
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
                     seed: 30                            	[default: 0]
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
                  use_amp: True                          
           val_batch_size: 64                            	[default: 512]
                 val_freq: 20                            	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [CityscapesDataset] and dataloder are created
dataset [CityscapesDataset] and dataloder are created
The number of validation images = 500
Starting training of copy-model
The number of training images = 2975
The number of epochs to run = 5
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [CopyModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.634 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): GaussianSmoothing()
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential()
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (sigmoid): Sigmoid()
    (pred_layers): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=1, bias=True)
      (3): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 1.606 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 0.00,0.55
                real: 1.00, 0.55
                fake: 0.00, 0.55

ran validation set (B:1) in                         62.2 s.
validation accuracies:
                gf: 1.00,0.42
                real: 0.00, 0.44
                fake: 1.00, 0.37

ran validation set (B:21) in                         61.8 s.
validation accuracies:
                gf: 0.27,0.53
                real: 0.86, 0.56
                fake: 0.84, 0.41

ran validation set (B:41) in                         77.4 s.
validation accuracies:
                gf: 0.41,0.51
                real: 0.89, 0.53
                fake: 0.59, 0.49

ran validation set (B:61) in                         69.4 s.
validation accuracies:
                gf: 1.00,0.36
                real: 0.06, 0.43
                fake: 1.00, 0.36

ran validation set (B:81) in                         76.8 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 5 	 Time Taken: 607 sec
validation accuracies:
                gf: 0.86,0.43
                real: 0.17, 0.45
                fake: 0.94, 0.45

ran validation set (B:101) in                         61.9 s.
validation accuracies:
                gf: 1.00,0.38
                real: 0.00, 0.41
                fake: 1.00, 0.39

ran validation set (B:121) in                         71.2 s.
validation accuracies:
                gf: 0.98,0.42
                real: 0.27, 0.47
                fake: 0.78, 0.48

ran validation set (B:141) in                         73.6 s.
validation accuracies:
                gf: 1.00,0.38
                real: 0.25, 0.46
                fake: 0.94, 0.38

ran validation set (B:161) in                         77.8 s.
validation accuracies:
                gf: 0.94,0.42
                real: 0.42, 0.49
                fake: 0.67, 0.48

ran validation set (B:181) in                         50.2 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 5 	 Time Taken: 597 sec
validation accuracies:
                gf: 1.00,0.37
                real: 0.25, 0.46
                fake: 0.98, 0.40

ran validation set (B:201) in                         65.7 s.
validation accuracies:
                gf: 0.73,0.47
                real: 0.34, 0.49
                fake: 0.50, 0.50

ran validation set (B:221) in                         65.9 s.
validation accuracies:
                gf: 1.00,0.39
                real: 0.00, 0.40
                fake: 1.00, 0.40

ran validation set (B:241) in                         77.8 s.
validation accuracies:
                gf: 1.00,0.42
                real: 0.00, 0.44
                fake: 1.00, 0.45

ran validation set (B:261) in                         62.7 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 5 	 Time Taken: 548 sec
validation accuracies:
                gf: 0.98,0.46
                real: 0.19, 0.48
                fake: 0.95, 0.46

ran validation set (B:281) in                         66.0 s.
validation accuracies:
                gf: 0.97,0.45
                real: 0.22, 0.48
                fake: 0.70, 0.49

ran validation set (B:301) in                         74.0 s.
validation accuracies:
                gf: 1.00,0.39
                real: 0.23, 0.46
                fake: 1.00, 0.39

ran validation set (B:321) in                         63.4 s.
validation accuracies:
                gf: 0.80,0.47
                real: 0.47, 0.50
                fake: 0.53, 0.50

ran validation set (B:341) in                         66.1 s.
validation accuracies:
                gf: 0.97,0.42
                real: 0.08, 0.44
                fake: 1.00, 0.40

ran validation set (B:361) in                         65.3 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 5 	 Time Taken: 608 sec
validation accuracies:
                gf: 0.81,0.46
                real: 0.30, 0.48
                fake: 0.78, 0.48

ran validation set (B:381) in                         59.9 s.
validation accuracies:
                gf: 1.00,0.38
                real: 0.31, 0.46
                fake: 1.00, 0.41

ran validation set (B:401) in                         77.0 s.
validation accuracies:
                gf: 0.92,0.44
                real: 0.02, 0.45
                fake: 0.88, 0.46

ran validation set (B:421) in                         71.5 s.
validation accuracies:
                gf: 1.00,0.39
                real: 0.00, 0.42
                fake: 1.00, 0.41

ran validation set (B:441) in                         64.3 s.
learning rate 0.0002000 -> 0.0001600
End of epoch 5 / 5 	 Time Taken: 556 sec
Finished training, model is saved (5 epochs in 2923.0220992565155s)
Batches trained - G: 219, D: 241 
Seed: 42
----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 32                            	[default: 64]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints/         	[default: ./checkpoints]
        confidence_weight: 0.0                           
           continue_train: False                         
                crop_size: 256                           	[default: 64]
                 dataroot: /scratch/datasets/Cityscapes  	[default: datasets]
             dataset_mode: cityscapes                    	[default: double]
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
              fake_target: 0.1                           
            flip_vertical: False                         
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.0                           	[default: 0.1]
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: inf                           
          min_obj_surface: 100                           
                    model: copy                          
    n_alternating_batches: 20                            	[default: 1]
                 n_epochs: 5                             	[default: 20]
           n_epochs_decay: 0                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN                       
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
             noisy_labels: True                          	[default: False]
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
              pred_type_D: baseline                      	[default: pool]
               preprocess: resize_and_crop               
               print_freq: 100                           	[default: 20]
              real_target: 0.9                           
                      run: -1                            
             save_by_iter: False                         
          save_epoch_freq: 10                            
         save_latest_freq: 5000                          
                     seed: 42                            	[default: 0]
           serial_batches: False                         
               sigma_blur: 1.0                           
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
                  use_amp: True                          
           val_batch_size: 64                            	[default: 512]
                 val_freq: 20                            	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [CityscapesDataset] and dataloder are created
dataset [CityscapesDataset] and dataloder are created
The number of validation images = 500
Starting training of copy-model
The number of training images = 2975
The number of epochs to run = 5
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [CopyModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential(
      (0): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): DecoderBlock(
        (model): Sequential(
          (0): Upsample(scale_factor=2.0, mode=bilinear)
          (1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
          (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (3): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.634 M
DataParallel(
  (module): CopyDiscriminator(
    (blur_filter): GaussianSmoothing()
    (downscale): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (upscale): Sequential()
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=replicate)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2)
      )
    )
    (sigmoid): Sigmoid()
    (pred_layers): Sequential(
      (0): AdaptiveAvgPool2d(output_size=1)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=512, out_features=1, bias=True)
      (3): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 1.606 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN/web...
validation accuracies:
                gf: 1.00,0.49
                real: 0.00, 0.49
                fake: 1.00, 0.49

ran validation set (B:1) in                         47.7 s.
validation accuracies:
                gf: 1.00,0.49
                real: 0.00, 0.49
                fake: 0.34, 0.50

ran validation set (B:21) in                         68.9 s.
validation accuracies:
                gf: 0.05,0.53
                real: 0.97, 0.54
                fake: 0.88, 0.48

ran validation set (B:41) in                         71.2 s.
validation accuracies:
                gf: 1.00,0.48
                real: 0.00, 0.48
                fake: 1.00, 0.47

ran validation set (B:61) in                         72.2 s.
validation accuracies:
                gf: 0.41,0.51
                real: 0.75, 0.52
                fake: 0.83, 0.48

ran validation set (B:81) in                         69.4 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 5 	 Time Taken: 585 sec
validation accuracies:
                gf: 0.94,0.49
                real: 0.20, 0.49
                fake: 0.95, 0.48

ran validation set (B:101) in                         59.2 s.
validation accuracies:
                gf: 1.00,0.38
                real: 0.00, 0.40
                fake: 1.00, 0.37

ran validation set (B:121) in                         63.7 s.
validation accuracies:
                gf: 1.00,0.42
                real: 0.00, 0.42
                fake: 1.00, 0.42

ran validation set (B:141) in                         78.3 s.
validation accuracies:
                gf: 0.97,0.46
                real: 0.14, 0.47
                fake: 1.00, 0.44

ran validation set (B:161) in                         67.8 s.
validation accuracies:
                gf: 1.00,0.45
                real: 0.00, 0.45
                fake: 1.00, 0.45

ran validation set (B:181) in                         42.0 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 5 	 Time Taken: 603 sec
validation accuracies:
                gf: 0.41,0.51
                real: 0.64, 0.52
                fake: 0.61, 0.48

ran validation set (B:201) in                         64.6 s.
validation accuracies:
                gf: 1.00,0.46
                real: 0.00, 0.45
                fake: 1.00, 0.46

ran validation set (B:221) in                         71.9 s.
validation accuracies:
                gf: 0.83,0.49
                real: 0.16, 0.49
                fake: 0.97, 0.47

ran validation set (B:241) in                         56.8 s.
validation accuracies:
                gf: 0.81,0.48
                real: 0.05, 0.48
                fake: 0.56, 0.50

ran validation set (B:261) in                         71.9 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 5 	 Time Taken: 557 sec
validation accuracies:
                gf: 1.00,0.40
                real: 0.00, 0.40
                fake: 1.00, 0.40

ran validation set (B:281) in                         65.9 s.
validation accuracies:
                gf: 1.00,0.44
                real: 0.00, 0.44
                fake: 1.00, 0.45

ran validation set (B:301) in                         70.4 s.
validation accuracies:
                gf: 0.89,0.49
                real: 0.27, 0.49
                fake: 0.86, 0.49

ran validation set (B:321) in                         76.0 s.
validation accuracies:
                gf: 0.98,0.49
                real: 0.11, 0.49
                fake: 0.75, 0.49

ran validation set (B:341) in                         61.7 s.
validation accuracies:
                gf: 1.00,0.41
                real: 0.00, 0.41
                fake: 1.00, 0.41

ran validation set (B:361) in                         62.9 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 5 	 Time Taken: 613 sec
validation accuracies:
                gf: 1.00,0.44
                real: 0.02, 0.45
                fake: 1.00, 0.46

ran validation set (B:381) in                         72.7 s.
validation accuracies:
                gf: 0.50,0.50
                real: 0.59, 0.51
                fake: 0.69, 0.48

ran validation set (B:401) in                         79.1 s.
validation accuracies:
                gf: 0.84,0.48
                real: 0.31, 0.49
                fake: 0.70, 0.49

ran validation set (B:421) in                         79.2 s.
validation accuracies:
                gf: 1.00,0.40
                real: 0.00, 0.41
                fake: 1.00, 0.40

ran validation set (B:441) in                         62.7 s.
learning rate 0.0002000 -> 0.0001600
End of epoch 5 / 5 	 Time Taken: 569 sec
Finished training, model is saved (5 epochs in 2933.3669090270996s)
Batches trained - G: 238, D: 222 
