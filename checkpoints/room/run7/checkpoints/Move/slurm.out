starting MoveGAN training run 7
Tar file moved to scratch
Current time : 14:12:23

10k_train.tar.gz
990000_img.jpg
990000_mask_0.jpg
990000_mask_1.jpg
990000_mask_2.jpg
Tar file extracted on scratch
Current time : 14:12:29

Validation tar copied to scratch
Current time : 14:12:29

validation tar extracted on scratch
Current time : 14:12:29

----------------- Options ---------------
               batch_size: 64                            	[default: 1]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/ROOM/images/	[default: None]
             dataset_mode: room                          
                direction: AtoB                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
                load_iter: 0                             	[default: 0]
                load_size: 64                            
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: 10000                         	[default: inf]
          min_obj_surface: 60                            	[default: 100]
                    model: move                          	[default: copy]
                 n_epochs: 5                             	[default: 100]
           n_epochs_decay: 15                            	[default: 100]
               n_layers_D: 3                             
            n_layers_conv: 4                             
                     name: Move                          	[default: MoveModel]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: True                          
                  no_html: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize                        
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
                     seed: 0                             
           serial_batches: False                         
                   suffix:                               
                theta_dim: 6                             	[default: 2]
              tracemalloc: False                         
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: False                         
----------------- End -------------------
dataset [RoomDataset] and dataloder are created
dataset [RoomDataset] and dataloder are created
Starting training of move-model
The number of training images = 10000
The number of validation images = 1111
The number of epochs to run = 20
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [MoveModel] was created
---------- Networks initialized -------------
[Network Conv] Total number of parameters : 4.732 M
[Network D] Total number of parameters : 6.960 M
-----------------------------------------------
create web directory /scratch/checkpoints/Move/web...
(epoch: 1, batches: 20, time: 0.002, data: 0.002) loss_D_real: 0.979 loss_D_fake: 0.625 loss_D: 0.802 loss_G: 1.085 loss_conv: 1.085 acc_real: 0.394 acc_fake: 0.596 
(epoch: 1, batches: 40, time: 0.003, data: 0.002) loss_D_real: 0.837 loss_D_fake: 0.643 loss_D: 0.740 loss_G: 0.897 loss_conv: 0.897 acc_real: 0.394 acc_fake: 0.596 
(epoch: 1, batches: 60, time: 0.002, data: 0.002) loss_D_real: 1.095 loss_D_fake: 0.384 loss_D: 0.739 loss_G: 1.083 loss_conv: 1.083 acc_real: 0.394 acc_fake: 0.596 
(epoch: 1, batches: 80, time: 0.003, data: 0.001) loss_D_real: 0.911 loss_D_fake: 0.625 loss_D: 0.768 loss_G: 0.960 loss_conv: 0.960 acc_real: 0.394 acc_fake: 0.596 
(epoch: 1, batches: 100, time: 0.003, data: 0.002) loss_D_real: 1.056 loss_D_fake: 0.470 loss_D: 0.763 loss_G: 0.863 loss_conv: 0.863 acc_real: 0.394 acc_fake: 0.596 
(epoch: 1, batches: 120, time: 0.002, data: 0.003) loss_D_real: 0.984 loss_D_fake: 0.455 loss_D: 0.720 loss_G: 0.985 loss_conv: 0.985 acc_real: 0.358 acc_fake: 0.650 
(epoch: 1, batches: 140, time: 0.002, data: 0.003) loss_D_real: 0.727 loss_D_fake: 0.742 loss_D: 0.735 loss_G: 1.041 loss_conv: 1.041 acc_real: 0.358 acc_fake: 0.650 
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 20 	 Time Taken: 427 sec
(epoch: 2, batches: 20, time: 0.002, data: 0.005) loss_D_real: 0.976 loss_D_fake: 0.499 loss_D: 0.737 loss_G: 0.827 loss_conv: 0.827 acc_real: 0.358 acc_fake: 0.650 
(epoch: 2, batches: 40, time: 0.003, data: 0.001) loss_D_real: 0.848 loss_D_fake: 0.559 loss_D: 0.704 loss_G: 0.897 loss_conv: 0.897 acc_real: 0.358 acc_fake: 0.650 
(epoch: 2, batches: 60, time: 0.002, data: 0.045) loss_D_real: 0.878 loss_D_fake: 0.509 loss_D: 0.693 loss_G: 0.877 loss_conv: 0.877 acc_real: 0.208 acc_fake: 0.817 
(epoch: 2, batches: 80, time: 0.002, data: 0.006) loss_D_real: 0.883 loss_D_fake: 0.491 loss_D: 0.687 loss_G: 0.827 loss_conv: 0.827 acc_real: 0.208 acc_fake: 0.817 
(epoch: 2, batches: 100, time: 0.003, data: 0.002) loss_D_real: 0.886 loss_D_fake: 0.552 loss_D: 0.719 loss_G: 0.941 loss_conv: 0.941 acc_real: 0.208 acc_fake: 0.817 
(epoch: 2, batches: 120, time: 0.002, data: 0.002) loss_D_real: 0.865 loss_D_fake: 0.559 loss_D: 0.712 loss_G: 0.870 loss_conv: 0.870 acc_real: 0.208 acc_fake: 0.817 
(epoch: 2, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.855 loss_D_fake: 0.547 loss_D: 0.701 loss_G: 0.888 loss_conv: 0.888 acc_real: 0.208 acc_fake: 0.817 
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 20 	 Time Taken: 424 sec
(epoch: 3, batches: 20, time: 0.003, data: 0.001) loss_D_real: 0.821 loss_D_fake: 0.493 loss_D: 0.657 loss_G: 0.839 loss_conv: 0.839 acc_real: 0.361 acc_fake: 0.691 
(epoch: 3, batches: 40, time: 0.003, data: 0.002) loss_D_real: 0.830 loss_D_fake: 0.453 loss_D: 0.642 loss_G: 0.809 loss_conv: 0.809 acc_real: 0.361 acc_fake: 0.691 
(epoch: 3, batches: 60, time: 0.003, data: 0.002) loss_D_real: 0.961 loss_D_fake: 0.402 loss_D: 0.681 loss_G: 1.002 loss_conv: 1.002 acc_real: 0.361 acc_fake: 0.691 
(epoch: 3, batches: 80, time: 0.003, data: 0.002) loss_D_real: 0.824 loss_D_fake: 0.515 loss_D: 0.669 loss_G: 0.985 loss_conv: 0.985 acc_real: 0.361 acc_fake: 0.691 
(epoch: 3, batches: 100, time: 0.003, data: 0.321) loss_D_real: 0.872 loss_D_fake: 0.475 loss_D: 0.673 loss_G: 0.859 loss_conv: 0.859 acc_real: 0.074 acc_fake: 0.955 
(epoch: 3, batches: 120, time: 0.003, data: 0.355) loss_D_real: 0.897 loss_D_fake: 0.460 loss_D: 0.679 loss_G: 0.969 loss_conv: 0.969 acc_real: 0.074 acc_fake: 0.955 
(epoch: 3, batches: 140, time: 0.003, data: 0.376) loss_D_real: 0.686 loss_D_fake: 0.668 loss_D: 0.677 loss_G: 1.167 loss_conv: 1.167 acc_real: 0.074 acc_fake: 0.955 
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 20 	 Time Taken: 423 sec
(epoch: 4, batches: 20, time: 0.003, data: 0.003) loss_D_real: 0.741 loss_D_fake: 0.558 loss_D: 0.649 loss_G: 1.127 loss_conv: 1.127 acc_real: 0.074 acc_fake: 0.955 
(epoch: 4, batches: 40, time: 0.003, data: 0.003) loss_D_real: 0.668 loss_D_fake: 0.622 loss_D: 0.645 loss_G: 1.274 loss_conv: 1.274 acc_real: 0.502 acc_fake: 0.727 
(epoch: 4, batches: 60, time: 0.003, data: 0.001) loss_D_real: 0.646 loss_D_fake: 0.637 loss_D: 0.641 loss_G: 0.821 loss_conv: 0.821 acc_real: 0.502 acc_fake: 0.727 
(epoch: 4, batches: 80, time: 0.003, data: 0.003) loss_D_real: 0.685 loss_D_fake: 0.498 loss_D: 0.591 loss_G: 1.324 loss_conv: 1.324 acc_real: 0.502 acc_fake: 0.727 
(epoch: 4, batches: 100, time: 0.003, data: 0.003) loss_D_real: 0.655 loss_D_fake: 0.519 loss_D: 0.587 loss_G: 1.188 loss_conv: 1.188 acc_real: 0.502 acc_fake: 0.727 
(epoch: 4, batches: 120, time: 0.002, data: 0.002) loss_D_real: 0.731 loss_D_fake: 0.368 loss_D: 0.549 loss_G: 1.559 loss_conv: 1.559 acc_real: 0.502 acc_fake: 0.727 
(epoch: 4, batches: 140, time: 0.003, data: 0.003) loss_D_real: 0.763 loss_D_fake: 0.351 loss_D: 0.557 loss_G: 1.220 loss_conv: 1.220 acc_real: 0.418 acc_fake: 0.860 
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 20 	 Time Taken: 422 sec
(epoch: 5, batches: 20, time: 0.003, data: 9.973) loss_D_real: 0.565 loss_D_fake: 0.539 loss_D: 0.552 loss_G: 1.645 loss_conv: 1.645 acc_real: 0.418 acc_fake: 0.860 
(epoch: 5, batches: 40, time: 0.003, data: 9.399) loss_D_real: 0.824 loss_D_fake: 0.306 loss_D: 0.565 loss_G: 1.187 loss_conv: 1.187 acc_real: 0.418 acc_fake: 0.860 
(epoch: 5, batches: 60, time: 0.002, data: 8.392) loss_D_real: 0.679 loss_D_fake: 0.434 loss_D: 0.556 loss_G: 1.706 loss_conv: 1.706 acc_real: 0.418 acc_fake: 0.860 
(epoch: 5, batches: 80, time: 0.002, data: 7.572) loss_D_real: 0.590 loss_D_fake: 0.477 loss_D: 0.533 loss_G: 1.559 loss_conv: 1.559 acc_real: 0.909 acc_fake: 0.662 
(epoch: 5, batches: 100, time: 0.002, data: 6.922) loss_D_real: 0.876 loss_D_fake: 0.300 loss_D: 0.588 loss_G: 1.663 loss_conv: 1.663 acc_real: 0.909 acc_fake: 0.662 
(epoch: 5, batches: 120, time: 0.002, data: 6.299) loss_D_real: 0.873 loss_D_fake: 0.234 loss_D: 0.554 loss_G: 2.045 loss_conv: 2.045 acc_real: 0.909 acc_fake: 0.662 
(epoch: 5, batches: 140, time: 0.003, data: 5.791) loss_D_real: 0.678 loss_D_fake: 0.374 loss_D: 0.526 loss_G: 2.003 loss_conv: 2.003 acc_real: 0.909 acc_fake: 0.662 
saving the model at the end of epoch 5, iters 49920
learning rate 0.0002000 -> 0.0001600
End of epoch 5 / 20 	 Time Taken: 423 sec
(epoch: 6, batches: 20, time: 0.003, data: 0.005) loss_D_real: 0.564 loss_D_fake: 0.393 loss_D: 0.479 loss_G: 2.045 loss_conv: 2.045 acc_real: 0.909 acc_fake: 0.662 
(epoch: 6, batches: 40, time: 0.003, data: 0.006) loss_D_real: 0.605 loss_D_fake: 0.360 loss_D: 0.483 loss_G: 2.229 loss_conv: 2.229 acc_real: 0.837 acc_fake: 0.787 
(epoch: 6, batches: 60, time: 0.003, data: 0.393) loss_D_real: 0.644 loss_D_fake: 0.346 loss_D: 0.495 loss_G: 1.919 loss_conv: 1.919 acc_real: 0.837 acc_fake: 0.787 
(epoch: 6, batches: 80, time: 0.002, data: 0.384) loss_D_real: 0.690 loss_D_fake: 0.250 loss_D: 0.470 loss_G: 2.240 loss_conv: 2.240 acc_real: 0.837 acc_fake: 0.787 
(epoch: 6, batches: 100, time: 0.003, data: 0.370) loss_D_real: 0.589 loss_D_fake: 0.420 loss_D: 0.504 loss_G: 2.410 loss_conv: 2.410 acc_real: 0.837 acc_fake: 0.787 
(epoch: 6, batches: 120, time: 0.004, data: 0.454) loss_D_real: 0.620 loss_D_fake: 0.254 loss_D: 0.437 loss_G: 2.015 loss_conv: 2.015 acc_real: 0.837 acc_fake: 0.787 
(epoch: 6, batches: 140, time: 0.002, data: 0.236) loss_D_real: 0.656 loss_D_fake: 0.220 loss_D: 0.438 loss_G: 2.679 loss_conv: 2.679 acc_real: 0.766 acc_fake: 0.878 
learning rate 0.0001600 -> 0.0001600
End of epoch 6 / 20 	 Time Taken: 424 sec
(epoch: 7, batches: 20, time: 0.003, data: 0.003) loss_D_real: 0.570 loss_D_fake: 0.342 loss_D: 0.456 loss_G: 2.558 loss_conv: 2.558 acc_real: 0.766 acc_fake: 0.878 
(epoch: 7, batches: 40, time: 0.003, data: 0.001) loss_D_real: 0.631 loss_D_fake: 0.262 loss_D: 0.447 loss_G: 2.517 loss_conv: 2.517 acc_real: 0.766 acc_fake: 0.878 
(epoch: 7, batches: 60, time: 0.003, data: 0.002) loss_D_real: 0.665 loss_D_fake: 0.245 loss_D: 0.455 loss_G: 2.903 loss_conv: 2.903 acc_real: 0.766 acc_fake: 0.878 
(epoch: 7, batches: 80, time: 0.002, data: 0.003) loss_D_real: 0.592 loss_D_fake: 0.315 loss_D: 0.454 loss_G: 2.647 loss_conv: 2.647 acc_real: 0.713 acc_fake: 0.895 
(epoch: 7, batches: 100, time: 0.003, data: 0.001) loss_D_real: 0.582 loss_D_fake: 0.438 loss_D: 0.510 loss_G: 2.837 loss_conv: 2.837 acc_real: 0.713 acc_fake: 0.895 
(epoch: 7, batches: 120, time: 0.003, data: 0.002) loss_D_real: 0.695 loss_D_fake: 0.227 loss_D: 0.461 loss_G: 2.747 loss_conv: 2.747 acc_real: 0.713 acc_fake: 0.895 
(epoch: 7, batches: 140, time: 0.003, data: 0.003) loss_D_real: 0.778 loss_D_fake: 0.101 loss_D: 0.439 loss_G: 2.371 loss_conv: 2.371 acc_real: 0.713 acc_fake: 0.895 
learning rate 0.0001600 -> 0.0001600
End of epoch 7 / 20 	 Time Taken: 422 sec
(epoch: 8, batches: 20, time: 0.002, data: 0.092) loss_D_real: 0.678 loss_D_fake: 0.179 loss_D: 0.429 loss_G: 2.613 loss_conv: 2.613 acc_real: 0.624 acc_fake: 0.942 
(epoch: 8, batches: 40, time: 0.002, data: 0.005) loss_D_real: 0.614 loss_D_fake: 0.230 loss_D: 0.422 loss_G: 2.780 loss_conv: 2.780 acc_real: 0.624 acc_fake: 0.942 
(epoch: 8, batches: 60, time: 0.002, data: 0.046) loss_D_real: 0.699 loss_D_fake: 0.224 loss_D: 0.461 loss_G: 2.771 loss_conv: 2.771 acc_real: 0.624 acc_fake: 0.942 
(epoch: 8, batches: 80, time: 0.003, data: 0.061) loss_D_real: 0.620 loss_D_fake: 0.161 loss_D: 0.390 loss_G: 2.389 loss_conv: 2.389 acc_real: 0.624 acc_fake: 0.942 
(epoch: 8, batches: 100, time: 0.002, data: 0.136) loss_D_real: 0.608 loss_D_fake: 0.146 loss_D: 0.377 loss_G: 2.742 loss_conv: 2.742 acc_real: 0.624 acc_fake: 0.942 
(epoch: 8, batches: 120, time: 0.002, data: 0.002) loss_D_real: 0.729 loss_D_fake: 0.180 loss_D: 0.455 loss_G: 2.639 loss_conv: 2.639 acc_real: 0.665 acc_fake: 0.936 
(epoch: 8, batches: 140, time: 0.002, data: 0.002) loss_D_real: 0.577 loss_D_fake: 0.163 loss_D: 0.370 loss_G: 2.517 loss_conv: 2.517 acc_real: 0.665 acc_fake: 0.936 
learning rate 0.0001600 -> 0.0001600
End of epoch 8 / 20 	 Time Taken: 423 sec
(epoch: 9, batches: 20, time: 0.003, data: 0.006) loss_D_real: 0.697 loss_D_fake: 0.220 loss_D: 0.458 loss_G: 2.658 loss_conv: 2.658 acc_real: 0.665 acc_fake: 0.936 
(epoch: 9, batches: 40, time: 0.003, data: 0.006) loss_D_real: 0.541 loss_D_fake: 0.381 loss_D: 0.461 loss_G: 3.259 loss_conv: 3.259 acc_real: 0.665 acc_fake: 0.936 
(epoch: 9, batches: 60, time: 0.002, data: 0.002) loss_D_real: 0.601 loss_D_fake: 0.221 loss_D: 0.411 loss_G: 3.246 loss_conv: 3.246 acc_real: 0.835 acc_fake: 0.912 
(epoch: 9, batches: 80, time: 0.002, data: 0.002) loss_D_real: 0.625 loss_D_fake: 0.286 loss_D: 0.455 loss_G: 2.715 loss_conv: 2.715 acc_real: 0.835 acc_fake: 0.912 
(epoch: 9, batches: 100, time: 0.003, data: 0.002) loss_D_real: 0.561 loss_D_fake: 0.208 loss_D: 0.385 loss_G: 2.845 loss_conv: 2.845 acc_real: 0.835 acc_fake: 0.912 
(epoch: 9, batches: 120, time: 0.003, data: 0.002) loss_D_real: 0.679 loss_D_fake: 0.116 loss_D: 0.398 loss_G: 3.334 loss_conv: 3.334 acc_real: 0.835 acc_fake: 0.912 
(epoch: 9, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.679 loss_D_fake: 0.244 loss_D: 0.461 loss_G: 2.901 loss_conv: 2.901 acc_real: 0.835 acc_fake: 0.912 
learning rate 0.0001600 -> 0.0001600
End of epoch 9 / 20 	 Time Taken: 427 sec
(epoch: 10, batches: 20, time: 0.002, data: 10.153) loss_D_real: 0.668 loss_D_fake: 0.123 loss_D: 0.396 loss_G: 3.340 loss_conv: 3.340 acc_real: 0.859 acc_fake: 0.913 
(epoch: 10, batches: 40, time: 0.003, data: 10.109) loss_D_real: 0.721 loss_D_fake: 0.084 loss_D: 0.402 loss_G: 3.003 loss_conv: 3.003 acc_real: 0.859 acc_fake: 0.913 
(epoch: 10, batches: 60, time: 0.003, data: 9.754) loss_D_real: 0.610 loss_D_fake: 0.253 loss_D: 0.432 loss_G: 2.857 loss_conv: 2.857 acc_real: 0.859 acc_fake: 0.913 
(epoch: 10, batches: 80, time: 0.003, data: 8.675) loss_D_real: 0.552 loss_D_fake: 0.236 loss_D: 0.394 loss_G: 3.186 loss_conv: 3.186 acc_real: 0.859 acc_fake: 0.913 
(epoch: 10, batches: 100, time: 0.003, data: 7.514) loss_D_real: 0.623 loss_D_fake: 0.111 loss_D: 0.367 loss_G: 3.292 loss_conv: 3.292 acc_real: 0.787 acc_fake: 0.932 
(epoch: 10, batches: 120, time: 0.002, data: 5.349) loss_D_real: 0.619 loss_D_fake: 0.181 loss_D: 0.400 loss_G: 2.816 loss_conv: 2.816 acc_real: 0.787 acc_fake: 0.932 
(epoch: 10, batches: 140, time: 0.003, data: 4.551) loss_D_real: 0.668 loss_D_fake: 0.190 loss_D: 0.429 loss_G: 3.219 loss_conv: 3.219 acc_real: 0.787 acc_fake: 0.932 
saving the model at the end of epoch 10, iters 99840
learning rate 0.0001600 -> 0.0001280
End of epoch 10 / 20 	 Time Taken: 424 sec
(epoch: 11, batches: 20, time: 0.003, data: 0.002) loss_D_real: 0.571 loss_D_fake: 0.172 loss_D: 0.372 loss_G: 3.631 loss_conv: 3.631 acc_real: 0.787 acc_fake: 0.932 
(epoch: 11, batches: 40, time: 0.003, data: 0.046) loss_D_real: 0.582 loss_D_fake: 0.170 loss_D: 0.376 loss_G: 3.530 loss_conv: 3.530 acc_real: 0.787 acc_fake: 0.932 
(epoch: 11, batches: 60, time: 0.002, data: 0.005) loss_D_real: 0.577 loss_D_fake: 0.107 loss_D: 0.342 loss_G: 3.204 loss_conv: 3.204 acc_real: 0.845 acc_fake: 0.914 
(epoch: 11, batches: 80, time: 0.003, data: 0.085) loss_D_real: 0.586 loss_D_fake: 0.252 loss_D: 0.419 loss_G: 3.067 loss_conv: 3.067 acc_real: 0.845 acc_fake: 0.914 
(epoch: 11, batches: 100, time: 0.002, data: 0.231) loss_D_real: 0.597 loss_D_fake: 0.216 loss_D: 0.406 loss_G: 3.002 loss_conv: 3.002 acc_real: 0.845 acc_fake: 0.914 
(epoch: 11, batches: 120, time: 0.002, data: 0.533) loss_D_real: 0.639 loss_D_fake: 0.167 loss_D: 0.403 loss_G: 2.990 loss_conv: 2.990 acc_real: 0.845 acc_fake: 0.914 
(epoch: 11, batches: 140, time: 0.003, data: 0.953) loss_D_real: 0.534 loss_D_fake: 0.140 loss_D: 0.337 loss_G: 3.408 loss_conv: 3.408 acc_real: 0.845 acc_fake: 0.914 
learning rate 0.0001280 -> 0.0001280
End of epoch 11 / 20 	 Time Taken: 423 sec
(epoch: 12, batches: 20, time: 0.003, data: 0.002) loss_D_real: 0.565 loss_D_fake: 0.211 loss_D: 0.388 loss_G: 3.326 loss_conv: 3.326 acc_real: 0.845 acc_fake: 0.945 
(epoch: 12, batches: 40, time: 0.003, data: 0.001) loss_D_real: 0.570 loss_D_fake: 0.170 loss_D: 0.370 loss_G: 3.624 loss_conv: 3.624 acc_real: 0.845 acc_fake: 0.945 
(epoch: 12, batches: 60, time: 0.003, data: 0.002) loss_D_real: 0.533 loss_D_fake: 0.213 loss_D: 0.373 loss_G: 2.917 loss_conv: 2.917 acc_real: 0.845 acc_fake: 0.945 
(epoch: 12, batches: 80, time: 0.002, data: 0.002) loss_D_real: 0.606 loss_D_fake: 0.114 loss_D: 0.360 loss_G: 3.364 loss_conv: 3.364 acc_real: 0.845 acc_fake: 0.945 
(epoch: 12, batches: 100, time: 0.003, data: 0.002) loss_D_real: 0.552 loss_D_fake: 0.313 loss_D: 0.432 loss_G: 3.732 loss_conv: 3.732 acc_real: 0.858 acc_fake: 0.921 
(epoch: 12, batches: 120, time: 0.002, data: 0.002) loss_D_real: 0.559 loss_D_fake: 0.149 loss_D: 0.354 loss_G: 3.669 loss_conv: 3.669 acc_real: 0.858 acc_fake: 0.921 
(epoch: 12, batches: 140, time: 0.002, data: 0.002) loss_D_real: 0.632 loss_D_fake: 0.116 loss_D: 0.374 loss_G: 3.323 loss_conv: 3.323 acc_real: 0.858 acc_fake: 0.921 
learning rate 0.0001280 -> 0.0001280
End of epoch 12 / 20 	 Time Taken: 421 sec
(epoch: 13, batches: 20, time: 0.003, data: 0.001) loss_D_real: 0.600 loss_D_fake: 0.134 loss_D: 0.367 loss_G: 3.146 loss_conv: 3.146 acc_real: 0.858 acc_fake: 0.921 
(epoch: 13, batches: 40, time: 0.003, data: 0.002) loss_D_real: 0.591 loss_D_fake: 0.182 loss_D: 0.387 loss_G: 3.097 loss_conv: 3.097 acc_real: 0.896 acc_fake: 0.904 
(epoch: 13, batches: 60, time: 0.002, data: 0.003) loss_D_real: 0.660 loss_D_fake: 0.144 loss_D: 0.402 loss_G: 3.422 loss_conv: 3.422 acc_real: 0.896 acc_fake: 0.904 
(epoch: 13, batches: 80, time: 0.003, data: 0.002) loss_D_real: 0.639 loss_D_fake: 0.107 loss_D: 0.373 loss_G: 3.482 loss_conv: 3.482 acc_real: 0.896 acc_fake: 0.904 
(epoch: 13, batches: 100, time: 0.002, data: 0.006) loss_D_real: 0.629 loss_D_fake: 0.082 loss_D: 0.355 loss_G: 3.208 loss_conv: 3.208 acc_real: 0.896 acc_fake: 0.904 
(epoch: 13, batches: 120, time: 0.002, data: 0.093) loss_D_real: 0.543 loss_D_fake: 0.133 loss_D: 0.338 loss_G: 3.189 loss_conv: 3.189 acc_real: 0.896 acc_fake: 0.904 
(epoch: 13, batches: 140, time: 0.002, data: 0.002) loss_D_real: 0.569 loss_D_fake: 0.106 loss_D: 0.337 loss_G: 3.445 loss_conv: 3.445 acc_real: 0.886 acc_fake: 0.930 
learning rate 0.0001280 -> 0.0001280
End of epoch 13 / 20 	 Time Taken: 424 sec
(epoch: 14, batches: 20, time: 0.002, data: 0.003) loss_D_real: 0.626 loss_D_fake: 0.090 loss_D: 0.358 loss_G: 2.949 loss_conv: 2.949 acc_real: 0.886 acc_fake: 0.930 
(epoch: 14, batches: 40, time: 0.003, data: 0.040) loss_D_real: 0.593 loss_D_fake: 0.137 loss_D: 0.365 loss_G: 3.301 loss_conv: 3.301 acc_real: 0.886 acc_fake: 0.930 
(epoch: 14, batches: 60, time: 0.002, data: 0.004) loss_D_real: 0.544 loss_D_fake: 0.237 loss_D: 0.390 loss_G: 2.904 loss_conv: 2.904 acc_real: 0.886 acc_fake: 0.930 
(epoch: 14, batches: 80, time: 0.002, data: 0.005) loss_D_real: 0.582 loss_D_fake: 0.250 loss_D: 0.416 loss_G: 3.619 loss_conv: 3.619 acc_real: 0.697 acc_fake: 0.956 
(epoch: 14, batches: 100, time: 0.003, data: 0.014) loss_D_real: 0.542 loss_D_fake: 0.173 loss_D: 0.357 loss_G: 4.131 loss_conv: 4.131 acc_real: 0.697 acc_fake: 0.956 
(epoch: 14, batches: 120, time: 0.003, data: 0.044) loss_D_real: 0.587 loss_D_fake: 0.232 loss_D: 0.409 loss_G: 3.835 loss_conv: 3.835 acc_real: 0.697 acc_fake: 0.956 
(epoch: 14, batches: 140, time: 0.003, data: 0.025) loss_D_real: 0.642 loss_D_fake: 0.136 loss_D: 0.389 loss_G: 3.427 loss_conv: 3.427 acc_real: 0.697 acc_fake: 0.956 
learning rate 0.0001280 -> 0.0001280
End of epoch 14 / 20 	 Time Taken: 421 sec
(epoch: 15, batches: 20, time: 0.003, data: 10.002) loss_D_real: 0.575 loss_D_fake: 0.214 loss_D: 0.394 loss_G: 3.336 loss_conv: 3.336 acc_real: 0.886 acc_fake: 0.920 
(epoch: 15, batches: 40, time: 0.003, data: 9.739) loss_D_real: 0.613 loss_D_fake: 0.094 loss_D: 0.354 loss_G: 2.996 loss_conv: 2.996 acc_real: 0.886 acc_fake: 0.920 
(epoch: 15, batches: 60, time: 0.003, data: 9.957) loss_D_real: 0.585 loss_D_fake: 0.227 loss_D: 0.406 loss_G: 3.718 loss_conv: 3.718 acc_real: 0.886 acc_fake: 0.920 
(epoch: 15, batches: 80, time: 0.003, data: 9.954) loss_D_real: 0.552 loss_D_fake: 0.181 loss_D: 0.366 loss_G: 4.111 loss_conv: 4.111 acc_real: 0.886 acc_fake: 0.920 
(epoch: 15, batches: 100, time: 0.003, data: 9.451) loss_D_real: 0.589 loss_D_fake: 0.145 loss_D: 0.367 loss_G: 3.864 loss_conv: 3.864 acc_real: 0.886 acc_fake: 0.920 
(epoch: 15, batches: 120, time: 0.003, data: 8.664) loss_D_real: 0.576 loss_D_fake: 0.218 loss_D: 0.397 loss_G: 3.345 loss_conv: 3.345 acc_real: 0.898 acc_fake: 0.921 
(epoch: 15, batches: 140, time: 0.003, data: 9.197) loss_D_real: 0.598 loss_D_fake: 0.189 loss_D: 0.394 loss_G: 3.556 loss_conv: 3.556 acc_real: 0.898 acc_fake: 0.921 
saving the model at the end of epoch 15, iters 149760
learning rate 0.0001280 -> 0.0001024
End of epoch 15 / 20 	 Time Taken: 423 sec
(epoch: 16, batches: 20, time: 0.002, data: 0.002) loss_D_real: 0.649 loss_D_fake: 0.240 loss_D: 0.445 loss_G: 3.586 loss_conv: 3.586 acc_real: 0.898 acc_fake: 0.921 
(epoch: 16, batches: 40, time: 0.003, data: 0.002) loss_D_real: 0.546 loss_D_fake: 0.238 loss_D: 0.392 loss_G: 3.846 loss_conv: 3.846 acc_real: 0.898 acc_fake: 0.921 
(epoch: 16, batches: 60, time: 0.004, data: 0.003) loss_D_real: 0.589 loss_D_fake: 0.164 loss_D: 0.377 loss_G: 4.221 loss_conv: 4.221 acc_real: 0.898 acc_fake: 0.921 
(epoch: 16, batches: 80, time: 0.003, data: 0.001) loss_D_real: 0.590 loss_D_fake: 0.061 loss_D: 0.326 loss_G: 4.174 loss_conv: 4.174 acc_real: 0.851 acc_fake: 0.957 
(epoch: 16, batches: 100, time: 0.003, data: 0.002) loss_D_real: 0.554 loss_D_fake: 0.131 loss_D: 0.342 loss_G: 3.666 loss_conv: 3.666 acc_real: 0.851 acc_fake: 0.957 
(epoch: 16, batches: 120, time: 0.003, data: 0.001) loss_D_real: 0.524 loss_D_fake: 0.207 loss_D: 0.365 loss_G: 3.950 loss_conv: 3.950 acc_real: 0.851 acc_fake: 0.957 
(epoch: 16, batches: 140, time: 0.002, data: 0.002) loss_D_real: 0.540 loss_D_fake: 0.136 loss_D: 0.338 loss_G: 3.459 loss_conv: 3.459 acc_real: 0.851 acc_fake: 0.957 
learning rate 0.0001024 -> 0.0001024
End of epoch 16 / 20 	 Time Taken: 423 sec
(epoch: 17, batches: 20, time: 0.003, data: 0.003) loss_D_real: 0.594 loss_D_fake: 0.070 loss_D: 0.332 loss_G: 4.022 loss_conv: 4.022 acc_real: 0.838 acc_fake: 0.952 
(epoch: 17, batches: 40, time: 0.003, data: 0.002) loss_D_real: 0.599 loss_D_fake: 0.143 loss_D: 0.371 loss_G: 3.880 loss_conv: 3.880 acc_real: 0.838 acc_fake: 0.952 
(epoch: 17, batches: 60, time: 0.002, data: 0.003) loss_D_real: 0.589 loss_D_fake: 0.185 loss_D: 0.387 loss_G: 3.845 loss_conv: 3.845 acc_real: 0.838 acc_fake: 0.952 
(epoch: 17, batches: 80, time: 0.003, data: 0.002) loss_D_real: 0.637 loss_D_fake: 0.149 loss_D: 0.393 loss_G: 3.640 loss_conv: 3.640 acc_real: 0.838 acc_fake: 0.952 
(epoch: 17, batches: 100, time: 0.003, data: 0.002) loss_D_real: 0.608 loss_D_fake: 0.179 loss_D: 0.394 loss_G: 4.134 loss_conv: 4.134 acc_real: 0.838 acc_fake: 0.952 
(epoch: 17, batches: 120, time: 0.002, data: 0.002) loss_D_real: 0.550 loss_D_fake: 0.091 loss_D: 0.320 loss_G: 3.786 loss_conv: 3.786 acc_real: 0.919 acc_fake: 0.917 
(epoch: 17, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.551 loss_D_fake: 0.113 loss_D: 0.332 loss_G: 4.324 loss_conv: 4.324 acc_real: 0.919 acc_fake: 0.917 
learning rate 0.0001024 -> 0.0001024
End of epoch 17 / 20 	 Time Taken: 425 sec
(epoch: 18, batches: 20, time: 0.003, data: 0.037) loss_D_real: 0.550 loss_D_fake: 0.075 loss_D: 0.313 loss_G: 3.832 loss_conv: 3.832 acc_real: 0.919 acc_fake: 0.917 
(epoch: 18, batches: 40, time: 0.003, data: 0.046) loss_D_real: 0.519 loss_D_fake: 0.134 loss_D: 0.326 loss_G: 4.386 loss_conv: 4.386 acc_real: 0.919 acc_fake: 0.917 
(epoch: 18, batches: 60, time: 0.003, data: 0.002) loss_D_real: 0.562 loss_D_fake: 0.185 loss_D: 0.374 loss_G: 3.938 loss_conv: 3.938 acc_real: 0.897 acc_fake: 0.923 
(epoch: 18, batches: 80, time: 0.002, data: 0.001) loss_D_real: 0.622 loss_D_fake: 0.058 loss_D: 0.340 loss_G: 3.877 loss_conv: 3.877 acc_real: 0.897 acc_fake: 0.923 
(epoch: 18, batches: 100, time: 0.002, data: 0.002) loss_D_real: 0.584 loss_D_fake: 0.098 loss_D: 0.341 loss_G: 3.845 loss_conv: 3.845 acc_real: 0.897 acc_fake: 0.923 
(epoch: 18, batches: 120, time: 0.002, data: 0.002) loss_D_real: 0.582 loss_D_fake: 0.195 loss_D: 0.388 loss_G: 3.676 loss_conv: 3.676 acc_real: 0.897 acc_fake: 0.923 
(epoch: 18, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.568 loss_D_fake: 0.126 loss_D: 0.347 loss_G: 3.828 loss_conv: 3.828 acc_real: 0.897 acc_fake: 0.923 
learning rate 0.0001024 -> 0.0001024
End of epoch 18 / 20 	 Time Taken: 424 sec
(epoch: 19, batches: 20, time: 0.003, data: 0.038) loss_D_real: 0.557 loss_D_fake: 0.178 loss_D: 0.368 loss_G: 3.975 loss_conv: 3.975 acc_real: 0.897 acc_fake: 0.930 
(epoch: 19, batches: 40, time: 0.003, data: 0.033) loss_D_real: 0.586 loss_D_fake: 0.099 loss_D: 0.342 loss_G: 3.951 loss_conv: 3.951 acc_real: 0.897 acc_fake: 0.930 
(epoch: 19, batches: 60, time: 0.002, data: 0.219) loss_D_real: 0.628 loss_D_fake: 0.122 loss_D: 0.375 loss_G: 3.862 loss_conv: 3.862 acc_real: 0.897 acc_fake: 0.930 
(epoch: 19, batches: 80, time: 0.002, data: 0.424) loss_D_real: 0.586 loss_D_fake: 0.142 loss_D: 0.364 loss_G: 4.237 loss_conv: 4.237 acc_real: 0.897 acc_fake: 0.930 
(epoch: 19, batches: 100, time: 0.002, data: 1.299) loss_D_real: 0.616 loss_D_fake: 0.153 loss_D: 0.385 loss_G: 4.000 loss_conv: 4.000 acc_real: 0.907 acc_fake: 0.920 
(epoch: 19, batches: 120, time: 0.002, data: 1.289) loss_D_real: 0.574 loss_D_fake: 0.111 loss_D: 0.342 loss_G: 4.163 loss_conv: 4.163 acc_real: 0.907 acc_fake: 0.920 
(epoch: 19, batches: 140, time: 0.003, data: 1.443) loss_D_real: 0.639 loss_D_fake: 0.120 loss_D: 0.380 loss_G: 4.116 loss_conv: 4.116 acc_real: 0.907 acc_fake: 0.920 
learning rate 0.0001024 -> 0.0001024
End of epoch 19 / 20 	 Time Taken: 424 sec
(epoch: 20, batches: 20, time: 0.002, data: 10.058) loss_D_real: 0.545 loss_D_fake: 0.147 loss_D: 0.346 loss_G: 3.895 loss_conv: 3.895 acc_real: 0.907 acc_fake: 0.920 
(epoch: 20, batches: 40, time: 0.003, data: 9.941) loss_D_real: 0.626 loss_D_fake: 0.078 loss_D: 0.352 loss_G: 4.562 loss_conv: 4.562 acc_real: 0.891 acc_fake: 0.934 
(epoch: 20, batches: 60, time: 0.002, data: 9.992) loss_D_real: 0.613 loss_D_fake: 0.240 loss_D: 0.427 loss_G: 3.823 loss_conv: 3.823 acc_real: 0.891 acc_fake: 0.934 
(epoch: 20, batches: 80, time: 0.003, data: 10.171) loss_D_real: 0.518 loss_D_fake: 0.285 loss_D: 0.402 loss_G: 3.544 loss_conv: 3.544 acc_real: 0.891 acc_fake: 0.934 
(epoch: 20, batches: 100, time: 0.002, data: 10.212) loss_D_real: 0.577 loss_D_fake: 0.084 loss_D: 0.331 loss_G: 3.929 loss_conv: 3.929 acc_real: 0.891 acc_fake: 0.934 
(epoch: 20, batches: 120, time: 0.002, data: 10.182) loss_D_real: 0.544 loss_D_fake: 0.073 loss_D: 0.309 loss_G: 3.876 loss_conv: 3.876 acc_real: 0.891 acc_fake: 0.934 
(epoch: 20, batches: 140, time: 0.003, data: 10.085) loss_D_real: 0.545 loss_D_fake: 0.099 loss_D: 0.322 loss_G: 4.326 loss_conv: 4.326 acc_real: 0.911 acc_fake: 0.925 
saving the model at the end of epoch 20, iters 199680
learning rate 0.0001024 -> 0.0000819
End of epoch 20 / 20 	 Time Taken: 424 sec
Finished training, model is saved
Batches trained - G: 2080, D: 1040 
