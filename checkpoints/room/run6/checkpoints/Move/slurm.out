starting MoveGAN training run 6
Tar file moved to scratch
Current time : 13:53:51

10k_train.tar.gz
990000_img.jpg
990000_mask_0.jpg
990000_mask_1.jpg
990000_mask_2.jpg
Tar file extracted on scratch
Current time : 13:53:57

Validation tar copied to scratch
Current time : 13:53:57

validation tar extracted on scratch
Current time : 13:53:58

----------------- Options ---------------
               batch_size: 64                            	[default: 1]
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/ROOM/images/	[default: None]
             dataset_mode: room                          
                direction: AtoB                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
                load_iter: 0                             	[default: 0]
                load_size: 64                            
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: 10000                         	[default: inf]
          min_obj_surface: 60                            	[default: 100]
                    model: move                          	[default: cycle_gan]
                 n_epochs: 5                             	[default: 100]
           n_epochs_decay: 15                            	[default: 100]
               n_layers_D: 3                             
            n_layers_conv: 4                             
                     name: Move                          	[default: MoveModel]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: True                          
                  no_html: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize                        
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
                     seed: 0                             
           serial_batches: False                         
                   suffix:                               
                theta_dim: 6                             	[default: 2]
              tracemalloc: False                         
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 100                           
                  verbose: False                         
----------------- End -------------------
dataset [RoomDataset] and dataloder are created
dataset [RoomDataset] and dataloder are created
Starting training of move-model
The number of training images = 10000
The number of validation images = 1111
The number of epochs to run = 20
gpu_ids: [0]
initialize network with normal
gpu_ids: [0]
initialize network with normal
model [MoveModel] was created
---------- Networks initialized -------------
[Network Conv] Total number of parameters : 3.962 M
[Network D] Total number of parameters : 6.960 M
-----------------------------------------------
create web directory /scratch/checkpoints/Move/web...
(epoch: 1, batches: 20, time: 0.011, data: 0.001) loss_D_real: 0.976 loss_D_fake: 0.624 loss_D: 0.800 loss_G: 0.964 loss_eq: 2.000 loss_conv: 2.964 acc_real: 0.456 acc_fake: 0.549 
(epoch: 1, batches: 40, time: 0.004, data: 0.511) loss_D_real: 1.007 loss_D_fake: 0.461 loss_D: 0.734 loss_G: 0.896 loss_eq: 1.967 loss_conv: 2.863 acc_real: 0.456 acc_fake: 0.549 
(epoch: 1, batches: 60, time: 0.003, data: 0.001) loss_D_real: 0.880 loss_D_fake: 0.615 loss_D: 0.747 loss_G: 0.891 loss_eq: 1.964 loss_conv: 2.855 acc_real: 0.456 acc_fake: 0.549 
(epoch: 1, batches: 80, time: 0.004, data: 1.635) loss_D_real: 0.913 loss_D_fake: 0.557 loss_D: 0.735 loss_G: 0.825 loss_eq: 2.000 loss_conv: 2.825 acc_real: 0.456 acc_fake: 0.549 
(epoch: 1, batches: 100, time: 0.005, data: 3.020) loss_D_real: 0.972 loss_D_fake: 0.561 loss_D: 0.766 loss_G: 0.941 loss_eq: 2.000 loss_conv: 2.941 acc_real: 0.456 acc_fake: 0.549 
(epoch: 1, batches: 120, time: 0.005, data: 0.001) loss_D_real: 0.914 loss_D_fake: 0.539 loss_D: 0.727 loss_G: 0.881 loss_eq: 1.367 loss_conv: 2.248 acc_real: 0.205 acc_fake: 0.793 
(epoch: 1, batches: 140, time: 0.004, data: 0.004) loss_D_real: 0.854 loss_D_fake: 0.579 loss_D: 0.717 loss_G: 0.963 loss_eq: 1.929 loss_conv: 2.892 acc_real: 0.205 acc_fake: 0.793 
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 20 	 Time Taken: 660 sec
(epoch: 2, batches: 20, time: 0.005, data: 0.001) loss_D_real: 0.822 loss_D_fake: 0.630 loss_D: 0.726 loss_G: 1.084 loss_eq: 1.770 loss_conv: 2.854 acc_real: 0.205 acc_fake: 0.793 
(epoch: 2, batches: 40, time: 0.005, data: 2.586) loss_D_real: 0.921 loss_D_fake: 0.504 loss_D: 0.712 loss_G: 0.941 loss_eq: 1.839 loss_conv: 2.780 acc_real: 0.205 acc_fake: 0.793 
(epoch: 2, batches: 60, time: 0.005, data: 2.996) loss_D_real: 0.921 loss_D_fake: 0.453 loss_D: 0.687 loss_G: 0.929 loss_eq: 1.797 loss_conv: 2.726 acc_real: 0.228 acc_fake: 0.772 
(epoch: 2, batches: 80, time: 0.004, data: 0.746) loss_D_real: 0.827 loss_D_fake: 0.629 loss_D: 0.728 loss_G: 0.905 loss_eq: 1.864 loss_conv: 2.769 acc_real: 0.228 acc_fake: 0.772 
(epoch: 2, batches: 100, time: 0.004, data: 0.001) loss_D_real: 0.877 loss_D_fake: 0.568 loss_D: 0.722 loss_G: 0.850 loss_eq: 1.967 loss_conv: 2.816 acc_real: 0.228 acc_fake: 0.772 
(epoch: 2, batches: 120, time: 0.005, data: 0.001) loss_D_real: 0.864 loss_D_fake: 0.532 loss_D: 0.698 loss_G: 0.886 loss_eq: 2.000 loss_conv: 2.886 acc_real: 0.228 acc_fake: 0.772 
(epoch: 2, batches: 140, time: 0.005, data: 0.381) loss_D_real: 0.860 loss_D_fake: 0.530 loss_D: 0.695 loss_G: 0.877 loss_eq: 2.000 loss_conv: 2.877 acc_real: 0.228 acc_fake: 0.772 
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 20 	 Time Taken: 666 sec
(epoch: 3, batches: 20, time: 0.006, data: 0.026) loss_D_real: 0.875 loss_D_fake: 0.519 loss_D: 0.697 loss_G: 0.810 loss_eq: 1.933 loss_conv: 2.744 acc_real: 0.320 acc_fake: 0.690 
(epoch: 3, batches: 40, time: 0.006, data: 0.339) loss_D_real: 0.843 loss_D_fake: 0.532 loss_D: 0.688 loss_G: 0.934 loss_eq: 1.900 loss_conv: 2.834 acc_real: 0.320 acc_fake: 0.690 
(epoch: 3, batches: 60, time: 0.004, data: 5.275) loss_D_real: 0.837 loss_D_fake: 0.538 loss_D: 0.687 loss_G: 0.845 loss_eq: 2.000 loss_conv: 2.845 acc_real: 0.320 acc_fake: 0.690 
(epoch: 3, batches: 80, time: 0.006, data: 4.412) loss_D_real: 0.886 loss_D_fake: 0.498 loss_D: 0.692 loss_G: 0.809 loss_eq: 2.000 loss_conv: 2.809 acc_real: 0.320 acc_fake: 0.690 
(epoch: 3, batches: 100, time: 0.006, data: 5.361) loss_D_real: 0.863 loss_D_fake: 0.544 loss_D: 0.704 loss_G: 0.835 loss_eq: 2.000 loss_conv: 2.835 acc_real: 0.122 acc_fake: 0.875 
(epoch: 3, batches: 120, time: 0.006, data: 1.953) loss_D_real: 0.839 loss_D_fake: 0.576 loss_D: 0.708 loss_G: 0.799 loss_eq: 1.935 loss_conv: 2.735 acc_real: 0.122 acc_fake: 0.875 
(epoch: 3, batches: 140, time: 0.004, data: 2.806) loss_D_real: 0.910 loss_D_fake: 0.505 loss_D: 0.707 loss_G: 0.862 loss_eq: 1.967 loss_conv: 2.829 acc_real: 0.122 acc_fake: 0.875 
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 20 	 Time Taken: 655 sec
(epoch: 4, batches: 20, time: 0.005, data: 0.002) loss_D_real: 0.833 loss_D_fake: 0.518 loss_D: 0.675 loss_G: 0.906 loss_eq: 1.968 loss_conv: 2.874 acc_real: 0.122 acc_fake: 0.875 
(epoch: 4, batches: 40, time: 0.006, data: 0.001) loss_D_real: 0.846 loss_D_fake: 0.504 loss_D: 0.675 loss_G: 0.873 loss_eq: 2.000 loss_conv: 2.873 acc_real: 0.122 acc_fake: 0.877 
(epoch: 4, batches: 60, time: 0.004, data: 0.002) loss_D_real: 0.880 loss_D_fake: 0.458 loss_D: 0.669 loss_G: 0.883 loss_eq: 2.000 loss_conv: 2.883 acc_real: 0.122 acc_fake: 0.877 
(epoch: 4, batches: 80, time: 0.004, data: 0.001) loss_D_real: 0.875 loss_D_fake: 0.528 loss_D: 0.701 loss_G: 0.873 loss_eq: 2.000 loss_conv: 2.873 acc_real: 0.122 acc_fake: 0.877 
(epoch: 4, batches: 100, time: 0.003, data: 0.001) loss_D_real: 0.853 loss_D_fake: 0.510 loss_D: 0.682 loss_G: 0.834 loss_eq: 2.000 loss_conv: 2.834 acc_real: 0.122 acc_fake: 0.877 
(epoch: 4, batches: 120, time: 0.004, data: 0.001) loss_D_real: 0.892 loss_D_fake: 0.466 loss_D: 0.679 loss_G: 0.935 loss_eq: 2.000 loss_conv: 2.935 acc_real: 0.122 acc_fake: 0.877 
(epoch: 4, batches: 140, time: 0.004, data: 0.001) loss_D_real: 0.803 loss_D_fake: 0.572 loss_D: 0.687 loss_G: 0.902 loss_eq: 1.967 loss_conv: 2.868 acc_real: 0.154 acc_fake: 0.850 
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 20 	 Time Taken: 659 sec
(epoch: 5, batches: 20, time: 0.003, data: 17.758) loss_D_real: 0.819 loss_D_fake: 0.525 loss_D: 0.672 loss_G: 0.857 loss_eq: 1.900 loss_conv: 2.757 acc_real: 0.154 acc_fake: 0.850 
(epoch: 5, batches: 40, time: 0.006, data: 15.117) loss_D_real: 0.837 loss_D_fake: 0.532 loss_D: 0.684 loss_G: 0.887 loss_eq: 1.930 loss_conv: 2.817 acc_real: 0.154 acc_fake: 0.850 
(epoch: 5, batches: 60, time: 0.003, data: 14.158) loss_D_real: 0.828 loss_D_fake: 0.531 loss_D: 0.679 loss_G: 0.818 loss_eq: 1.893 loss_conv: 2.711 acc_real: 0.154 acc_fake: 0.850 
(epoch: 5, batches: 80, time: 0.003, data: 5.768) loss_D_real: 0.855 loss_D_fake: 0.525 loss_D: 0.690 loss_G: 0.795 loss_eq: 2.000 loss_conv: 2.795 acc_real: 0.109 acc_fake: 0.899 
(epoch: 5, batches: 100, time: 0.004, data: 4.160) loss_D_real: 0.828 loss_D_fake: 0.555 loss_D: 0.691 loss_G: 0.865 loss_eq: 1.932 loss_conv: 2.798 acc_real: 0.109 acc_fake: 0.899 
(epoch: 5, batches: 120, time: 0.004, data: 0.899) loss_D_real: 0.865 loss_D_fake: 0.527 loss_D: 0.696 loss_G: 0.871 loss_eq: 1.934 loss_conv: 2.806 acc_real: 0.109 acc_fake: 0.899 
(epoch: 5, batches: 140, time: 0.004, data: 5.916) loss_D_real: 0.823 loss_D_fake: 0.541 loss_D: 0.682 loss_G: 0.875 loss_eq: 1.897 loss_conv: 2.771 acc_real: 0.109 acc_fake: 0.899 
saving the model at the end of epoch 5, iters 49920
learning rate 0.0002000 -> 0.0001400
End of epoch 5 / 20 	 Time Taken: 664 sec
(epoch: 6, batches: 20, time: 0.007, data: 0.001) loss_D_real: 0.836 loss_D_fake: 0.524 loss_D: 0.680 loss_G: 0.824 loss_eq: 1.966 loss_conv: 2.791 acc_real: 0.109 acc_fake: 0.899 
(epoch: 6, batches: 40, time: 0.006, data: 0.001) loss_D_real: 0.836 loss_D_fake: 0.507 loss_D: 0.672 loss_G: 0.810 loss_eq: 1.937 loss_conv: 2.746 acc_real: 0.016 acc_fake: 0.988 
(epoch: 6, batches: 60, time: 0.003, data: 0.001) loss_D_real: 0.866 loss_D_fake: 0.481 loss_D: 0.673 loss_G: 0.867 loss_eq: 1.967 loss_conv: 2.834 acc_real: 0.016 acc_fake: 0.988 
(epoch: 6, batches: 80, time: 0.005, data: 0.001) loss_D_real: 0.801 loss_D_fake: 0.557 loss_D: 0.679 loss_G: 0.835 loss_eq: 1.966 loss_conv: 2.801 acc_real: 0.016 acc_fake: 0.988 
(epoch: 6, batches: 100, time: 0.003, data: 0.001) loss_D_real: 0.842 loss_D_fake: 0.507 loss_D: 0.674 loss_G: 0.849 loss_eq: 2.000 loss_conv: 2.849 acc_real: 0.016 acc_fake: 0.988 
(epoch: 6, batches: 120, time: 0.007, data: 0.001) loss_D_real: 0.865 loss_D_fake: 0.507 loss_D: 0.686 loss_G: 0.859 loss_eq: 1.967 loss_conv: 2.825 acc_real: 0.016 acc_fake: 0.988 
(epoch: 6, batches: 140, time: 0.005, data: 0.002) loss_D_real: 0.830 loss_D_fake: 0.516 loss_D: 0.673 loss_G: 0.832 loss_eq: 2.000 loss_conv: 2.832 acc_real: 0.008 acc_fake: 0.990 
learning rate 0.0001400 -> 0.0001400
End of epoch 6 / 20 	 Time Taken: 654 sec
(epoch: 7, batches: 20, time: 0.005, data: 0.045) loss_D_real: 0.855 loss_D_fake: 0.500 loss_D: 0.678 loss_G: 0.841 loss_eq: 1.966 loss_conv: 2.807 acc_real: 0.008 acc_fake: 0.990 
(epoch: 7, batches: 40, time: 0.004, data: 4.771) loss_D_real: 0.864 loss_D_fake: 0.486 loss_D: 0.675 loss_G: 0.850 loss_eq: 2.000 loss_conv: 2.850 acc_real: 0.008 acc_fake: 0.990 
(epoch: 7, batches: 60, time: 0.005, data: 0.001) loss_D_real: 0.857 loss_D_fake: 0.496 loss_D: 0.677 loss_G: 0.858 loss_eq: 2.000 loss_conv: 2.858 acc_real: 0.008 acc_fake: 0.990 
(epoch: 7, batches: 80, time: 0.005, data: 0.002) loss_D_real: 0.843 loss_D_fake: 0.518 loss_D: 0.681 loss_G: 0.846 loss_eq: 2.000 loss_conv: 2.846 acc_real: 0.003 acc_fake: 0.996 
(epoch: 7, batches: 100, time: 0.004, data: 0.001) loss_D_real: 0.843 loss_D_fake: 0.504 loss_D: 0.673 loss_G: 0.821 loss_eq: 2.000 loss_conv: 2.821 acc_real: 0.003 acc_fake: 0.996 
(epoch: 7, batches: 120, time: 0.005, data: 0.001) loss_D_real: 0.825 loss_D_fake: 0.542 loss_D: 0.684 loss_G: 0.823 loss_eq: 2.000 loss_conv: 2.823 acc_real: 0.003 acc_fake: 0.996 
(epoch: 7, batches: 140, time: 0.004, data: 0.001) loss_D_real: 0.863 loss_D_fake: 0.464 loss_D: 0.664 loss_G: 0.797 loss_eq: 1.967 loss_conv: 2.764 acc_real: 0.003 acc_fake: 0.996 
learning rate 0.0001400 -> 0.0001400
End of epoch 7 / 20 	 Time Taken: 659 sec
(epoch: 8, batches: 20, time: 0.005, data: 0.002) loss_D_real: 0.826 loss_D_fake: 0.523 loss_D: 0.674 loss_G: 0.839 loss_eq: 2.000 loss_conv: 2.839 acc_real: 0.007 acc_fake: 0.994 
(epoch: 8, batches: 40, time: 0.004, data: 1.935) loss_D_real: 0.864 loss_D_fake: 0.504 loss_D: 0.684 loss_G: 0.849 loss_eq: 2.000 loss_conv: 2.849 acc_real: 0.007 acc_fake: 0.994 
(epoch: 8, batches: 60, time: 0.006, data: 1.491) loss_D_real: 0.847 loss_D_fake: 0.507 loss_D: 0.677 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.007 acc_fake: 0.994 
(epoch: 8, batches: 80, time: 0.005, data: 0.002) loss_D_real: 0.858 loss_D_fake: 0.490 loss_D: 0.674 loss_G: 0.845 loss_eq: 1.934 loss_conv: 2.779 acc_real: 0.007 acc_fake: 0.994 
(epoch: 8, batches: 100, time: 0.005, data: 1.319) loss_D_real: 0.836 loss_D_fake: 0.514 loss_D: 0.675 loss_G: 0.862 loss_eq: 2.000 loss_conv: 2.862 acc_real: 0.007 acc_fake: 0.994 
(epoch: 8, batches: 120, time: 0.005, data: 3.159) loss_D_real: 0.858 loss_D_fake: 0.512 loss_D: 0.685 loss_G: 0.845 loss_eq: 2.000 loss_conv: 2.845 acc_real: 0.002 acc_fake: 0.998 
(epoch: 8, batches: 140, time: 0.003, data: 4.015) loss_D_real: 0.843 loss_D_fake: 0.509 loss_D: 0.676 loss_G: 0.830 loss_eq: 2.000 loss_conv: 2.830 acc_real: 0.002 acc_fake: 0.998 
learning rate 0.0001400 -> 0.0001400
End of epoch 8 / 20 	 Time Taken: 537 sec
(epoch: 9, batches: 20, time: 0.005, data: 0.002) loss_D_real: 0.865 loss_D_fake: 0.490 loss_D: 0.678 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.002 acc_fake: 0.998 
(epoch: 9, batches: 40, time: 0.006, data: 0.002) loss_D_real: 0.823 loss_D_fake: 0.527 loss_D: 0.675 loss_G: 0.858 loss_eq: 2.000 loss_conv: 2.858 acc_real: 0.002 acc_fake: 0.998 
(epoch: 9, batches: 60, time: 0.004, data: 0.002) loss_D_real: 0.814 loss_D_fake: 0.522 loss_D: 0.668 loss_G: 0.827 loss_eq: 1.967 loss_conv: 2.795 acc_real: 0.001 acc_fake: 0.999 
(epoch: 9, batches: 80, time: 0.005, data: 0.007) loss_D_real: 0.846 loss_D_fake: 0.511 loss_D: 0.679 loss_G: 0.832 loss_eq: 2.000 loss_conv: 2.832 acc_real: 0.001 acc_fake: 0.999 
(epoch: 9, batches: 100, time: 0.003, data: 0.355) loss_D_real: 0.847 loss_D_fake: 0.509 loss_D: 0.678 loss_G: 0.823 loss_eq: 2.000 loss_conv: 2.823 acc_real: 0.001 acc_fake: 0.999 
(epoch: 9, batches: 120, time: 0.005, data: 0.174) loss_D_real: 0.843 loss_D_fake: 0.511 loss_D: 0.677 loss_G: 0.842 loss_eq: 1.968 loss_conv: 2.810 acc_real: 0.001 acc_fake: 0.999 
(epoch: 9, batches: 140, time: 0.004, data: 0.001) loss_D_real: 0.830 loss_D_fake: 0.528 loss_D: 0.679 loss_G: 0.835 loss_eq: 1.966 loss_conv: 2.801 acc_real: 0.001 acc_fake: 0.999 
learning rate 0.0001400 -> 0.0001400
End of epoch 9 / 20 	 Time Taken: 439 sec
(epoch: 10, batches: 20, time: 0.003, data: 9.206) loss_D_real: 0.836 loss_D_fake: 0.519 loss_D: 0.678 loss_G: 0.836 loss_eq: 2.000 loss_conv: 2.836 acc_real: 0.001 acc_fake: 1.000 
(epoch: 10, batches: 40, time: 0.004, data: 8.548) loss_D_real: 0.828 loss_D_fake: 0.518 loss_D: 0.673 loss_G: 0.844 loss_eq: 2.000 loss_conv: 2.844 acc_real: 0.001 acc_fake: 1.000 
(epoch: 10, batches: 60, time: 0.004, data: 6.930) loss_D_real: 0.836 loss_D_fake: 0.502 loss_D: 0.669 loss_G: 0.847 loss_eq: 2.000 loss_conv: 2.847 acc_real: 0.001 acc_fake: 1.000 
(epoch: 10, batches: 80, time: 0.005, data: 4.988) loss_D_real: 0.822 loss_D_fake: 0.529 loss_D: 0.675 loss_G: 0.830 loss_eq: 1.968 loss_conv: 2.798 acc_real: 0.001 acc_fake: 1.000 
(epoch: 10, batches: 100, time: 0.004, data: 8.018) loss_D_real: 0.838 loss_D_fake: 0.521 loss_D: 0.680 loss_G: 0.837 loss_eq: 2.000 loss_conv: 2.837 acc_real: 0.030 acc_fake: 0.971 
(epoch: 10, batches: 120, time: 0.004, data: 8.774) loss_D_real: 0.834 loss_D_fake: 0.520 loss_D: 0.677 loss_G: 0.833 loss_eq: 2.000 loss_conv: 2.833 acc_real: 0.030 acc_fake: 0.971 
(epoch: 10, batches: 140, time: 0.005, data: 7.292) loss_D_real: 0.864 loss_D_fake: 0.493 loss_D: 0.679 loss_G: 0.833 loss_eq: 2.000 loss_conv: 2.833 acc_real: 0.030 acc_fake: 0.971 
saving the model at the end of epoch 10, iters 99840
learning rate 0.0001400 -> 0.0000980
End of epoch 10 / 20 	 Time Taken: 436 sec
(epoch: 11, batches: 20, time: 0.004, data: 0.002) loss_D_real: 0.814 loss_D_fake: 0.520 loss_D: 0.667 loss_G: 0.830 loss_eq: 1.967 loss_conv: 2.797 acc_real: 0.030 acc_fake: 0.971 
(epoch: 11, batches: 40, time: 0.007, data: 0.002) loss_D_real: 0.844 loss_D_fake: 0.501 loss_D: 0.672 loss_G: 0.839 loss_eq: 2.000 loss_conv: 2.839 acc_real: 0.030 acc_fake: 0.971 
(epoch: 11, batches: 60, time: 0.005, data: 0.002) loss_D_real: 0.845 loss_D_fake: 0.492 loss_D: 0.669 loss_G: 0.855 loss_eq: 2.000 loss_conv: 2.855 acc_real: 0.001 acc_fake: 1.000 
(epoch: 11, batches: 80, time: 0.004, data: 0.002) loss_D_real: 0.839 loss_D_fake: 0.524 loss_D: 0.682 loss_G: 0.840 loss_eq: 1.966 loss_conv: 2.806 acc_real: 0.001 acc_fake: 1.000 
(epoch: 11, batches: 100, time: 0.005, data: 0.002) loss_D_real: 0.851 loss_D_fake: 0.505 loss_D: 0.678 loss_G: 0.836 loss_eq: 2.000 loss_conv: 2.836 acc_real: 0.001 acc_fake: 1.000 
(epoch: 11, batches: 120, time: 0.005, data: 0.001) loss_D_real: 0.825 loss_D_fake: 0.539 loss_D: 0.682 loss_G: 0.825 loss_eq: 1.967 loss_conv: 2.792 acc_real: 0.001 acc_fake: 1.000 
(epoch: 11, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.835 loss_D_fake: 0.519 loss_D: 0.677 loss_G: 0.844 loss_eq: 1.965 loss_conv: 2.809 acc_real: 0.001 acc_fake: 1.000 
learning rate 0.0000980 -> 0.0000980
End of epoch 11 / 20 	 Time Taken: 437 sec
(epoch: 12, batches: 20, time: 0.003, data: 0.002) loss_D_real: 0.860 loss_D_fake: 0.491 loss_D: 0.676 loss_G: 0.798 loss_eq: 1.967 loss_conv: 2.765 acc_real: 0.003 acc_fake: 0.998 
(epoch: 12, batches: 40, time: 0.003, data: 0.002) loss_D_real: 0.835 loss_D_fake: 0.509 loss_D: 0.672 loss_G: 0.843 loss_eq: 1.967 loss_conv: 2.811 acc_real: 0.003 acc_fake: 0.998 
(epoch: 12, batches: 60, time: 0.005, data: 0.007) loss_D_real: 0.845 loss_D_fake: 0.500 loss_D: 0.673 loss_G: 0.849 loss_eq: 1.932 loss_conv: 2.781 acc_real: 0.003 acc_fake: 0.998 
(epoch: 12, batches: 80, time: 0.003, data: 0.002) loss_D_real: 0.842 loss_D_fake: 0.507 loss_D: 0.675 loss_G: 0.852 loss_eq: 2.000 loss_conv: 2.852 acc_real: 0.003 acc_fake: 0.998 
(epoch: 12, batches: 100, time: 0.005, data: 0.002) loss_D_real: 0.846 loss_D_fake: 0.517 loss_D: 0.681 loss_G: 0.847 loss_eq: 1.966 loss_conv: 2.813 acc_real: 0.003 acc_fake: 0.995 
(epoch: 12, batches: 120, time: 0.005, data: 0.002) loss_D_real: 0.824 loss_D_fake: 0.522 loss_D: 0.673 loss_G: 0.830 loss_eq: 1.932 loss_conv: 2.762 acc_real: 0.003 acc_fake: 0.995 
(epoch: 12, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.847 loss_D_fake: 0.504 loss_D: 0.675 loss_G: 0.866 loss_eq: 2.000 loss_conv: 2.866 acc_real: 0.003 acc_fake: 0.995 
learning rate 0.0000980 -> 0.0000980
End of epoch 12 / 20 	 Time Taken: 437 sec
(epoch: 13, batches: 20, time: 0.004, data: 0.185) loss_D_real: 0.857 loss_D_fake: 0.508 loss_D: 0.682 loss_G: 0.856 loss_eq: 2.000 loss_conv: 2.856 acc_real: 0.003 acc_fake: 0.995 
(epoch: 13, batches: 40, time: 0.004, data: 0.002) loss_D_real: 0.851 loss_D_fake: 0.490 loss_D: 0.670 loss_G: 0.855 loss_eq: 2.000 loss_conv: 2.855 acc_real: 0.006 acc_fake: 0.996 
(epoch: 13, batches: 60, time: 0.005, data: 0.001) loss_D_real: 0.822 loss_D_fake: 0.524 loss_D: 0.673 loss_G: 0.826 loss_eq: 2.000 loss_conv: 2.826 acc_real: 0.006 acc_fake: 0.996 
(epoch: 13, batches: 80, time: 0.004, data: 0.002) loss_D_real: 0.831 loss_D_fake: 0.520 loss_D: 0.676 loss_G: 0.819 loss_eq: 2.000 loss_conv: 2.819 acc_real: 0.006 acc_fake: 0.996 
(epoch: 13, batches: 100, time: 0.006, data: 0.002) loss_D_real: 0.826 loss_D_fake: 0.509 loss_D: 0.668 loss_G: 0.835 loss_eq: 2.000 loss_conv: 2.835 acc_real: 0.006 acc_fake: 0.996 
(epoch: 13, batches: 120, time: 0.006, data: 1.141) loss_D_real: 0.829 loss_D_fake: 0.528 loss_D: 0.679 loss_G: 0.817 loss_eq: 2.000 loss_conv: 2.817 acc_real: 0.006 acc_fake: 0.996 
(epoch: 13, batches: 140, time: 0.005, data: 1.563) loss_D_real: 0.825 loss_D_fake: 0.514 loss_D: 0.669 loss_G: 0.844 loss_eq: 2.000 loss_conv: 2.844 acc_real: 0.002 acc_fake: 0.999 
learning rate 0.0000980 -> 0.0000980
End of epoch 13 / 20 	 Time Taken: 442 sec
(epoch: 14, batches: 20, time: 0.004, data: 0.005) loss_D_real: 0.837 loss_D_fake: 0.511 loss_D: 0.674 loss_G: 0.829 loss_eq: 2.000 loss_conv: 2.829 acc_real: 0.002 acc_fake: 0.999 
(epoch: 14, batches: 40, time: 0.004, data: 0.018) loss_D_real: 0.839 loss_D_fake: 0.513 loss_D: 0.676 loss_G: 0.831 loss_eq: 2.000 loss_conv: 2.831 acc_real: 0.002 acc_fake: 0.999 
(epoch: 14, batches: 60, time: 0.004, data: 0.002) loss_D_real: 0.851 loss_D_fake: 0.516 loss_D: 0.683 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.002 acc_fake: 0.999 
(epoch: 14, batches: 80, time: 0.004, data: 0.494) loss_D_real: 0.834 loss_D_fake: 0.512 loss_D: 0.673 loss_G: 0.856 loss_eq: 1.967 loss_conv: 2.823 acc_real: 0.000 acc_fake: 1.000 
(epoch: 14, batches: 100, time: 0.004, data: 0.895) loss_D_real: 0.845 loss_D_fake: 0.514 loss_D: 0.680 loss_G: 0.839 loss_eq: 2.000 loss_conv: 2.839 acc_real: 0.000 acc_fake: 1.000 
(epoch: 14, batches: 120, time: 0.004, data: 0.015) loss_D_real: 0.832 loss_D_fake: 0.512 loss_D: 0.672 loss_G: 0.842 loss_eq: 2.000 loss_conv: 2.842 acc_real: 0.000 acc_fake: 1.000 
(epoch: 14, batches: 140, time: 0.004, data: 0.049) loss_D_real: 0.838 loss_D_fake: 0.512 loss_D: 0.675 loss_G: 0.863 loss_eq: 1.966 loss_conv: 2.829 acc_real: 0.000 acc_fake: 1.000 
learning rate 0.0000980 -> 0.0000980
End of epoch 14 / 20 	 Time Taken: 441 sec
(epoch: 15, batches: 20, time: 0.004, data: 8.886) loss_D_real: 0.866 loss_D_fake: 0.483 loss_D: 0.675 loss_G: 0.849 loss_eq: 2.000 loss_conv: 2.849 acc_real: 0.000 acc_fake: 1.000 
(epoch: 15, batches: 40, time: 0.003, data: 8.843) loss_D_real: 0.832 loss_D_fake: 0.515 loss_D: 0.674 loss_G: 0.844 loss_eq: 2.000 loss_conv: 2.844 acc_real: 0.000 acc_fake: 1.000 
(epoch: 15, batches: 60, time: 0.005, data: 9.683) loss_D_real: 0.857 loss_D_fake: 0.488 loss_D: 0.672 loss_G: 0.866 loss_eq: 1.966 loss_conv: 2.832 acc_real: 0.000 acc_fake: 1.000 
(epoch: 15, batches: 80, time: 0.005, data: 9.316) loss_D_real: 0.837 loss_D_fake: 0.511 loss_D: 0.674 loss_G: 0.826 loss_eq: 1.934 loss_conv: 2.760 acc_real: 0.000 acc_fake: 1.000 
(epoch: 15, batches: 100, time: 0.005, data: 8.249) loss_D_real: 0.830 loss_D_fake: 0.516 loss_D: 0.673 loss_G: 0.835 loss_eq: 2.000 loss_conv: 2.835 acc_real: 0.000 acc_fake: 1.000 
(epoch: 15, batches: 120, time: 0.006, data: 6.979) loss_D_real: 0.820 loss_D_fake: 0.542 loss_D: 0.681 loss_G: 0.814 loss_eq: 2.000 loss_conv: 2.814 acc_real: 0.011 acc_fake: 0.988 
(epoch: 15, batches: 140, time: 0.005, data: 8.872) loss_D_real: 0.849 loss_D_fake: 0.497 loss_D: 0.673 loss_G: 0.865 loss_eq: 2.000 loss_conv: 2.865 acc_real: 0.011 acc_fake: 0.988 
saving the model at the end of epoch 15, iters 149760
learning rate 0.0000980 -> 0.0000686
End of epoch 15 / 20 	 Time Taken: 436 sec
(epoch: 16, batches: 20, time: 0.003, data: 0.007) loss_D_real: 0.835 loss_D_fake: 0.514 loss_D: 0.675 loss_G: 0.830 loss_eq: 1.968 loss_conv: 2.798 acc_real: 0.011 acc_fake: 0.988 
(epoch: 16, batches: 40, time: 0.006, data: 0.002) loss_D_real: 0.832 loss_D_fake: 0.521 loss_D: 0.676 loss_G: 0.832 loss_eq: 1.968 loss_conv: 2.801 acc_real: 0.011 acc_fake: 0.988 
(epoch: 16, batches: 60, time: 0.005, data: 0.002) loss_D_real: 0.833 loss_D_fake: 0.510 loss_D: 0.672 loss_G: 0.828 loss_eq: 2.000 loss_conv: 2.828 acc_real: 0.011 acc_fake: 0.988 
(epoch: 16, batches: 80, time: 0.005, data: 0.002) loss_D_real: 0.837 loss_D_fake: 0.513 loss_D: 0.675 loss_G: 0.829 loss_eq: 1.967 loss_conv: 2.796 acc_real: 0.001 acc_fake: 1.000 
(epoch: 16, batches: 100, time: 0.006, data: 0.002) loss_D_real: 0.846 loss_D_fake: 0.496 loss_D: 0.671 loss_G: 0.848 loss_eq: 2.000 loss_conv: 2.848 acc_real: 0.001 acc_fake: 1.000 
(epoch: 16, batches: 120, time: 0.005, data: 0.002) loss_D_real: 0.841 loss_D_fake: 0.508 loss_D: 0.675 loss_G: 0.845 loss_eq: 2.000 loss_conv: 2.845 acc_real: 0.001 acc_fake: 1.000 
(epoch: 16, batches: 140, time: 0.005, data: 0.002) loss_D_real: 0.839 loss_D_fake: 0.507 loss_D: 0.673 loss_G: 0.829 loss_eq: 1.935 loss_conv: 2.764 acc_real: 0.001 acc_fake: 1.000 
learning rate 0.0000686 -> 0.0000686
End of epoch 16 / 20 	 Time Taken: 437 sec
(epoch: 17, batches: 20, time: 0.004, data: 0.128) loss_D_real: 0.826 loss_D_fake: 0.521 loss_D: 0.674 loss_G: 0.835 loss_eq: 2.000 loss_conv: 2.835 acc_real: 0.001 acc_fake: 1.000 
(epoch: 17, batches: 40, time: 0.005, data: 0.002) loss_D_real: 0.837 loss_D_fake: 0.511 loss_D: 0.674 loss_G: 0.828 loss_eq: 1.966 loss_conv: 2.794 acc_real: 0.001 acc_fake: 1.000 
(epoch: 17, batches: 60, time: 0.004, data: 0.002) loss_D_real: 0.833 loss_D_fake: 0.508 loss_D: 0.671 loss_G: 0.843 loss_eq: 2.000 loss_conv: 2.843 acc_real: 0.001 acc_fake: 1.000 
(epoch: 17, batches: 80, time: 0.005, data: 0.002) loss_D_real: 0.843 loss_D_fake: 0.502 loss_D: 0.672 loss_G: 0.849 loss_eq: 2.000 loss_conv: 2.849 acc_real: 0.001 acc_fake: 1.000 
(epoch: 17, batches: 100, time: 0.005, data: 0.002) loss_D_real: 0.851 loss_D_fake: 0.505 loss_D: 0.678 loss_G: 0.827 loss_eq: 2.000 loss_conv: 2.827 acc_real: 0.001 acc_fake: 1.000 
(epoch: 17, batches: 120, time: 0.005, data: 0.002) loss_D_real: 0.815 loss_D_fake: 0.526 loss_D: 0.670 loss_G: 0.819 loss_eq: 2.000 loss_conv: 2.819 acc_real: 0.000 acc_fake: 1.000 
(epoch: 17, batches: 140, time: 0.004, data: 0.002) loss_D_real: 0.833 loss_D_fake: 0.519 loss_D: 0.676 loss_G: 0.846 loss_eq: 2.000 loss_conv: 2.846 acc_real: 0.000 acc_fake: 1.000 
learning rate 0.0000686 -> 0.0000686
End of epoch 17 / 20 	 Time Taken: 444 sec
(epoch: 18, batches: 20, time: 0.003, data: 0.001) loss_D_real: 0.848 loss_D_fake: 0.509 loss_D: 0.679 loss_G: 0.835 loss_eq: 1.968 loss_conv: 2.803 acc_real: 0.000 acc_fake: 1.000 
(epoch: 18, batches: 40, time: 0.006, data: 0.002) loss_D_real: 0.832 loss_D_fake: 0.506 loss_D: 0.669 loss_G: 0.839 loss_eq: 2.000 loss_conv: 2.839 acc_real: 0.000 acc_fake: 1.000 
(epoch: 18, batches: 60, time: 0.003, data: 0.007) loss_D_real: 0.845 loss_D_fake: 0.492 loss_D: 0.668 loss_G: 0.856 loss_eq: 2.000 loss_conv: 2.856 acc_real: 0.000 acc_fake: 1.000 
(epoch: 18, batches: 80, time: 0.005, data: 0.002) loss_D_real: 0.843 loss_D_fake: 0.509 loss_D: 0.676 loss_G: 0.840 loss_eq: 2.000 loss_conv: 2.840 acc_real: 0.000 acc_fake: 1.000 
(epoch: 18, batches: 100, time: 0.004, data: 0.001) loss_D_real: 0.839 loss_D_fake: 0.502 loss_D: 0.671 loss_G: 0.811 loss_eq: 2.000 loss_conv: 2.811 acc_real: 0.000 acc_fake: 1.000 
(epoch: 18, batches: 120, time: 0.004, data: 0.002) loss_D_real: 0.833 loss_D_fake: 0.513 loss_D: 0.673 loss_G: 0.835 loss_eq: 2.000 loss_conv: 2.835 acc_real: 0.000 acc_fake: 1.000 
(epoch: 18, batches: 140, time: 0.003, data: 0.002) loss_D_real: 0.843 loss_D_fake: 0.510 loss_D: 0.676 loss_G: 0.830 loss_eq: 2.000 loss_conv: 2.830 acc_real: 0.000 acc_fake: 1.000 
learning rate 0.0000686 -> 0.0000686
End of epoch 18 / 20 	 Time Taken: 441 sec
(epoch: 19, batches: 20, time: 0.006, data: 0.006) loss_D_real: 0.849 loss_D_fake: 0.507 loss_D: 0.678 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.001 acc_fake: 0.999 
(epoch: 19, batches: 40, time: 0.004, data: 0.002) loss_D_real: 0.852 loss_D_fake: 0.501 loss_D: 0.676 loss_G: 0.833 loss_eq: 2.000 loss_conv: 2.833 acc_real: 0.001 acc_fake: 0.999 
(epoch: 19, batches: 60, time: 0.006, data: 0.002) loss_D_real: 0.843 loss_D_fake: 0.508 loss_D: 0.675 loss_G: 0.839 loss_eq: 2.000 loss_conv: 2.839 acc_real: 0.001 acc_fake: 0.999 
(epoch: 19, batches: 80, time: 0.003, data: 0.002) loss_D_real: 0.836 loss_D_fake: 0.508 loss_D: 0.672 loss_G: 0.830 loss_eq: 1.966 loss_conv: 2.795 acc_real: 0.001 acc_fake: 0.999 
(epoch: 19, batches: 100, time: 0.006, data: 0.002) loss_D_real: 0.833 loss_D_fake: 0.515 loss_D: 0.674 loss_G: 0.838 loss_eq: 2.000 loss_conv: 2.838 acc_real: 0.001 acc_fake: 0.999 
(epoch: 19, batches: 120, time: 0.004, data: 0.002) loss_D_real: 0.844 loss_D_fake: 0.509 loss_D: 0.676 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.001 acc_fake: 0.999 
(epoch: 19, batches: 140, time: 0.004, data: 0.002) loss_D_real: 0.834 loss_D_fake: 0.508 loss_D: 0.671 loss_G: 0.827 loss_eq: 1.967 loss_conv: 2.794 acc_real: 0.001 acc_fake: 0.999 
learning rate 0.0000686 -> 0.0000686
End of epoch 19 / 20 	 Time Taken: 435 sec
(epoch: 20, batches: 20, time: 0.004, data: 10.125) loss_D_real: 0.840 loss_D_fake: 0.512 loss_D: 0.676 loss_G: 0.824 loss_eq: 1.967 loss_conv: 2.791 acc_real: 0.001 acc_fake: 0.999 
(epoch: 20, batches: 40, time: 0.005, data: 9.585) loss_D_real: 0.836 loss_D_fake: 0.521 loss_D: 0.678 loss_G: 0.837 loss_eq: 1.968 loss_conv: 2.805 acc_real: 0.001 acc_fake: 0.999 
(epoch: 20, batches: 60, time: 0.004, data: 9.927) loss_D_real: 0.842 loss_D_fake: 0.506 loss_D: 0.674 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.001 acc_fake: 0.999 
(epoch: 20, batches: 80, time: 0.005, data: 9.930) loss_D_real: 0.845 loss_D_fake: 0.497 loss_D: 0.671 loss_G: 0.826 loss_eq: 2.000 loss_conv: 2.826 acc_real: 0.001 acc_fake: 0.999 
(epoch: 20, batches: 100, time: 0.005, data: 7.645) loss_D_real: 0.841 loss_D_fake: 0.507 loss_D: 0.674 loss_G: 0.827 loss_eq: 2.000 loss_conv: 2.827 acc_real: 0.001 acc_fake: 0.999 
(epoch: 20, batches: 120, time: 0.005, data: 6.817) loss_D_real: 0.835 loss_D_fake: 0.516 loss_D: 0.675 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.001 acc_fake: 0.999 
(epoch: 20, batches: 140, time: 0.003, data: 5.448) loss_D_real: 0.836 loss_D_fake: 0.516 loss_D: 0.676 loss_G: 0.841 loss_eq: 2.000 loss_conv: 2.841 acc_real: 0.000 acc_fake: 1.000 
saving the model at the end of epoch 20, iters 199680
learning rate 0.0000686 -> 0.0000480
End of epoch 20 / 20 	 Time Taken: 441 sec
Finished training, model is saved
Batches trained - G: 2080, D: 1040 
