starting ROOM training run 1
Tar file moved to scratch
Current time : 19:22:04

Tar file extracted on scratch
Current time : 19:22:11

Validation tar copied to scratch
Current time : 19:22:11

validation tar extracted on scratch
Current time : 19:22:11

----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/ROOM/images/	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
            flip_vertical: False                         
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 64                            	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: 10000                         	[default: inf]
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 10                            	[default: 20]
           n_epochs_decay: 5                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN_room                  	[default: CopyGAN]
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
             no_alternate: True                          	[default: False]
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: True                          	[default: False]
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            	[default: 0]
           serial_batches: False                         
               sigma_blur: 0.0                           	[default: 1.0]
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 200                           	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
----------------- Options ---------------
              D_headstart: 0                             
              D_threshold: 0.5                           
       accumulation_steps: 1                             
               batch_size: 64                            
                    beta1: 0.5                           
                    beta2: 0.999                         
          checkpoints_dir: /scratch/checkpoints          	[default: ./checkpoints]
        confidence_weight: 1.0                           	[default: 0.0]
           continue_train: False                         
                crop_size: 64                            
                 dataroot: /scratch/datasets/ROOM/images/	[default: datasets]
             dataset_mode: double                        
                direction: None                          
              display_env: main                          
             display_freq: 100                           
               display_id: 0                             	[default: 1]
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
            flip_vertical: False                         
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
          keep_last_batch: False                         
               lambda_aux: 0.1                           
                load_iter: 0                             	[default: 0]
                load_size: 64                            	[default: 70]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: step                          
         max_dataset_size: 10000                         	[default: inf]
                    model: copypasteGAN                  	[default: cycle_gan]
                 n_epochs: 10                            	[default: 20]
           n_epochs_decay: 5                             	[default: 10]
               n_layers_D: 3                             
                     name: CopyGAN_room                  	[default: CopyGAN]
                      ndf: 64                            
                     netD: copy                          
                     netG: copy                          
                      ngf: 64                            
             no_alternate: True                          	[default: False]
        no_border_zeroing: False                         
               no_dropout: False                         
                  no_flip: False                         
               no_grfakes: False                         
                  no_html: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                  patch_D: True                          	[default: False]
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 20                            
              real_target: 0.8                           
             save_by_iter: False                         
          save_epoch_freq: 5                             	[default: 10]
         save_latest_freq: 5000                          
                     seed: 42                            	[default: 0]
           serial_batches: False                         
               sigma_blur: 0.0                           	[default: 1.0]
                   suffix:                               
              tracemalloc: False                         
         update_html_freq: 100                           
           val_batch_size: 128                           
                 val_freq: 200                           	[default: 100]
                  verbose: True                          	[default: False]
----------------- End -------------------
dataset [DoubleDataset] and dataloder are created
dataset [DoubleDataset] and dataloder are created
The number of training images = 10000
The number of validation images = 1111
The number of epochs to run = 15
initialize network with normal
initialize network with normal
model [CopyPasteGANModel] was created
---------- Networks initialized -------------
DataParallel(
  (module): CopyGenerator(
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (sigmoid): Sigmoid()
  )
)
[Network G] Total number of parameters : 3.469 M
DataParallel(
  (module): CopyDiscriminator(
    (enc1): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc2): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc3): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (enc4): EncoderBlock(
      (model): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec4): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec3): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec2): DecoderBlock(
      (model): Sequential(
        (0): Upsample(scale_factor=2.0, mode=bilinear)
        (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): LeakyReLU(negative_slope=0.2, inplace=True)
      )
    )
    (dec1): DecoderBlock(
      (model): Sequential(
        (0): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (sigmoid): Sigmoid()
    (patch_conv): Sequential(
      (0): EncoderBlock(
        (model): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (2): LeakyReLU(negative_slope=0.2, inplace=True)
        )
      )
      (1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (patch_fc): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=16, out_features=1, bias=True)
      (2): Sigmoid()
    )
  )
)
[Network D] Total number of parameters : 4.060 M
-----------------------------------------------
create web directory /scratch/checkpoints/CopyGAN_room/web...
validation accuracies:
                gf: 0.34
                real: 0.63
                fake: 0.37

ran validation set (B:1) in                         12.3 s.
(epoch: 1, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.832 loss_D_fake: 0.481 loss_D: 2.061 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.245 loss_D_gr_fake: 0.503 acc_grfake: 0.345 
(epoch: 1, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.797 loss_D_fake: 0.454 loss_D: 2.034 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.275 loss_D_gr_fake: 0.508 acc_grfake: 0.345 
(epoch: 1, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.836 loss_D_fake: 0.379 loss_D: 1.948 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.302 loss_D_gr_fake: 0.431 acc_grfake: 0.345 
(epoch: 1, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.746 loss_D_fake: 0.321 loss_D: 1.828 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.318 loss_D_gr_fake: 0.443 acc_grfake: 0.345 
(epoch: 1, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.721 loss_D_fake: 0.316 loss_D: 1.770 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.334 loss_D_gr_fake: 0.400 acc_grfake: 0.345 
(epoch: 1, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.635 loss_D_fake: 0.346 loss_D: 1.833 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.350 loss_D_gr_fake: 0.503 acc_grfake: 0.345 
(epoch: 1, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.653 loss_D_fake: 0.323 loss_D: 1.737 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.352 loss_D_gr_fake: 0.408 acc_grfake: 0.345 
learning rate 0.0002000 -> 0.0002000
End of epoch 1 / 15 	 Time Taken: 83 sec
/home/tlotze/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
(epoch: 2, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.687 loss_D_fake: 0.155 loss_D: 1.514 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.372 loss_D_gr_fake: 0.300 acc_grfake: 0.345 
(epoch: 2, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.000 loss_G_anti_sc: 0.000 loss_G: 0.000 loss_D_real: 0.569 loss_D_fake: 0.243 loss_D: 1.604 acc_real: 0.630 acc_fake: 0.372 loss_G_conf: 0.000 loss_AUX: 0.367 loss_D_gr_fake: 0.426 acc_grfake: 0.345 
validation accuracies:
                gf: 0.91
                real: 0.71
                fake: 0.98

ran validation set (B:201) in                         11.7 s.
(epoch: 2, batches: 60, time: 0.005, data: 0.003) loss_G_comp: 1.158 loss_G_anti_sc: 0.381 loss_G: 1.659 loss_D_real: 0.595 loss_D_fake: 0.212 loss_D: 1.576 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.119 loss_AUX: 0.373 loss_D_gr_fake: 0.396 acc_grfake: 0.907 
(epoch: 2, batches: 80, time: 0.005, data: 0.003) loss_G_comp: 1.034 loss_G_anti_sc: 0.528 loss_G: 1.643 loss_D_real: 0.595 loss_D_fake: 0.212 loss_D: 1.576 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.081 loss_AUX: 0.373 loss_D_gr_fake: 0.396 acc_grfake: 0.907 
(epoch: 2, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 0.971 loss_G_anti_sc: 0.538 loss_G: 1.578 loss_D_real: 0.595 loss_D_fake: 0.212 loss_D: 1.576 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.069 loss_AUX: 0.373 loss_D_gr_fake: 0.396 acc_grfake: 0.907 
(epoch: 2, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.968 loss_G_anti_sc: 0.521 loss_G: 1.560 loss_D_real: 0.595 loss_D_fake: 0.212 loss_D: 1.576 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.070 loss_AUX: 0.373 loss_D_gr_fake: 0.396 acc_grfake: 0.907 
(epoch: 2, batches: 140, time: 0.005, data: 0.003) loss_G_comp: 0.989 loss_G_anti_sc: 0.501 loss_G: 1.546 loss_D_real: 0.595 loss_D_fake: 0.212 loss_D: 1.576 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.056 loss_AUX: 0.373 loss_D_gr_fake: 0.396 acc_grfake: 0.907 
learning rate 0.0002000 -> 0.0002000
End of epoch 2 / 15 	 Time Taken: 67 sec
(epoch: 3, batches: 20, time: 0.005, data: 0.003) loss_G_comp: 0.813 loss_G_anti_sc: 0.503 loss_G: 1.361 loss_D_real: 0.826 loss_D_fake: 0.560 loss_D: 2.213 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.045 loss_AUX: 0.306 loss_D_gr_fake: 0.520 acc_grfake: 0.907 
(epoch: 3, batches: 40, time: 0.005, data: 0.003) loss_G_comp: 0.791 loss_G_anti_sc: 0.499 loss_G: 1.328 loss_D_real: 0.836 loss_D_fake: 0.590 loss_D: 2.225 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.038 loss_AUX: 0.284 loss_D_gr_fake: 0.515 acc_grfake: 0.907 
(epoch: 3, batches: 60, time: 0.005, data: 0.003) loss_G_comp: 0.777 loss_G_anti_sc: 0.485 loss_G: 1.297 loss_D_real: 0.840 loss_D_fake: 0.594 loss_D: 2.229 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.035 loss_AUX: 0.295 loss_D_gr_fake: 0.500 acc_grfake: 0.907 
(epoch: 3, batches: 80, time: 0.005, data: 0.003) loss_G_comp: 0.756 loss_G_anti_sc: 0.485 loss_G: 1.279 loss_D_real: 0.834 loss_D_fake: 0.625 loss_D: 2.259 acc_real: 0.715 acc_fake: 0.979 loss_G_conf: 0.037 loss_AUX: 0.310 loss_D_gr_fake: 0.491 acc_grfake: 0.907 
validation accuracies:
                gf: 0.93
                real: 0.11
                fake: 0.52

ran validation set (B:401) in                         11.7 s.
(epoch: 3, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 0.780 loss_G_anti_sc: 0.479 loss_G: 1.292 loss_D_real: 0.846 loss_D_fake: 0.637 loss_D: 2.273 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.033 loss_AUX: 0.304 loss_D_gr_fake: 0.486 acc_grfake: 0.928 
(epoch: 3, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.744 loss_G_anti_sc: 0.501 loss_G: 1.272 loss_D_real: 0.846 loss_D_fake: 0.637 loss_D: 2.273 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.027 loss_AUX: 0.304 loss_D_gr_fake: 0.486 acc_grfake: 0.928 
(epoch: 3, batches: 140, time: 0.005, data: 0.003) loss_G_comp: 0.749 loss_G_anti_sc: 0.491 loss_G: 1.264 loss_D_real: 0.846 loss_D_fake: 0.637 loss_D: 2.273 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.024 loss_AUX: 0.304 loss_D_gr_fake: 0.486 acc_grfake: 0.928 
learning rate 0.0002000 -> 0.0002000
End of epoch 3 / 15 	 Time Taken: 66 sec
(epoch: 4, batches: 20, time: 0.005, data: 0.003) loss_G_comp: 0.739 loss_G_anti_sc: 0.479 loss_G: 1.244 loss_D_real: 0.846 loss_D_fake: 0.637 loss_D: 2.273 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.026 loss_AUX: 0.304 loss_D_gr_fake: 0.486 acc_grfake: 0.928 
(epoch: 4, batches: 40, time: 0.005, data: 0.003) loss_G_comp: 1.132 loss_G_anti_sc: 0.288 loss_G: 1.460 loss_D_real: 1.442 loss_D_fake: 0.390 loss_D: 2.451 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.039 loss_AUX: 0.342 loss_D_gr_fake: 0.277 acc_grfake: 0.928 
(epoch: 4, batches: 60, time: 0.005, data: 0.003) loss_G_comp: 0.728 loss_G_anti_sc: 0.447 loss_G: 1.198 loss_D_real: 0.925 loss_D_fake: 0.715 loss_D: 2.408 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.023 loss_AUX: 0.314 loss_D_gr_fake: 0.454 acc_grfake: 0.928 
(epoch: 4, batches: 80, time: 0.005, data: 0.003) loss_G_comp: 0.728 loss_G_anti_sc: 0.441 loss_G: 1.194 loss_D_real: 0.914 loss_D_fake: 0.736 loss_D: 2.429 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.025 loss_AUX: 0.317 loss_D_gr_fake: 0.463 acc_grfake: 0.928 
(epoch: 4, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 0.735 loss_G_anti_sc: 0.425 loss_G: 1.182 loss_D_real: 0.876 loss_D_fake: 0.738 loss_D: 2.441 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.022 loss_AUX: 0.348 loss_D_gr_fake: 0.479 acc_grfake: 0.928 
(epoch: 4, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.711 loss_G_anti_sc: 0.457 loss_G: 1.188 loss_D_real: 0.886 loss_D_fake: 0.731 loss_D: 2.399 acc_real: 0.106 acc_fake: 0.521 loss_G_conf: 0.020 loss_AUX: 0.318 loss_D_gr_fake: 0.464 acc_grfake: 0.928 
validation accuracies:
                gf: 0.92
                real: 0.11
                fake: 0.38

ran validation set (B:601) in                         11.8 s.
(epoch: 4, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.832 loss_D_fake: 0.808 loss_D: 2.472 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.336 loss_D_gr_fake: 0.495 acc_grfake: 0.924 
learning rate 0.0002000 -> 0.0002000
End of epoch 4 / 15 	 Time Taken: 70 sec
(epoch: 5, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.807 loss_D_fake: 0.734 loss_D: 2.364 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.336 loss_D_gr_fake: 0.488 acc_grfake: 0.924 
(epoch: 5, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.788 loss_D_fake: 0.719 loss_D: 2.318 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.337 loss_D_gr_fake: 0.475 acc_grfake: 0.924 
(epoch: 5, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.758 loss_D_fake: 0.734 loss_D: 2.315 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.354 loss_D_gr_fake: 0.469 acc_grfake: 0.924 
(epoch: 5, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.755 loss_D_fake: 0.740 loss_D: 2.266 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.354 loss_D_gr_fake: 0.417 acc_grfake: 0.924 
(epoch: 5, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.720 loss_D_fake: 0.740 loss_D: 2.238 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.322 loss_D_gr_fake: 0.456 acc_grfake: 0.924 
(epoch: 5, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.724 loss_D_fake: 0.793 loss_D: 2.259 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.346 loss_D_gr_fake: 0.397 acc_grfake: 0.924 
(epoch: 5, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.725 loss_D_fake: 0.713 loss_D: 2.144 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.341 loss_D_gr_fake: 0.365 acc_grfake: 0.924 
saving the model at the end of epoch 5, iters 49920
learning rate 0.0002000 -> 0.0002000
End of epoch 5 / 15 	 Time Taken: 70 sec
(epoch: 6, batches: 20, time: 0.008, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.708 loss_D_fake: 0.695 loss_D: 2.135 acc_real: 0.114 acc_fake: 0.383 loss_G_conf: 0.023 loss_AUX: 0.362 loss_D_gr_fake: 0.369 acc_grfake: 0.924 
validation accuracies:
                gf: 0.86
                real: 0.81
                fake: 0.33

ran validation set (B:801) in                         11.8 s.
(epoch: 6, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.686 loss_D_fake: 0.745 loss_D: 2.148 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.350 loss_D_gr_fake: 0.366 acc_grfake: 0.862 
(epoch: 6, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.642 loss_D_fake: 0.928 loss_D: 2.329 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.386 loss_D_gr_fake: 0.373 acc_grfake: 0.862 
(epoch: 6, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.725 loss_D_fake: 0.645 loss_D: 2.016 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.377 loss_D_gr_fake: 0.270 acc_grfake: 0.862 
(epoch: 6, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.690 loss_D_fake: 0.678 loss_D: 2.038 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.376 loss_D_gr_fake: 0.294 acc_grfake: 0.862 
(epoch: 6, batches: 120, time: 0.008, data: 0.007) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.746 loss_D_fake: 0.591 loss_D: 1.918 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.353 loss_D_gr_fake: 0.229 acc_grfake: 0.862 
(epoch: 6, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.675 loss_D_fake: 0.723 loss_D: 2.022 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.377 loss_D_gr_fake: 0.247 acc_grfake: 0.862 
learning rate 0.0002000 -> 0.0002000
End of epoch 6 / 15 	 Time Taken: 82 sec
(epoch: 7, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.707 loss_D_fake: 0.597 loss_D: 1.927 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.375 loss_D_gr_fake: 0.249 acc_grfake: 0.862 
(epoch: 7, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.556 loss_D_fake: 0.969 loss_D: 2.287 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.360 loss_D_gr_fake: 0.402 acc_grfake: 0.862 
(epoch: 7, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.607 loss_D_fake: 0.795 loss_D: 2.088 acc_real: 0.808 acc_fake: 0.332 loss_G_conf: 0.023 loss_AUX: 0.363 loss_D_gr_fake: 0.323 acc_grfake: 0.862 
validation accuracies:
                gf: 0.79
                real: 0.93
                fake: 0.27

ran validation set (B:1001) in                         11.8 s.
(epoch: 7, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.669 loss_D_fake: 0.817 loss_D: 2.070 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.373 loss_D_gr_fake: 0.211 acc_grfake: 0.787 
(epoch: 7, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.682 loss_D_fake: 0.657 loss_D: 1.945 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.410 loss_D_gr_fake: 0.195 acc_grfake: 0.787 
(epoch: 7, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.643 loss_D_fake: 0.852 loss_D: 2.147 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.395 loss_D_gr_fake: 0.258 acc_grfake: 0.787 
(epoch: 7, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.609 loss_D_fake: 0.729 loss_D: 1.906 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.375 loss_D_gr_fake: 0.194 acc_grfake: 0.787 
learning rate 0.0002000 -> 0.0002000
End of epoch 7 / 15 	 Time Taken: 81 sec
(epoch: 8, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.591 loss_D_fake: 0.846 loss_D: 2.026 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.378 loss_D_gr_fake: 0.212 acc_grfake: 0.787 
(epoch: 8, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.614 loss_D_fake: 0.983 loss_D: 2.307 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.421 loss_D_gr_fake: 0.289 acc_grfake: 0.787 
(epoch: 8, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.617 loss_D_fake: 0.827 loss_D: 1.979 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.399 loss_D_gr_fake: 0.136 acc_grfake: 0.787 
(epoch: 8, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.643 loss_D_fake: 0.735 loss_D: 2.019 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.399 loss_D_gr_fake: 0.242 acc_grfake: 0.787 
(epoch: 8, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.708 loss_G_anti_sc: 0.473 loss_G: 1.205 loss_D_real: 0.598 loss_D_fake: 0.880 loss_D: 2.127 acc_real: 0.931 acc_fake: 0.266 loss_G_conf: 0.023 loss_AUX: 0.408 loss_D_gr_fake: 0.242 acc_grfake: 0.787 
validation accuracies:
                gf: 0.96
                real: 0.75
                fake: 0.57

ran validation set (B:1201) in                         11.8 s.
(epoch: 8, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.833 loss_G_anti_sc: 0.716 loss_G: 1.571 loss_D_real: 0.566 loss_D_fake: 1.075 loss_D: 2.373 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.022 loss_AUX: 0.391 loss_D_gr_fake: 0.341 acc_grfake: 0.961 
(epoch: 8, batches: 140, time: 0.005, data: 0.003) loss_G_comp: 0.784 loss_G_anti_sc: 0.679 loss_G: 1.495 loss_D_real: 0.566 loss_D_fake: 1.075 loss_D: 2.373 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.033 loss_AUX: 0.391 loss_D_gr_fake: 0.341 acc_grfake: 0.961 
learning rate 0.0002000 -> 0.0002000
End of epoch 8 / 15 	 Time Taken: 75 sec
(epoch: 9, batches: 20, time: 0.005, data: 0.003) loss_G_comp: 0.780 loss_G_anti_sc: 0.671 loss_G: 1.473 loss_D_real: 0.566 loss_D_fake: 1.075 loss_D: 2.373 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.022 loss_AUX: 0.391 loss_D_gr_fake: 0.341 acc_grfake: 0.961 
(epoch: 9, batches: 40, time: 0.005, data: 0.003) loss_G_comp: 0.836 loss_G_anti_sc: 0.673 loss_G: 1.531 loss_D_real: 0.566 loss_D_fake: 1.075 loss_D: 2.373 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.023 loss_AUX: 0.391 loss_D_gr_fake: 0.341 acc_grfake: 0.961 
(epoch: 9, batches: 60, time: 0.005, data: 0.003) loss_G_comp: 1.733 loss_G_anti_sc: 0.262 loss_G: 2.020 loss_D_real: 1.907 loss_D_fake: 0.259 loss_D: 2.772 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.026 loss_AUX: 0.361 loss_D_gr_fake: 0.245 acc_grfake: 0.961 
(epoch: 9, batches: 80, time: 0.005, data: 0.003) loss_G_comp: 0.976 loss_G_anti_sc: 0.423 loss_G: 1.420 loss_D_real: 1.057 loss_D_fake: 0.436 loss_D: 2.197 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.022 loss_AUX: 0.302 loss_D_gr_fake: 0.401 acc_grfake: 0.961 
(epoch: 9, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 0.856 loss_G_anti_sc: 0.484 loss_G: 1.357 loss_D_real: 0.907 loss_D_fake: 0.531 loss_D: 2.202 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.017 loss_AUX: 0.277 loss_D_gr_fake: 0.487 acc_grfake: 0.961 
(epoch: 9, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.825 loss_G_anti_sc: 0.516 loss_G: 1.357 loss_D_real: 0.891 loss_D_fake: 0.542 loss_D: 2.165 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.016 loss_AUX: 0.256 loss_D_gr_fake: 0.475 acc_grfake: 0.961 
(epoch: 9, batches: 140, time: 0.005, data: 0.003) loss_G_comp: 0.815 loss_G_anti_sc: 0.494 loss_G: 1.323 loss_D_real: 0.868 loss_D_fake: 0.558 loss_D: 2.194 acc_real: 0.749 acc_fake: 0.572 loss_G_conf: 0.014 loss_AUX: 0.295 loss_D_gr_fake: 0.473 acc_grfake: 0.961 
validation accuracies:
                gf: 0.93
                real: 0.09
                fake: 0.73

ran validation set (B:1401) in                         11.7 s.
learning rate 0.0002000 -> 0.0002000
End of epoch 9 / 15 	 Time Taken: 68 sec
(epoch: 10, batches: 20, time: 0.005, data: 0.003) loss_G_comp: 0.818 loss_G_anti_sc: 0.497 loss_G: 1.329 loss_D_real: 0.847 loss_D_fake: 0.560 loss_D: 2.178 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.014 loss_AUX: 0.284 loss_D_gr_fake: 0.486 acc_grfake: 0.926 
(epoch: 10, batches: 40, time: 0.005, data: 0.003) loss_G_comp: 0.796 loss_G_anti_sc: 0.515 loss_G: 1.324 loss_D_real: 0.847 loss_D_fake: 0.560 loss_D: 2.178 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.013 loss_AUX: 0.284 loss_D_gr_fake: 0.486 acc_grfake: 0.926 
(epoch: 10, batches: 60, time: 0.005, data: 0.003) loss_G_comp: 0.816 loss_G_anti_sc: 0.467 loss_G: 1.296 loss_D_real: 0.847 loss_D_fake: 0.560 loss_D: 2.178 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.013 loss_AUX: 0.284 loss_D_gr_fake: 0.486 acc_grfake: 0.926 
(epoch: 10, batches: 80, time: 0.005, data: 0.003) loss_G_comp: 0.816 loss_G_anti_sc: 0.480 loss_G: 1.310 loss_D_real: 0.847 loss_D_fake: 0.560 loss_D: 2.178 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.015 loss_AUX: 0.284 loss_D_gr_fake: 0.486 acc_grfake: 0.926 
(epoch: 10, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 1.094 loss_G_anti_sc: 0.405 loss_G: 1.515 loss_D_real: 1.242 loss_D_fake: 0.571 loss_D: 2.518 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.017 loss_AUX: 0.269 loss_D_gr_fake: 0.435 acc_grfake: 0.926 
(epoch: 10, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.794 loss_G_anti_sc: 0.415 loss_G: 1.224 loss_D_real: 0.903 loss_D_fake: 0.646 loss_D: 2.313 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.015 loss_AUX: 0.290 loss_D_gr_fake: 0.475 acc_grfake: 0.926 
(epoch: 10, batches: 140, time: 0.005, data: 0.003) loss_G_comp: 0.750 loss_G_anti_sc: 0.477 loss_G: 1.241 loss_D_real: 0.909 loss_D_fake: 0.647 loss_D: 2.301 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.014 loss_AUX: 0.287 loss_D_gr_fake: 0.458 acc_grfake: 0.926 
saving the model at the end of epoch 10, iters 99840
learning rate 0.0002000 -> 0.0001600
End of epoch 10 / 15 	 Time Taken: 53 sec
(epoch: 11, batches: 20, time: 0.005, data: 0.003) loss_G_comp: 0.734 loss_G_anti_sc: 0.478 loss_G: 1.225 loss_D_real: 0.866 loss_D_fake: 0.705 loss_D: 2.344 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.013 loss_AUX: 0.298 loss_D_gr_fake: 0.476 acc_grfake: 0.926 
(epoch: 11, batches: 40, time: 0.006, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.889 loss_D_fake: 0.657 loss_D: 2.295 acc_real: 0.092 acc_fake: 0.734 loss_G_conf: 0.012 loss_AUX: 0.287 loss_D_gr_fake: 0.463 acc_grfake: 0.926 
validation accuracies:
                gf: 0.90
                real: 0.14
                fake: 0.43

ran validation set (B:1601) in                         11.7 s.
(epoch: 11, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.833 loss_D_fake: 0.698 loss_D: 2.321 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.296 loss_D_gr_fake: 0.494 acc_grfake: 0.900 
(epoch: 11, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.837 loss_D_fake: 0.700 loss_D: 2.337 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.307 loss_D_gr_fake: 0.494 acc_grfake: 0.900 
(epoch: 11, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.830 loss_D_fake: 0.661 loss_D: 2.296 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.308 loss_D_gr_fake: 0.497 acc_grfake: 0.900 
(epoch: 11, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.837 loss_D_fake: 0.667 loss_D: 2.277 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.289 loss_D_gr_fake: 0.484 acc_grfake: 0.900 
(epoch: 11, batches: 140, time: 0.009, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.842 loss_D_fake: 0.649 loss_D: 2.265 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.295 loss_D_gr_fake: 0.480 acc_grfake: 0.900 
learning rate 0.0001600 -> 0.0001600
End of epoch 11 / 15 	 Time Taken: 79 sec
(epoch: 12, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.820 loss_D_fake: 0.651 loss_D: 2.285 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.323 loss_D_gr_fake: 0.491 acc_grfake: 0.900 
(epoch: 12, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.823 loss_D_fake: 0.641 loss_D: 2.263 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.305 loss_D_gr_fake: 0.495 acc_grfake: 0.900 
(epoch: 12, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.804 loss_D_fake: 0.677 loss_D: 2.256 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.287 loss_D_gr_fake: 0.488 acc_grfake: 0.900 
(epoch: 12, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.738 loss_G_anti_sc: 0.480 loss_G: 1.229 loss_D_real: 0.814 loss_D_fake: 0.659 loss_D: 2.250 acc_real: 0.141 acc_fake: 0.432 loss_G_conf: 0.012 loss_AUX: 0.314 loss_D_gr_fake: 0.462 acc_grfake: 0.900 
validation accuracies:
                gf: 0.89
                real: 0.24
                fake: 0.55

ran validation set (B:1801) in                         11.7 s.
(epoch: 12, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 0.753 loss_G_anti_sc: 0.505 loss_G: 1.271 loss_D_real: 0.834 loss_D_fake: 0.648 loss_D: 2.255 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.013 loss_AUX: 0.300 loss_D_gr_fake: 0.472 acc_grfake: 0.895 
(epoch: 12, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.742 loss_G_anti_sc: 0.488 loss_G: 1.242 loss_D_real: 0.834 loss_D_fake: 0.648 loss_D: 2.255 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.012 loss_AUX: 0.300 loss_D_gr_fake: 0.472 acc_grfake: 0.895 
(epoch: 12, batches: 140, time: 0.005, data: 0.003) loss_G_comp: 0.727 loss_G_anti_sc: 0.508 loss_G: 1.247 loss_D_real: 0.834 loss_D_fake: 0.648 loss_D: 2.255 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.012 loss_AUX: 0.300 loss_D_gr_fake: 0.472 acc_grfake: 0.895 
learning rate 0.0001600 -> 0.0001600
End of epoch 12 / 15 	 Time Taken: 71 sec
(epoch: 13, batches: 20, time: 0.005, data: 0.003) loss_G_comp: 0.747 loss_G_anti_sc: 0.481 loss_G: 1.241 loss_D_real: 0.834 loss_D_fake: 0.648 loss_D: 2.255 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.014 loss_AUX: 0.300 loss_D_gr_fake: 0.472 acc_grfake: 0.895 
(epoch: 13, batches: 40, time: 0.005, data: 0.003) loss_G_comp: 0.941 loss_G_anti_sc: 0.360 loss_G: 1.317 loss_D_real: 1.440 loss_D_fake: 0.530 loss_D: 2.581 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.016 loss_AUX: 0.352 loss_D_gr_fake: 0.260 acc_grfake: 0.895 
(epoch: 13, batches: 60, time: 0.005, data: 0.003) loss_G_comp: 0.739 loss_G_anti_sc: 0.420 loss_G: 1.172 loss_D_real: 0.961 loss_D_fake: 0.753 loss_D: 2.473 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.012 loss_AUX: 0.322 loss_D_gr_fake: 0.437 acc_grfake: 0.895 
(epoch: 13, batches: 80, time: 0.005, data: 0.003) loss_G_comp: 0.736 loss_G_anti_sc: 0.506 loss_G: 1.254 loss_D_real: 0.958 loss_D_fake: 0.737 loss_D: 2.464 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.012 loss_AUX: 0.336 loss_D_gr_fake: 0.432 acc_grfake: 0.895 
(epoch: 13, batches: 100, time: 0.005, data: 0.003) loss_G_comp: 0.715 loss_G_anti_sc: 0.487 loss_G: 1.217 loss_D_real: 0.942 loss_D_fake: 0.724 loss_D: 2.453 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.015 loss_AUX: 0.345 loss_D_gr_fake: 0.442 acc_grfake: 0.895 
(epoch: 13, batches: 120, time: 0.005, data: 0.003) loss_G_comp: 0.744 loss_G_anti_sc: 0.454 loss_G: 1.211 loss_D_real: 0.894 loss_D_fake: 0.723 loss_D: 2.399 acc_real: 0.244 acc_fake: 0.551 loss_G_conf: 0.012 loss_AUX: 0.326 loss_D_gr_fake: 0.457 acc_grfake: 0.895 
validation accuracies:
                gf: 0.93
                real: 0.10
                fake: 0.41

ran validation set (B:2001) in                         11.8 s.
(epoch: 13, batches: 140, time: 0.007, data: 0.004) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.865 loss_D_fake: 0.786 loss_D: 2.467 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.347 loss_D_gr_fake: 0.469 acc_grfake: 0.926 
learning rate 0.0001600 -> 0.0001600
End of epoch 13 / 15 	 Time Taken: 71 sec
(epoch: 14, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.815 loss_D_fake: 0.772 loss_D: 2.432 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.342 loss_D_gr_fake: 0.503 acc_grfake: 0.926 
(epoch: 14, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.817 loss_D_fake: 0.748 loss_D: 2.406 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.340 loss_D_gr_fake: 0.501 acc_grfake: 0.926 
(epoch: 14, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.814 loss_D_fake: 0.804 loss_D: 2.480 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.362 loss_D_gr_fake: 0.501 acc_grfake: 0.926 
(epoch: 14, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.812 loss_D_fake: 0.705 loss_D: 2.356 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.342 loss_D_gr_fake: 0.495 acc_grfake: 0.926 
(epoch: 14, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.828 loss_D_fake: 0.724 loss_D: 2.398 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.354 loss_D_gr_fake: 0.492 acc_grfake: 0.926 
(epoch: 14, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.821 loss_D_fake: 0.699 loss_D: 2.377 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.362 loss_D_gr_fake: 0.495 acc_grfake: 0.926 
(epoch: 14, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.821 loss_D_fake: 0.694 loss_D: 2.332 acc_real: 0.104 acc_fake: 0.410 loss_G_conf: 0.013 loss_AUX: 0.342 loss_D_gr_fake: 0.476 acc_grfake: 0.926 
learning rate 0.0001600 -> 0.0001600
End of epoch 14 / 15 	 Time Taken: 70 sec
validation accuracies:
                gf: 0.88
                real: 0.21
                fake: 0.42

ran validation set (B:2201) in                         11.8 s.
(epoch: 15, batches: 20, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.808 loss_D_fake: 0.688 loss_D: 2.348 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.373 loss_D_gr_fake: 0.478 acc_grfake: 0.881 
(epoch: 15, batches: 40, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.800 loss_D_fake: 0.753 loss_D: 2.411 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.369 loss_D_gr_fake: 0.490 acc_grfake: 0.881 
(epoch: 15, batches: 60, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.797 loss_D_fake: 0.706 loss_D: 2.353 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.361 loss_D_gr_fake: 0.488 acc_grfake: 0.881 
(epoch: 15, batches: 80, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.765 loss_D_fake: 0.721 loss_D: 2.356 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.365 loss_D_gr_fake: 0.505 acc_grfake: 0.881 
(epoch: 15, batches: 100, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.804 loss_D_fake: 0.708 loss_D: 2.357 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.373 loss_D_gr_fake: 0.471 acc_grfake: 0.881 
(epoch: 15, batches: 120, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.807 loss_D_fake: 0.740 loss_D: 2.382 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.389 loss_D_gr_fake: 0.447 acc_grfake: 0.881 
(epoch: 15, batches: 140, time: 0.007, data: 0.003) loss_G_comp: 0.725 loss_G_anti_sc: 0.506 loss_G: 1.244 loss_D_real: 0.816 loss_D_fake: 0.674 loss_D: 2.321 acc_real: 0.207 acc_fake: 0.418 loss_G_conf: 0.013 loss_AUX: 0.387 loss_D_gr_fake: 0.444 acc_grfake: 0.881 
saving the model at the end of epoch 15, iters 149760
learning rate 0.0001600 -> 0.0001600
End of epoch 15 / 15 	 Time Taken: 82 sec
Finished training, model is saved
Batches trained - G: 750, D: 1590 
